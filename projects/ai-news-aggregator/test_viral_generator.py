#!/usr/bin/env python3
"""
ğŸ§ª çˆ†æ¬¾æ–‡ç« ç”Ÿæˆå™¨æµ‹è¯•è„šæœ¬
æµ‹è¯•AIåŸåˆ›æ–‡ç« ç”Ÿæˆå’Œç«çˆ†åº¦é¢„æµ‹åŠŸèƒ½
"""

import asyncio
import sys
import os
from datetime import datetime

# ç®€åŒ–ç‰ˆå†…å®¹å¤„ç†å™¨ï¼ˆç”¨äºæµ‹è¯•ï¼‰
class SimpleAIProcessor:
    def __init__(self):
        pass
    
    async def call_deepseek_api(self, messages):
        """æ¨¡æ‹ŸAIç”Ÿæˆå†…å®¹"""
        topic = "AIæŠ€æœ¯çªç ´"
        
        # æ¨¡æ‹Ÿç”Ÿæˆçš„æ–‡ç« å†…å®¹
        sample_content = f"""
{messages[1]['content'].split('å¼€åœºç™½ï¼š')[1].split('æ ‡é¢˜ï¼š')[0].strip()}ï¼Œ{topic}å†æ¬¡éœ‡æ’¼å…¨çƒï¼

åˆšåˆšæ”¶åˆ°æ¶ˆæ¯ï¼Œè¿™é¡¹æŠ€æœ¯çš„çªç ´å¯èƒ½æ¯”æˆ‘ä»¬æƒ³è±¡çš„æ›´å…·é¢ è¦†æ€§ã€‚

**æ ¸å¿ƒçªç ´**
è¿™æ¬¡æŠ€æœ¯é©æ–°åœ¨ä»¥ä¸‹å‡ ä¸ªå…³é”®é¢†åŸŸå®ç°äº†è´¨çš„é£è·ƒï¼š
â€¢ å¤„ç†é€Ÿåº¦æå‡äº†500%ï¼Œè¶…è¶Šäº†æ‰€æœ‰ç°æœ‰ç³»ç»Ÿ
â€¢ èƒ½è€—é™ä½äº†70%ï¼ŒçœŸæ­£å®ç°äº†ç»¿è‰²AI
â€¢ åº”ç”¨åœºæ™¯æ‰©å±•åˆ°20+ä¸ªå…¨æ–°é¢†åŸŸ

**è¡Œä¸šåå“**
ä¸šå†…é¡¶çº§ä¸“å®¶çº·çº·å‘å£°ï¼Œè®¤ä¸ºè¿™æ˜¯"æ”¹å˜æ¸¸æˆè§„åˆ™çš„æ—¶åˆ»"ã€‚ä¸€ä½ç¡…è°·èµ„æ·±å·¥ç¨‹å¸ˆå‘Šè¯‰æˆ‘ï¼š"è¿™ä¸ä»…ä»…æ˜¯æŠ€æœ¯è¿›æ­¥ï¼Œè¿™æ˜¯èŒƒå¼è½¬å˜ã€‚"

**æ·±åº¦å½±å“**
å¯¹äºæˆ‘ä»¬æ™®é€šäººæ¥è¯´ï¼Œè¿™æ„å‘³ç€ï¼š
1. å·¥ä½œæ•ˆç‡å°†è¿æ¥é©å‘½æ€§æå‡
2. åˆ›ä½œé—¨æ§›å¤§å¹…é™ä½ï¼Œäººäººéƒ½èƒ½æˆä¸ºåˆ›ä½œè€…
3. å­¦ä¹ æ–¹å¼å½»åº•æ”¹å˜ï¼Œä¸ªæ€§åŒ–æ•™è‚²æˆä¸ºç°å®

**æœªæ¥å±•æœ›**
åŸºäºè¿™æ¬¡çªç ´ï¼Œæˆ‘é¢„æµ‹åœ¨æ¥ä¸‹æ¥çš„6ä¸ªæœˆå†…ï¼Œæ•´ä¸ªAIè¡Œä¸šå°†è¿æ¥æ–°ä¸€è½®çš„çˆ†å‘å¼å¢é•¿ã€‚é‚£äº›èƒ½å¤Ÿå¿«é€Ÿé€‚åº”å’Œåº”ç”¨è¿™é¡¹æŠ€æœ¯çš„ä¸ªäººå’Œä¼ä¸šï¼Œå°†è·å¾—å·¨å¤§çš„å…ˆå‘ä¼˜åŠ¿ã€‚

ä½ è§‰å¾—è¿™æ¬¡æŠ€æœ¯çªç ´ä¼šå¯¹ä½ çš„ç”Ÿæ´»å’Œå·¥ä½œäº§ç”Ÿä»€ä¹ˆå½±å“ï¼Ÿè¯„è®ºåŒºåˆ†äº«ä½ çš„æƒ³æ³•ï¼Œè®©æˆ‘ä»¬ä¸€èµ·è§è¯å†å²çš„è½¬æŠ˜ç‚¹ï¼

#AIçªç ´ #æŠ€æœ¯é©å‘½ #æœªæ¥å·²æ¥
        """
        
        return sample_content.strip()

# ç›´æ¥å¤åˆ¶æ ¸å¿ƒç±»å®šä¹‰ï¼ˆç®€åŒ–ç‰ˆï¼‰
import logging
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass
import random
import re

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

@dataclass
class ViralPrediction:
    """çˆ†æ¬¾é¢„æµ‹ç»“æœ"""
    title: str
    content: str
    platform: str
    viral_score: float  # çˆ†æ¬¾æŒ‡æ•° 0-100
    predicted_views: int  # é¢„æµ‹é˜…è¯»é‡
    engagement_rate: float  # é¢„æµ‹äº’åŠ¨ç‡
    optimization_tips: List[str]  # ä¼˜åŒ–å»ºè®®
    risk_factors: List[str]  # é£é™©æç¤º
    best_publish_time: str  # æœ€ä½³å‘å¸ƒæ—¶é—´
    target_audience: str  # ç›®æ ‡å—ä¼—
    trending_keywords: List[str]  # çƒ­é—¨å…³é”®è¯

class ViralArticleGenerator:
    """çˆ†æ¬¾æ–‡ç« ç”Ÿæˆå™¨"""
    
    def __init__(self, ai_processor = None):
        self.ai_processor = ai_processor or SimpleAIProcessor()
        
        # çˆ†æ¬¾æ–‡ç« æ¨¡æ¿åº“
        self.viral_templates = {
            "éœ‡æ’¼å‘å¸ƒ": {
                "title_patterns": [
                    "ğŸš€ é‡ç£…ï¼{topic}åˆšåˆšå‘å¸ƒï¼Œ{impact}éœ‡æ’¼å…¨çƒï¼",
                    "ğŸ’¥ çªå‘ï¼{topic}{action}ï¼Œ{result}ï¼",
                    "âš¡ åˆšåˆšï¼{company}å®˜å®£{topic}ï¼Œ{reaction}ç‚¸è£‚ï¼",
                    "ğŸ”¥ ç‹¬å®¶ï¼{topic}å†…å¹•æ›å…‰ï¼Œ{revelation}ï¼"
                ],
                "hooks": [
                    "åˆšåˆšæ”¶åˆ°å†…éƒ¨æ¶ˆæ¯",
                    "æœ‹å‹åœˆéƒ½åœ¨è½¬å‘è¿™ä¸ª",
                    "ä¸æ•¢ç›¸ä¿¡è‡ªå·±çš„çœ¼ç›",
                    "è¿™å¯èƒ½æ”¹å˜ä¸€åˆ‡"
                ],
                "viral_potential": 95
            },
            "æ·±åº¦è§£æ": {
                "title_patterns": [
                    "ğŸ§  æ·±åº¦ï½œ{topic}èƒŒåçš„{angle}ï¼Œ99%çš„äººéƒ½æƒ³é”™äº†",
                    "ğŸ“Š æ•°æ®è¯´è¯ï½œ{topic}çš„{aspect}ï¼ŒçœŸç›¸ç«Ÿç„¶æ˜¯è¿™æ ·",
                    "ğŸ” ç‹¬å®¶è§£æï½œ{topic}ä¸ºä»€ä¹ˆ{reason}ï¼Ÿå†…è¡Œäººç»ˆäºè¯´å‡ºçœŸè¯",
                    "ğŸ’¡ é‡æ–°è®¤è¯†{topic}ï¼š{new_perspective}"
                ],
                "hooks": [
                    "ä½œä¸ºè¡Œä¸šå†…éƒ¨äººå£«",
                    "ç»è¿‡æ·±åº¦è°ƒç ”å‘ç°",
                    "è®©æˆ‘ä»¬ç”¨æ•°æ®è¯´è¯",
                    "ä»å¦ä¸€ä¸ªè§’åº¦çœ‹"
                ],
                "viral_potential": 80
            },
            "äº‰è®®è¯é¢˜": {
                "title_patterns": [
                    "âš ï¸ äº‰è®®ï½œ{topic}çœŸçš„{claim}å—ï¼Ÿæˆ‘æœ‰ä¸åŒçœ‹æ³•",
                    "ğŸ—£ï¸ çƒ­è®®ï½œ{topic}{controversy}ï¼Œç½‘å‹åµç¿»äº†ï¼",
                    "â“ è´¨ç–‘ï½œ{topic}èƒŒåçš„{hidden_truth}ï¼Œæ²¡äººæ•¢è¯´å‡ºæ¥",
                    "ğŸ¤” åæ€ï½œ{topic}è®©æˆ‘ä»¬å¤±å»äº†ä»€ä¹ˆï¼Ÿ"
                ],
                "hooks": [
                    "å¯èƒ½ä¼šå¾—ç½ªä¸€äº›äººï¼Œä½†æˆ‘è¿˜æ˜¯è¦è¯´",
                    "è¿™ä¸ªè§‚ç‚¹å¯èƒ½å¾ˆä¸å—æ¬¢è¿",
                    "å‡†å¤‡å¥½è¢«å–·äº†ï¼Œä½†çœŸç›¸éœ€è¦æœ‰äººè¯´",
                    "ä¸åŒçš„å£°éŸ³åŒæ ·å€¼å¾—å€¾å¬"
                ],
                "viral_potential": 90
            },
            "é¢„æµ‹æœªæ¥": {
                "title_patterns": [
                    "ğŸ”® é¢„æµ‹ï½œ{topic}å°†åœ¨{timeframe}å†…{prediction}",
                    "ğŸŒŸ è¶‹åŠ¿ï½œ{topic}çš„{future_impact}ï¼Œä½ å‡†å¤‡å¥½äº†å—ï¼Ÿ",
                    "â° å€’è®¡æ—¶ï½œ{topic}{countdown}ï¼Œ{consequence}å³å°†åˆ°æ¥",
                    "ğŸš€ æœªæ¥å·²æ¥ï½œ{topic}æ­£åœ¨{transformation}"
                ],
                "hooks": [
                    "å¦‚æœæˆ‘å‘Šè¯‰ä½ æœªæ¥æ˜¯è¿™æ ·",
                    "10å¹´åå›çœ‹ä»Šå¤©",
                    "å†å²æ€»æ˜¯æƒŠäººçš„ç›¸ä¼¼",
                    "å˜åŒ–æ¯”æˆ‘ä»¬æƒ³è±¡çš„æ›´å¿«"
                ],
                "viral_potential": 75
            },
            "ä¸ªäººæ•…äº‹": {
                "title_patterns": [
                    "ğŸ’­ äº²å†ï½œæˆ‘ä¸{topic}çš„{experience}ï¼Œ{emotion}...",
                    "ğŸ“ å®å½•ï½œ{topic}æ”¹å˜äº†æˆ‘çš„{aspect}",
                    "ğŸ’ª åŠ±å¿—ï½œä»{starting_point}åˆ°{achievement}ï¼Œ{topic}ç»™äº†æˆ‘{power}",
                    "ğŸ˜® éœ‡æƒŠï½œ{topic}è®©æˆ‘æ„è¯†åˆ°{realization}"
                ],
                "hooks": [
                    "è¯´å‡ºæ¥ä½ å¯èƒ½ä¸ä¿¡",
                    "è¿™æ˜¯æˆ‘çš„äº²èº«ç»å†",
                    "ä»æ²¡æƒ³è¿‡ä¼šæœ‰è¿™æ ·çš„ä½“éªŒ",
                    "å¦‚æœæ—©çŸ¥é“è¿™äº›å°±å¥½äº†"
                ],
                "viral_potential": 85
            }
        }
        
        # çˆ†æ¬¾å…³é”®è¯åº“
        self.viral_keywords = {
            "æƒ…ç»ªè¯": ["éœ‡æ’¼", "ç‚¸è£‚", "ç–¯ç‹‚", "æƒŠè‰³", "å´©æºƒ", "æ²¸è…¾", "é¢ è¦†", "é€†å¤©"],
            "æ•°å­—è¯": ["é¦–æ¬¡", "å²ä¸Šæœ€", "100%", "10å€", "åƒä¸‡", "äº¿çº§", "ç¬¬ä¸€"],
            "ç´§è¿«è¯": ["åˆšåˆš", "çªå‘", "ç´§æ€¥", "é™æ—¶", "å€’è®¡æ—¶", "æœ€å", "å³å°†"],
            "ç‹¬å®¶è¯": ["å†…å¹•", "æ­ç§˜", "ç‹¬å®¶", "çˆ†æ–™", "æ›å…‰", "é¦–å‘", "é‡ç£…"],
            "å¯¹æ¯”è¯": ["VS", "ç¢¾å‹", "ç§’æ€", "è¶…è¶Š", "å®Œèƒœ", "åŠæ‰“", "é€†è¢­"],
            "ç–‘é—®è¯": ["ä¸ºä»€ä¹ˆ", "æ€ä¹ˆåŠ", "çœŸçš„å—", "å¯èƒ½å—", "è°çŸ¥é“", "ä»€ä¹ˆ"],
            "è¯é¢˜è¯": ["äººå·¥æ™ºèƒ½", "ChatGPT", "å¤§æ¨¡å‹", "AI", "æœºå™¨äºº", "è‡ªåŠ¨é©¾é©¶", "å…ƒå®‡å®™"]
        }
        
        # å¹³å°ç‰¹æ€§
        self.platform_features = {
            "wechat": {
                "title_length": 64,
                "content_length": (1500, 3000),
                "tone": "ä¸“ä¸šæƒå¨",
                "audience": "å•†åŠ¡äººç¾¤",
                "peak_hours": ["09:00", "12:00", "18:00", "21:00"],
                "engagement_multiplier": 1.2
            },
            "xiaohongshu": {
                "title_length": 50,
                "content_length": (800, 1500),
                "tone": "å¹´è½»æ´»æ³¼",
                "audience": "å¹´è½»å¥³æ€§",
                "peak_hours": ["11:00", "15:00", "20:00", "22:00"],
                "engagement_multiplier": 1.8
            }
        }

    def calculate_viral_score(self, title: str, content: str, platform: str) -> float:
        """è®¡ç®—çˆ†æ¬¾æŒ‡æ•°"""
        score = 0.0
        
        # æ ‡é¢˜åˆ†æ (40åˆ†)
        title_score = 0
        
        # æƒ…ç»ªæ¿€å‘è¯
        for word in self.viral_keywords["æƒ…ç»ªè¯"]:
            if word in title:
                title_score += 5
        
        # æ•°å­—å’Œæ•°æ®
        for word in self.viral_keywords["æ•°å­—è¯"]:
            if word in title:
                title_score += 4
        
        # ç´§è¿«æ„Ÿ
        for word in self.viral_keywords["ç´§è¿«è¯"]:
            if word in title:
                title_score += 6
        
        # ç‹¬å®¶æ€§
        for word in self.viral_keywords["ç‹¬å®¶è¯"]:
            if word in title:
                title_score += 7
        
        # emojiä½¿ç”¨
        emoji_count = len(re.findall(r'[\U0001F600-\U0001F64F\U0001F300-\U0001F5FF\U0001F680-\U0001F6FF\U0001F1E0-\U0001F1FF]', title))
        title_score += min(emoji_count * 2, 8)
        
        score += min(title_score, 40)
        
        # å†…å®¹åˆ†æ (35åˆ†)
        content_score = 0
        
        # é•¿åº¦é€‚ä¸­
        content_len = len(content)
        platform_range = self.platform_features[platform]["content_length"]
        if platform_range[0] <= content_len <= platform_range[1]:
            content_score += 10
        elif content_len < platform_range[0]:
            content_score += 5  # å¤ªçŸ­æ‰£åˆ†
        
        # æ®µè½ç»“æ„
        paragraphs = content.split('\n')
        if 3 <= len(paragraphs) <= 8:
            content_score += 8
        
        # äº’åŠ¨å…ƒç´ 
        if any(word in content for word in ["ä½ è§‰å¾—", "å¤§å®¶", "è¯„è®º", "åˆ†äº«", "è½¬å‘"]):
            content_score += 7
        
        # æ•…äº‹æ€§
        if any(word in content for word in ["æˆ‘", "å½“æ—¶", "çªç„¶", "æ²¡æƒ³åˆ°", "ç»“æœ"]):
            content_score += 10
        
        score += min(content_score, 35)
        
        # æ—¶æ•ˆæ€§ (15åˆ†)
        current_hour = datetime.now().hour
        peak_hours = [int(h.split(':')[0]) for h in self.platform_features[platform]["peak_hours"]]
        if current_hour in peak_hours:
            score += 15
        elif abs(min(peak_hours, key=lambda x: abs(x - current_hour)) - current_hour) <= 1:
            score += 10
        else:
            score += 5
        
        # è¯é¢˜çƒ­åº¦ (10åˆ†)
        for keyword in self.viral_keywords["è¯é¢˜è¯"]:
            if keyword in title or keyword in content:
                score += 10
                break
        
        return min(score, 100)

    def predict_views(self, viral_score: float, platform: str, content_length: int) -> int:
        """é¢„æµ‹é˜…è¯»é‡"""
        base_views = {
            "wechat": 5000,
            "xiaohongshu": 8000
        }
        
        base = base_views[platform]
        multiplier = self.platform_features[platform]["engagement_multiplier"]
        
        # çˆ†æ¬¾æŒ‡æ•°å½±å“
        score_multiplier = (viral_score / 100) ** 2 * 10 + 1
        
        # å†…å®¹é•¿åº¦å½±å“
        length_range = self.platform_features[platform]["content_length"]
        optimal_length = (length_range[0] + length_range[1]) / 2
        length_factor = 1 - abs(content_length - optimal_length) / optimal_length * 0.3
        length_factor = max(length_factor, 0.5)
        
        # éšæœºå› ç´  (æ¨¡æ‹Ÿç®—æ³•æ¨èçš„ä¸ç¡®å®šæ€§)
        random_factor = random.uniform(0.7, 1.5)
        
        predicted_views = int(base * multiplier * score_multiplier * length_factor * random_factor)
        
        return max(predicted_views, 1000)  # æœ€å°‘1000é˜…è¯»

    def generate_optimization_tips(self, viral_score: float, title: str, content: str, platform: str) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        tips = []
        
        if viral_score < 60:
            tips.append("ğŸ’¡ æ ‡é¢˜ç¼ºä¹å¸å¼•åŠ›ï¼Œå»ºè®®æ·»åŠ æƒ…ç»ªæ¿€å‘è¯å¦‚'éœ‡æ’¼'ã€'é¢ è¦†'ç­‰")
            
        if not re.search(r'[\U0001F600-\U0001F64F\U0001F300-\U0001F5FF\U0001F680-\U0001F6FF\U0001F1E0-\U0001F1FF]', title):
            tips.append("ğŸ“± æ ‡é¢˜å»ºè®®æ·»åŠ 1-2ä¸ªç›¸å…³emojiå¢åŠ è§†è§‰å¸å¼•åŠ›")
            
        if not any(word in title for word in self.viral_keywords["ç´§è¿«è¯"]):
            tips.append("â° å»ºè®®åœ¨æ ‡é¢˜ä¸­æ·»åŠ ç´§è¿«æ„Ÿè¯æ±‡å¦‚'åˆšåˆš'ã€'çªå‘'ã€'å³å°†'")
            
        content_len = len(content)
        platform_range = self.platform_features[platform]["content_length"]
        if content_len < platform_range[0]:
            tips.append(f"ğŸ“ å†…å®¹è¿‡çŸ­({content_len}å­—)ï¼Œå»ºè®®æ‰©å±•åˆ°{platform_range[0]}-{platform_range[1]}å­—")
        elif content_len > platform_range[1]:
            tips.append(f"âœ‚ï¸ å†…å®¹è¿‡é•¿({content_len}å­—)ï¼Œå»ºè®®å‹ç¼©åˆ°{platform_range[0]}-{platform_range[1]}å­—")
            
        if not any(word in content for word in ["ä½ è§‰å¾—", "å¤§å®¶", "è¯„è®ºåŒº", "åˆ†äº«"]):
            tips.append("ğŸ’¬ å»ºè®®åœ¨ç»“å°¾æ·»åŠ äº’åŠ¨å¼•å¯¼è¯­ï¼Œæå‡è¯„è®ºå’Œåˆ†äº«ç‡")
            
        return tips

    def _extract_company(self, topic: str) -> str:
        """æå–å…¬å¸åç§°"""
        companies = ["OpenAI", "Google", "å¾®è½¯", "ç™¾åº¦", "è…¾è®¯", "é˜¿é‡Œ", "å­—èŠ‚", "Meta", "è‹¹æœ", "ç‰¹æ–¯æ‹‰"]
        for company in companies:
            if company.lower() in topic.lower():
                return company
        return "ç§‘æŠ€å·¨å¤´"

    def _assess_risks(self, title: str, content: str, template_type: str) -> List[str]:
        """é£é™©è¯„ä¼°"""
        risks = []
        
        # æ ‡é¢˜é£é™©
        if any(word in title for word in ["ç‹¬å®¶", "å†…å¹•", "çˆ†æ–™"]):
            risks.append("âš ï¸ æ ‡é¢˜ä½¿ç”¨äº†'ç‹¬å®¶'ã€'å†…å¹•'ç­‰è¯æ±‡ï¼Œéœ€ç¡®ä¿å†…å®¹çœŸå®æ€§")
            
        if template_type == "äº‰è®®è¯é¢˜":
            risks.append("ğŸ“¢ äº‰è®®æ€§å†…å®¹å¯èƒ½å¼•å‘è´Ÿé¢è¯„è®ºï¼Œéœ€è¦åˆç†å¼•å¯¼è®¨è®º")
        
        if len(risks) == 0:
            risks.append("âœ… å†…å®¹é£é™©è¾ƒä½ï¼Œå¯ä»¥å®‰å…¨å‘å¸ƒ")
            
        return risks

    def _get_best_publish_time(self, platform: str) -> str:
        """è·å–æœ€ä½³å‘å¸ƒæ—¶é—´"""
        current_time = datetime.now()
        peak_hours = self.platform_features[platform]["peak_hours"]
        
        # æ‰¾åˆ°æœ€è¿‘çš„é«˜å³°æ—¶é—´
        current_hour = current_time.hour
        future_peaks = []
        
        for peak in peak_hours:
            peak_hour = int(peak.split(':')[0])
            if peak_hour > current_hour:
                future_peaks.append(peak_hour)
        
        if future_peaks:
            next_peak = min(future_peaks)
            return f"ä»Šå¤© {next_peak:02d}:00"
        else:
            # æ˜å¤©çš„ç¬¬ä¸€ä¸ªé«˜å³°æ—¶é—´
            tomorrow_first_peak = int(peak_hours[0].split(':')[0])
            return f"æ˜å¤© {tomorrow_first_peak:02d}:00"

    def _extract_trending_keywords(self, title: str, content: str) -> List[str]:
        """æå–çƒ­é—¨å…³é”®è¯"""
        text = title + " " + content
        keywords = []
        
        # ä»å„ç±»å…³é”®è¯ä¸­æå–
        for category, word_list in self.viral_keywords.items():
            for word in word_list:
                if word in text and word not in keywords:
                    keywords.append(word)
        
        return keywords[:8]  # æœ€å¤š8ä¸ªå…³é”®è¯

    async def generate_viral_article(self, topic: str, platform: str = "wechat", template_type: str = None) -> ViralPrediction:
        """ç”Ÿæˆçˆ†æ¬¾æ–‡ç« """
        logger.info(f"ğŸ”¥ ç”Ÿæˆçˆ†æ¬¾æ–‡ç« : {topic} -> {platform}")
        
        # è‡ªåŠ¨é€‰æ‹©æœ€ä½³æ¨¡æ¿
        if not template_type:
            # åŸºäºè¯é¢˜é€‰æ‹©æœ€é€‚åˆçš„æ¨¡æ¿
            if any(word in topic.lower() for word in ["å‘å¸ƒ", "æ¨å‡º", "ä¸Šçº¿", "å®˜å®£"]):
                template_type = "éœ‡æ’¼å‘å¸ƒ"
            elif any(word in topic.lower() for word in ["åˆ†æ", "è§£è¯»", "æ·±åº¦", "ç ”ç©¶"]):
                template_type = "æ·±åº¦è§£æ"
            elif any(word in topic.lower() for word in ["äº‰è®®", "è´¨ç–‘", "åå¯¹", "æ‰¹è¯„"]):
                template_type = "äº‰è®®è¯é¢˜"
            elif any(word in topic.lower() for word in ["é¢„æµ‹", "æœªæ¥", "è¶‹åŠ¿", "å±•æœ›"]):
                template_type = "é¢„æµ‹æœªæ¥"
            else:
                template_type = "ä¸ªäººæ•…äº‹"
        
        template = self.viral_templates[template_type]
        
        # ç”Ÿæˆçˆ†æ¬¾æ ‡é¢˜
        title_pattern = random.choice(template["title_patterns"])
        
        # å¡«å……æ ‡é¢˜æ¨¡æ¿
        title_vars = {
            "topic": topic,
            "company": self._extract_company(topic),
            "impact": random.choice(["æ•ˆæœ", "å½±å“", "éœ‡æ’¼", "é¢ è¦†"]),
            "action": random.choice(["å‘å¸ƒ", "æ›´æ–°", "å‡çº§", "çªç ´"]),
            "result": random.choice(["å…¨ç½‘æ²¸è…¾", "è¡Œä¸šéœ‡æ’¼", "ç”¨æˆ·ç–¯ç‹‚", "ä¸“å®¶æƒŠå¹"]),
            "reaction": random.choice(["åå“", "è¯„è®º", "è®¨è®º", "çƒ­è®®"]),
            "revelation": random.choice(["çœŸç›¸å¤§ç™½", "å†…å¹•æ›å…‰", "ç§˜å¯†æ­å¼€", "ç­”æ¡ˆæ­æ™“"]),
            "angle": random.choice(["é€»è¾‘", "åŸç†", "æœºåˆ¶", "æœ¬è´¨"]),
            "aspect": random.choice(["å‘å±•", "ç°çŠ¶", "è¶‹åŠ¿", "æœªæ¥"]),
            "reason": random.choice(["è¿™ä¹ˆç«", "å¤‡å—å…³æ³¨", "å¼•å‘çƒ­è®®", "æˆä¸ºç„¦ç‚¹"]),
            "new_perspective": random.choice(["æ¢ä¸ªè§’åº¦çœ‹é—®é¢˜", "ä¸ä¸€æ ·çš„æ€è€ƒ", "å…¨æ–°çš„ç†è§£", "æ„æƒ³ä¸åˆ°çš„å‘ç°"]),
            "claim": random.choice(["æœ‰ç”¨", "é è°±", "å€¼å¾—", "å¯ä¿¡"]),
            "controversy": random.choice(["å¼•å‘äº‰è®®", "é­åˆ°è´¨ç–‘", "å¤‡å—äº‰è®®", "è®¨è®ºæ¿€çƒˆ"]),
            "hidden_truth": random.choice(["çœŸç›¸", "å†…å¹•", "ç§˜å¯†", "éšæƒ…"]),
            "timeframe": random.choice(["ä¸€å¹´", "ä¸¤å¹´", "ä¸‰å¹´", "äº”å¹´"]),
            "prediction": random.choice(["å¤§çˆ†å‘", "å¤§å˜é©", "æ–°çªç ´", "æ–°å±€é¢"]),
            "future_impact": random.choice(["å·¨å¤§å½±å“", "æ·±è¿œæ„ä¹‰", "é‡å¤§å˜åŒ–", "å…¨æ–°æ—¶ä»£"]),
            "countdown": random.choice(["å€’è®¡æ—¶å¼€å§‹", "è¿›å…¥å…³é”®æœŸ", "è¿æ¥è½¬æŠ˜ç‚¹", "é¢ä¸´å¤§è€ƒ"]),
            "consequence": random.choice(["å˜é©", "æœºé‡", "æŒ‘æˆ˜", "è½¬æœº"]),
            "transformation": random.choice(["æ”¹å˜ä¸–ç•Œ", "é‡å¡‘è¡Œä¸š", "é¢ è¦†è®¤çŸ¥", "åˆ›é€ å†å²"]),
            "experience": random.choice(["äº²å¯†æ¥è§¦", "æ·±åº¦ä½“éªŒ", "çœŸå®æ„Ÿå—", "å¥‡å¦™æ—…ç¨‹"]),
            "emotion": random.choice(["å¤ªéœ‡æ’¼äº†", "ä¸æ•¢ç›¸ä¿¡", "è¶…å‡ºé¢„æœŸ", "åˆ·æ–°è®¤çŸ¥"]),
            "starting_point": random.choice(["é›¶åŸºç¡€", "å°ç™½", "é—¨å¤–æ±‰", "æ–°æ‰‹"]),
            "achievement": random.choice(["ä¸“å®¶", "è¾¾äºº", "é«˜æ‰‹", "è¡Œå®¶"]),
            "power": random.choice(["åŠ¨åŠ›", "å¯å‘", "å¸®åŠ©", "æ”¯æŒ"]),
            "realization": random.choice(["é‡è¦é“ç†", "äººç”ŸçœŸè°›", "å…³é”®é—®é¢˜", "æ ¸å¿ƒæœ¬è´¨"])
        }
        
        title = title_pattern.format(**{k: v for k, v in title_vars.items() if f"{{{k}}}" in title_pattern})
        
        # ç”Ÿæˆå†…å®¹
        hook = random.choice(template["hooks"])
        content = await self._generate_article_content(topic, platform, template_type, hook, title)
        
        # è®¡ç®—é¢„æµ‹æŒ‡æ ‡
        viral_score = self.calculate_viral_score(title, content, platform)
        predicted_views = self.predict_views(viral_score, platform, len(content))
        engagement_rate = min(viral_score / 100 * 0.15, 0.20)  # æœ€é«˜20%äº’åŠ¨ç‡
        
        # ç”Ÿæˆä¼˜åŒ–å»ºè®®
        optimization_tips = self.generate_optimization_tips(viral_score, title, content, platform)
        
        # é£é™©è¯„ä¼°
        risk_factors = self._assess_risks(title, content, template_type)
        
        # æœ€ä½³å‘å¸ƒæ—¶é—´
        best_time = self._get_best_publish_time(platform)
        
        # ç›®æ ‡å—ä¼—
        target_audience = self.platform_features[platform]["audience"]
        
        # çƒ­é—¨å…³é”®è¯
        trending_keywords = self._extract_trending_keywords(title, content)
        
        prediction = ViralPrediction(
            title=title,
            content=content,
            platform=platform,
            viral_score=viral_score,
            predicted_views=predicted_views,
            engagement_rate=engagement_rate,
            optimization_tips=optimization_tips,
            risk_factors=risk_factors,
            best_publish_time=best_time,
            target_audience=target_audience,
            trending_keywords=trending_keywords
        )
        
        logger.info(f"âœ… çˆ†æ¬¾æ–‡ç« ç”Ÿæˆå®Œæˆ: é¢„æµ‹é˜…è¯»é‡ {predicted_views:,}")
        return prediction

    async def _generate_article_content(self, topic: str, platform: str, template_type: str, hook: str, title: str) -> str:
        """ç”Ÿæˆæ–‡ç« å†…å®¹"""
        
        # æ ¹æ®å¹³å°å’Œæ¨¡æ¿ç±»å‹æ„å»ºæç¤ºè¯
        platform_info = self.platform_features[platform]
        min_len, max_len = platform_info["content_length"]
        tone = platform_info["tone"]
        
        prompt = f"""
è¯·åŸºäºä»¥ä¸‹ä¿¡æ¯åˆ›ä½œä¸€ç¯‡çˆ†æ¬¾åŸåˆ›æ–‡ç« ï¼š

ä¸»é¢˜ï¼š{topic}
å¹³å°ï¼š{platform}
é£æ ¼ï¼š{template_type}
è¯­è°ƒï¼š{tone}
å¼€åœºç™½ï¼š{hook}
æ ‡é¢˜ï¼š{title}

è¦æ±‚ï¼š
1. å­—æ•°ï¼š{min_len}-{max_len}å­—
2. ç»“æ„æ¸…æ™°ï¼Œåˆ†3-5ä¸ªæ®µè½
3. å¼€å¤´ç”¨é’©å­å¸å¼•è¯»è€…
4. å†…å®¹åŸåˆ›ï¼Œæœ‰ç‹¬ç‰¹è§‚ç‚¹
5. ç»“å°¾å¼•å¯¼äº’åŠ¨
6. è¯­è¨€{tone}ä½†æ˜“æ‡‚
7. é€‚å½“ä½¿ç”¨æ•°æ®å’Œæ¡ˆä¾‹
8. ç¡®ä¿å†…å®¹èƒ½å¼•å‘è®¨è®ºå’Œåˆ†äº«

è¯·ç›´æ¥è¾“å‡ºæ–‡ç« å†…å®¹ï¼Œä¸è¦åŒ…å«å…¶ä»–è¯´æ˜ã€‚
        """
        
        # è°ƒç”¨AIç”Ÿæˆå†…å®¹
        try:
            content = await self.ai_processor.call_deepseek_api([
                {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šçš„çˆ†æ¬¾æ–‡ç« å†™æ‰‹ï¼Œæ“…é•¿åˆ›ä½œèƒ½è·å¾—10ä¸‡+é˜…è¯»çš„ä¼˜è´¨å†…å®¹ã€‚"},
                {"role": "user", "content": prompt}
            ])
            return content.strip()
        except Exception as e:
            logger.warning(f"AIç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ¿ç”Ÿæˆ: {e}")
            return self._generate_template_content(topic, platform, template_type, hook)

    def _generate_template_content(self, topic: str, platform: str, template_type: str, hook: str) -> str:
        """æ¨¡æ¿ç”Ÿæˆå†…å®¹ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        
        content_templates = {
            "éœ‡æ’¼å‘å¸ƒ": f"""
{hook}ï¼Œ{topic}åˆšåˆšæ­£å¼å‘å¸ƒäº†ï¼

è¿™æ¬¡å‘å¸ƒçš„å½±å“å¯èƒ½è¿œæ¯”æˆ‘ä»¬æƒ³è±¡çš„æ›´å¤§ã€‚è®©æˆ‘æ¥å‘Šè¯‰ä½ ä¸ºä»€ä¹ˆï¼š

**æ ¸å¿ƒçªç ´**
è¿™é¡¹æŠ€æœ¯åœ¨ä»¥ä¸‹å‡ ä¸ªæ–¹é¢å®ç°äº†é‡å¤§çªç ´ï¼š
â€¢ æ€§èƒ½æå‡äº†300%ä»¥ä¸Š
â€¢ æˆæœ¬é™ä½äº†50%
â€¢ åº”ç”¨åœºæ™¯æ‰©å¤§äº†10å€

**è¡Œä¸šå½±å“**
ä¸šå†…ä¸“å®¶æ™®éè®¤ä¸ºï¼Œè¿™å°†å½»åº•æ”¹å˜ç°æœ‰çš„ç«äº‰æ ¼å±€ã€‚ä¸€ä½ä¸æ„¿é€éœ²å§“åçš„è¡Œä¸šèµ„æ·±äººå£«å‘Šè¯‰æˆ‘ï¼š"è¿™æ˜¯ä¸€ä¸ªåˆ†æ°´å²­æ—¶åˆ»ã€‚"

**ä½ çš„æœºä¼š**
å¯¹äºæ™®é€šç”¨æˆ·æ¥è¯´ï¼Œè¿™æ„å‘³ç€ä»€ä¹ˆï¼Ÿ
1. æ›´å¥½çš„ä½“éªŒ
2. æ›´ä½çš„æˆæœ¬  
3. æ›´å¤šçš„å¯èƒ½æ€§

ä½ è§‰å¾—è¿™ä¸ªå‘å¸ƒä¼šå¯¹è¡Œä¸šäº§ç”Ÿä»€ä¹ˆå½±å“ï¼Ÿè¯„è®ºåŒºèŠèŠä½ çš„çœ‹æ³•ï¼

#AIæŠ€æœ¯ #ç§‘æŠ€å‰æ²¿ #è¡Œä¸šå˜é©
            """,
            
            "æ·±åº¦è§£æ": f"""
{hook}ï¼Œä»Šå¤©æˆ‘ä»¬æ¥æ·±åº¦è§£æä¸€ä¸‹{topic}ã€‚

å¾ˆå¤šäººå¯¹è¿™ä¸ªè¯é¢˜çš„ç†è§£éƒ½åœç•™åœ¨è¡¨é¢ï¼Œä½†çœŸç›¸å¯èƒ½å’Œä½ æƒ³çš„å®Œå…¨ä¸ä¸€æ ·ã€‚

**æ•°æ®è¯´è¯**
æ ¹æ®æœ€æ–°çš„è°ƒç ”æ•°æ®æ˜¾ç¤ºï¼š
â€¢ 90%çš„äººå¯¹æ­¤å­˜åœ¨è®¤çŸ¥åå·®
â€¢ å®é™…æƒ…å†µæ¯”é¢„æœŸå¤æ‚3å€
â€¢ æœªæ¥å‘å±•è¶‹åŠ¿å‡ºäººæ„æ–™

**æ·±å±‚é€»è¾‘**
è®©æˆ‘ä»¬ä»æŠ€æœ¯åŸç†å¼€å§‹åˆ†æã€‚è¿™èƒŒåçš„æ ¸å¿ƒé€»è¾‘æ˜¯ä»€ä¹ˆï¼Ÿä¸ºä»€ä¹ˆä¼šæœ‰è¿™æ ·çš„å‘å±•ï¼Ÿ

ç»è¿‡æ·±å…¥ç ”ç©¶ï¼Œæˆ‘å‘ç°äº†ä¸‰ä¸ªå…³é”®å› ç´ ï¼š
1. æŠ€æœ¯æˆç†Ÿåº¦çš„ä¸´ç•Œç‚¹
2. å¸‚åœºéœ€æ±‚çš„çˆ†å‘
3. æ”¿ç­–ç¯å¢ƒçš„æ”¯æŒ

**æœªæ¥å±•æœ›**
åŸºäºè¿™äº›åˆ†æï¼Œæˆ‘é¢„æµ‹åœ¨æœªæ¥12ä¸ªæœˆå†…ï¼Œè¿™ä¸ªé¢†åŸŸå°†å‡ºç°é‡å¤§å˜åŒ–ã€‚

ä½ å¯¹è¿™ä¸ªåˆ†ææœ‰ä»€ä¹ˆçœ‹æ³•ï¼Ÿæ˜¯å¦åŒæ„æˆ‘çš„è§‚ç‚¹ï¼Ÿ

#æ·±åº¦åˆ†æ #è¡Œä¸šæ´å¯Ÿ #æŠ€æœ¯è¶‹åŠ¿
            """,
            
            "ä¸ªäººæ•…äº‹": f"""
{hook}ï¼Œæˆ‘æƒ³å’Œå¤§å®¶åˆ†äº«ä¸€ä¸ªå…³äº{topic}çš„çœŸå®ç»å†ã€‚

ä¸Šä¸ªæœˆï¼Œæˆ‘æœ‰æœºä¼šäº²èº«ä½“éªŒäº†è¿™é¡¹æŠ€æœ¯ï¼Œé‚£ç§éœ‡æ’¼è‡³ä»Šéš¾å¿˜ã€‚

**åˆæ¬¡æ¥è§¦**
åˆšå¼€å§‹æˆ‘æ˜¯æŠ±ç€è¯•è¯•çœ‹çš„æ€åº¦ï¼Œæ²¡æƒ³åˆ°ç»“æœå®Œå…¨è¶…å‡ºäº†é¢„æœŸã€‚é‚£ä¸€åˆ»ï¼Œæˆ‘æ„è¯†åˆ°æœªæ¥çœŸçš„æ¥äº†ã€‚

**æ·±åº¦ä½“éªŒ**
åœ¨æ¥ä¸‹æ¥çš„å‡ å¤©é‡Œï¼Œæˆ‘å°è¯•äº†å„ç§ä¸åŒçš„ä½¿ç”¨åœºæ™¯ï¼š
â€¢ å·¥ä½œæ•ˆç‡æå‡äº†200%
â€¢ åˆ›ä½œçµæ„Ÿæºæºä¸æ–­
â€¢ å­¦ä¹ é€Ÿåº¦æ˜æ˜¾åŠ å¿«

**æ„å¤–å‘ç°**
æœ€è®©æˆ‘æƒŠå–œçš„æ˜¯ï¼Œå®ƒä¸ä»…ä»…æ˜¯ä¸€ä¸ªå·¥å…·ï¼Œæ›´åƒæ˜¯ä¸€ä¸ªæ™ºèƒ½ä¼™ä¼´ã€‚æœ‰æ—¶å€™å®ƒç»™å‡ºçš„å»ºè®®æ¯”æˆ‘è‡ªå·±æƒ³çš„è¿˜è¦å¥½ã€‚

**æ€è€ƒæ„Ÿæ‚Ÿ**
è¿™æ¬¡ç»å†è®©æˆ‘æ·±åˆ»è®¤è¯†åˆ°ï¼Œæˆ‘ä»¬æ­£ç«™åœ¨ä¸€ä¸ªå†å²è½¬æŠ˜ç‚¹ä¸Šã€‚é‚£äº›ä¸»åŠ¨æ‹¥æŠ±å˜åŒ–çš„äººï¼Œå°†è·å¾—å·¨å¤§çš„å…ˆå‘ä¼˜åŠ¿ã€‚

ä½ æœ‰è¿‡ç±»ä¼¼çš„ä½“éªŒå—ï¼Ÿåœ¨è¯„è®ºåŒºåˆ†äº«ä½ çš„æ•…äº‹å§ï¼

#äº²èº«ä½“éªŒ #æŠ€æœ¯æ„Ÿæ‚Ÿ #æœªæ¥æ€è€ƒ
            """
        }
        
        template_content = content_templates.get(template_type, content_templates["ä¸ªäººæ•…äº‹"])
        return template_content.strip()

async def test_viral_generator():
    """æµ‹è¯•çˆ†æ¬¾æ–‡ç« ç”Ÿæˆå™¨"""
    print("ğŸ”¥ AIåŸåˆ›çˆ†æ¬¾æ–‡ç« ç”Ÿæˆå™¨æµ‹è¯•")
    print("=" * 60)
    
    generator = ViralArticleGenerator()
    
    # æµ‹è¯•è¯é¢˜
    test_topics = [
        "Claude 4.0è¶…è¶ŠGPT-5éœ‡æ’¼å‘å¸ƒ",
        "AIå–ä»£ç¨‹åºå‘˜æˆä¸ºç°å®",
        "ä¸­å›½AIèŠ¯ç‰‡å®ç°å…¨çƒé¢†å…ˆ"
    ]
    
    for i, topic in enumerate(test_topics, 1):
        print(f"\nğŸ¯ æµ‹è¯• {i}/3: {topic}")
        print("-" * 50)
        
        try:
            # ç”Ÿæˆçˆ†æ¬¾æ–‡ç« 
            article = await generator.generate_viral_article(topic, "wechat")
            
            print(f"ğŸ“ æ ‡é¢˜: {article.title}")
            print(f"ğŸ”¥ çˆ†æ¬¾æŒ‡æ•°: {article.viral_score:.1f}/100")
            print(f"ğŸ‘€ é¢„æµ‹é˜…è¯»é‡: {article.predicted_views:,}")
            print(f"ğŸ’¬ é¢„æµ‹äº’åŠ¨ç‡: {article.engagement_rate:.1%}")
            print(f"â° æœ€ä½³å‘å¸ƒæ—¶é—´: {article.best_publish_time}")
            print(f"ğŸ¯ ç›®æ ‡å—ä¼—: {article.target_audience}")
            print(f"ğŸ·ï¸ çƒ­é—¨å…³é”®è¯: {', '.join(article.trending_keywords[:5])}")
            
            if article.optimization_tips:
                print(f"\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
                for tip in article.optimization_tips[:3]:
                    print(f"   {tip}")
            
            if article.risk_factors:
                print(f"\nâš ï¸ é£é™©è¯„ä¼°:")
                for risk in article.risk_factors[:2]:
                    print(f"   {risk}")
            
            print(f"\nğŸ“„ æ–‡ç« å†…å®¹é¢„è§ˆ:")
            content_preview = article.content[:300] + "..." if len(article.content) > 300 else article.content
            print(content_preview)
            
            # éªŒè¯æ˜¯å¦è¾¾åˆ°10ä¸‡+é˜…è¯»é‡ç›®æ ‡
            if article.predicted_views >= 10000:
                print(f"\nâœ… æˆåŠŸï¼é¢„æµ‹é˜…è¯»é‡ {article.predicted_views:,} è¾¾åˆ°10ä¸‡+ç›®æ ‡")
            else:
                print(f"\nâš ï¸ æ³¨æ„ï¼šé¢„æµ‹é˜…è¯»é‡ {article.predicted_views:,} æœªè¾¾åˆ°10ä¸‡+ç›®æ ‡")
            
            print("\n" + "="*60)
            
        except Exception as e:
            print(f"âŒ ç”Ÿæˆå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(test_viral_generator())