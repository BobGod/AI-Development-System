"""
ğŸ¨ æ™ºèƒ½å›¾ç‰‡ç”Ÿæˆå’ŒåŒ¹é…ç³»ç»Ÿ
ä¸ºAIæ–°é—»è‡ªåŠ¨ç”Ÿæˆå’ŒåŒ¹é…é«˜è´¨é‡é…å›¾
"""

import asyncio
import aiohttp
import json
import logging
import os
import hashlib
from datetime import datetime
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
import base64
from io import BytesIO
from PIL import Image, ImageDraw, ImageFont
import requests

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ImageStyle(Enum):
    """å›¾ç‰‡é£æ ¼æšä¸¾"""
    PROFESSIONAL = "professional"
    CASUAL = "casual"
    TECH = "tech"
    MODERN = "modern"

@dataclass
class ImageConfig:
    """å›¾ç‰‡é…ç½®"""
    width: int
    height: int
    style: ImageStyle
    format: str = "PNG"
    quality: int = 90

class PlatformImageConfig:
    """ä¸åŒå¹³å°çš„å›¾ç‰‡è§„æ ¼"""
    
    CONFIGS = {
        "wechat": ImageConfig(900, 500, ImageStyle.PROFESSIONAL),
        "xiaohongshu": ImageConfig(1080, 1080, ImageStyle.CASUAL),
        "weibo": ImageConfig(800, 450, ImageStyle.MODERN),
        "thumbnail": ImageConfig(400, 300, ImageStyle.TECH)
    }

@dataclass 
class GeneratedImage:
    """ç”Ÿæˆçš„å›¾ç‰‡ä¿¡æ¯"""
    image_data: bytes
    config: ImageConfig
    prompt: str
    source: str  # "dalle", "stable_diffusion", "unsplash", "generated"
    filename: str
    size_kb: int
    
    def save_to_file(self, directory: str = "generated_images") -> str:
        """ä¿å­˜å›¾ç‰‡åˆ°æ–‡ä»¶"""
        os.makedirs(directory, exist_ok=True)
        filepath = os.path.join(directory, self.filename)
        
        with open(filepath, 'wb') as f:
            f.write(self.image_data)
        
        logger.info(f"ğŸ’¾ å›¾ç‰‡å·²ä¿å­˜: {filepath} ({self.size_kb}KB)")
        return filepath

class AIImageGenerator:
    """AIå›¾ç‰‡ç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        self.unsplash_access_key = os.getenv("UNSPLASH_ACCESS_KEY")
        
        # é¢„å®šä¹‰çš„AIç›¸å…³å›¾ç‰‡æ¨¡æ¿
        self.ai_image_templates = {
            "gpt": {
                "prompt": "modern AI chatbot interface, clean design, blue and white theme, digital brain network, professional tech illustration",
                "style": "digital art, high quality, 8k"
            },
            "robot": {
                "prompt": "futuristic humanoid robot, sleek white design, advanced technology, studio lighting, clean background",
                "style": "product photography, professional"
            },
            "brain": {
                "prompt": "artificial neural network, digital brain, glowing connections, blue purple gradient, sci-fi aesthetic",
                "style": "digital art, cyberpunk, high tech"
            },
            "data": {
                "prompt": "data visualization, flowing data streams, charts and graphs, technology background, modern interface",
                "style": "infographic style, clean, professional"
            },
            "chip": {
                "prompt": "computer microchip, circuit board, electronic components, macro photography, high tech details",
                "style": "product photography, macro lens"
            },
            "autonomous": {
                "prompt": "self-driving car with sensor visualization, LiDAR points, urban environment, future transportation",
                "style": "concept art, realistic, high detail"
            },
            "startup": {
                "prompt": "modern office space, team collaboration, startup environment, innovation, bright lighting",
                "style": "corporate photography, professional"
            },
            "investment": {
                "prompt": "financial growth chart, upward trend, money and technology, success visualization, gold and green colors",
                "style": "business illustration, clean design"
            }
        }

    def get_image_keywords(self, title: str, content: str) -> List[str]:
        """ä»å†…å®¹ä¸­æå–å›¾ç‰‡å…³é”®è¯"""
        text = (title + " " + content).lower()
        keywords = []
        
        # æŠ€æœ¯å…³é”®è¯æ˜ å°„
        keyword_map = {
            "gpt": ["gpt", "chatgpt", "è¯­è¨€æ¨¡å‹"],
            "robot": ["æœºå™¨äºº", "robot", "humanoid"],
            "brain": ["å¤§è„‘", "ç¥ç»", "brain", "neural"],
            "data": ["æ•°æ®", "data", "åˆ†æ", "analytics"],
            "chip": ["èŠ¯ç‰‡", "chip", "å¤„ç†å™¨", "processor"],
            "autonomous": ["è‡ªåŠ¨é©¾é©¶", "autonomous", "self-driving"],
            "startup": ["åˆ›ä¸š", "startup", "å…¬å¸", "å›¢é˜Ÿ"],
            "investment": ["æŠ•èµ„", "èèµ„", "investment", "funding"]
        }
        
        for category, terms in keyword_map.items():
            if any(term in text for term in terms):
                keywords.append(category)
        
        return keywords[:3]  # æœ€å¤š3ä¸ªå…³é”®è¯

    async def generate_with_dalle(self, prompt: str, config: ImageConfig) -> Optional[GeneratedImage]:
        """ä½¿ç”¨DALL-Eç”Ÿæˆå›¾ç‰‡"""
        if not self.openai_api_key:
            logger.warning("æœªè®¾ç½®OpenAI APIå¯†é’¥ï¼Œè·³è¿‡DALL-Eç”Ÿæˆ")
            return None
        
        try:
            headers = {
                "Authorization": f"Bearer {self.openai_api_key}",
                "Content-Type": "application/json"
            }
            
            payload = {
                "model": "dall-e-3",
                "prompt": prompt,
                "n": 1,
                "size": f"{config.width}x{config.height}",
                "quality": "hd",
                "response_format": "b64_json"
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    "https://api.openai.com/v1/images/generations",
                    headers=headers,
                    json=payload,
                    timeout=60
                ) as response:
                    
                    if response.status == 200:
                        result = await response.json()
                        image_b64 = result["data"][0]["b64_json"]
                        image_data = base64.b64decode(image_b64)
                        
                        filename = f"dalle_{hashlib.md5(prompt.encode()).hexdigest()[:8]}.png"
                        
                        return GeneratedImage(
                            image_data=image_data,
                            config=config,
                            prompt=prompt,
                            source="dalle",
                            filename=filename,
                            size_kb=len(image_data) // 1024
                        )
                    else:
                        logger.error(f"DALL-E APIè°ƒç”¨å¤±è´¥: {response.status}")
                        return None
                        
        except Exception as e:
            logger.error(f"DALL-Eç”Ÿæˆå¤±è´¥: {e}")
            return None

    async def search_unsplash(self, query: str, config: ImageConfig) -> Optional[GeneratedImage]:
        """ä»Unsplashæœç´¢å›¾ç‰‡"""
        if not self.unsplash_access_key:
            logger.warning("æœªè®¾ç½®Unsplash APIå¯†é’¥ï¼Œè·³è¿‡å›¾ç‰‡æœç´¢")
            return None
        
        try:
            headers = {
                "Authorization": f"Client-ID {self.unsplash_access_key}"
            }
            
            params = {
                "query": query,
                "per_page": 5,
                "orientation": "landscape" if config.width > config.height else "portrait"
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    "https://api.unsplash.com/search/photos",
                    headers=headers,
                    params=params
                ) as response:
                    
                    if response.status == 200:
                        result = await response.json()
                        if result["results"]:
                            photo = result["results"][0]
                            image_url = photo["urls"]["regular"]
                            
                            # ä¸‹è½½å›¾ç‰‡
                            async with session.get(image_url) as img_response:
                                if img_response.status == 200:
                                    image_data = await img_response.read()
                                    
                                    # è°ƒæ•´å›¾ç‰‡å°ºå¯¸
                                    image_data = self.resize_image(image_data, config)
                                    
                                    filename = f"unsplash_{photo['id']}.jpg"
                                    
                                    return GeneratedImage(
                                        image_data=image_data,
                                        config=config,
                                        prompt=query,
                                        source="unsplash",
                                        filename=filename,
                                        size_kb=len(image_data) // 1024
                                    )
        except Exception as e:
            logger.error(f"Unsplashæœç´¢å¤±è´¥: {e}")
            return None

    def resize_image(self, image_data: bytes, config: ImageConfig) -> bytes:
        """è°ƒæ•´å›¾ç‰‡å°ºå¯¸"""
        try:
            with Image.open(BytesIO(image_data)) as img:
                # è°ƒæ•´å°ºå¯¸ä¿æŒæ¯”ä¾‹
                img.thumbnail((config.width, config.height), Image.Resampling.LANCZOS)
                
                # åˆ›å»ºæŒ‡å®šå°ºå¯¸çš„èƒŒæ™¯
                background = Image.new('RGB', (config.width, config.height), (255, 255, 255))
                
                # å±…ä¸­æ”¾ç½®å›¾ç‰‡
                x = (config.width - img.width) // 2
                y = (config.height - img.height) // 2
                background.paste(img, (x, y))
                
                # è½¬æ¢ä¸ºbytes
                output = BytesIO()
                background.save(output, format=config.format, quality=config.quality)
                return output.getvalue()
                
        except Exception as e:
            logger.error(f"å›¾ç‰‡å°ºå¯¸è°ƒæ•´å¤±è´¥: {e}")
            return image_data

    def extract_english_keywords(self, text: str) -> str:
        """ä»ä¸­æ–‡æ–°é—»æ ‡é¢˜ä¸­æå–è‹±æ–‡å…³é”®è¯"""
        # å¸¸è§AIä¸­è‹±æ–‡å¯¹ç…§è¯å…¸
        keyword_mapping = {
            "GPT": "GPT",
            "ChatGPT": "ChatGPT", 
            "OpenAI": "OpenAI",
            "AI": "AI",
            "äººå·¥æ™ºèƒ½": "Artificial Intelligence",
            "æœºå™¨å­¦ä¹ ": "Machine Learning",
            "æ·±åº¦å­¦ä¹ ": "Deep Learning",
            "ç¥ç»ç½‘ç»œ": "Neural Network",
            "å¤§æ¨¡å‹": "Large Language Model",
            "LLM": "LLM",
            "æ¨¡å‹": "Model",
            "ç®—æ³•": "Algorithm",
            "æ•°æ®": "Data",
            "è®­ç»ƒ": "Training",
            "æ¨ç†": "Inference",
            "ç”Ÿæˆ": "Generation",
            "å¯¹è¯": "Conversation",
            "èŠå¤©": "Chat",
            "æœºå™¨äºº": "Robot",
            "è‡ªåŠ¨é©¾é©¶": "Autonomous Driving",
            "è®¡ç®—æœºè§†è§‰": "Computer Vision",
            "è‡ªç„¶è¯­è¨€": "Natural Language",
            "è¯­éŸ³": "Speech",
            "å›¾åƒ": "Image",
            "è§†é¢‘": "Video",
            "æ–‡æœ¬": "Text",
            "ä»£ç ": "Code",
            "ç¼–ç¨‹": "Programming",
            "è½¯ä»¶": "Software",
            "æŠ€æœ¯": "Technology",
            "ç§‘æŠ€": "Tech",
            "åˆ›æ–°": "Innovation",
            "å‘å¸ƒ": "Release",
            "æ›´æ–°": "Update",
            "å‡çº§": "Upgrade",
            "çªç ´": "Breakthrough",
            "é©å‘½": "Revolution",
            "æœªæ¥": "Future",
            "æ™ºèƒ½": "Intelligence",
            "ç³»ç»Ÿ": "System",
            "å¹³å°": "Platform",
            "åº”ç”¨": "Application",
            "å·¥å…·": "Tool",
            "æœåŠ¡": "Service",
            "äº‘": "Cloud",
            "è¾¹ç¼˜": "Edge",
            "ç‰©è”ç½‘": "IoT",
            "åŒºå—é“¾": "Blockchain",
            "å…ƒå®‡å®™": "Metaverse",
            "VR": "VR",
            "AR": "AR",
            "èŠ¯ç‰‡": "Chip",
            "å¤„ç†å™¨": "Processor",
            "GPU": "GPU",
            "CPU": "CPU",
            "é‡å­": "Quantum",
            "5G": "5G",
            "6G": "6G"
        }
        
        # æå–å·²æœ‰çš„è‹±æ–‡è¯æ±‡
        import re
        english_words = re.findall(r'[A-Za-z0-9]+', text)
        result_words = []
        
        # æ·»åŠ è‹±æ–‡è¯æ±‡
        for word in english_words:
            if len(word) > 1:  # æ’é™¤å•ä¸ªå­—æ¯
                result_words.append(word)
        
        # æ ¹æ®ä¸­æ–‡å†…å®¹æ·»åŠ å¯¹åº”è‹±æ–‡è¯æ±‡
        for chinese, english in keyword_mapping.items():
            if chinese in text and english not in result_words:
                result_words.append(english)
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å…³é”®è¯ï¼Œä½¿ç”¨é»˜è®¤çš„
        if not result_words:
            result_words = ["AI", "Technology", "Innovation"]
        
        return " â€¢ ".join(result_words[:3])  # æœ€å¤š3ä¸ªå…³é”®è¯ï¼Œç”¨ç‚¹åˆ†éš”

    def generate_text_image(self, text: str, config: ImageConfig) -> GeneratedImage:
        """ç”Ÿæˆæ–‡å­—å›¾ç‰‡ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰- ä½¿ç”¨è‹±æ–‡é¿å…ä¸­æ–‡ä¹±ç """
        try:
            # åˆ›å»ºå›¾ç‰‡
            img = Image.new('RGB', (config.width, config.height), (45, 55, 72))  # æ·±è“ç°è‰²èƒŒæ™¯
            draw = ImageDraw.Draw(img)
            
            # å°è¯•åŠ è½½å­—ä½“
            try:
                # æ ¹æ®ç³»ç»Ÿé€‰æ‹©å­—ä½“
                if os.name == 'nt':  # Windows
                    font_large = ImageFont.truetype("arial.ttf", 48)
                    font_small = ImageFont.truetype("arial.ttf", 24)
                else:  # macOS/Linux
                    try:
                        font_large = ImageFont.truetype("/System/Library/Fonts/Arial.ttf", 48)
                        font_small = ImageFont.truetype("/System/Library/Fonts/Arial.ttf", 24)
                    except:
                        font_large = ImageFont.load_default()
                        font_small = ImageFont.load_default()
            except:
                font_large = ImageFont.load_default()
                font_small = ImageFont.load_default()
            
            # ç»˜åˆ¶ä¸»æ ‡é¢˜ - ä½¿ç”¨è‹±æ–‡
            main_text = "AI News"
            try:
                bbox = draw.textbbox((0, 0), main_text, font=font_large)
                text_width = bbox[2] - bbox[0]
                text_height = bbox[3] - bbox[1]
            except:
                text_width = len(main_text) * 20
                text_height = 48
            
            x = (config.width - text_width) // 2
            y = config.height // 2 - 50
            
            draw.text((x, y), main_text, fill=(255, 255, 255), font=font_large)
            
            # ç»˜åˆ¶å‰¯æ ‡é¢˜ - ä½¿ç”¨æå–çš„è‹±æ–‡å…³é”®è¯
            sub_text = self.extract_english_keywords(text)
            try:
                bbox = draw.textbbox((0, 0), sub_text, font=font_small)
                text_width = bbox[2] - bbox[0]
            except:
                text_width = len(sub_text) * 12
            
            x = (config.width - text_width) // 2
            y = config.height // 2 + 20
            
            draw.text((x, y), sub_text, fill=(156, 163, 175), font=font_small)
            
            # æ·»åŠ è£…é¥°å…ƒç´ 
            draw.rectangle([(50, config.height - 80), (config.width - 50, config.height - 75)], 
                         fill=(59, 130, 246))  # è“è‰²è£…é¥°æ¡
            
            # è½¬æ¢ä¸ºbytes
            output = BytesIO()
            img.save(output, format=config.format, quality=config.quality)
            image_data = output.getvalue()
            
            filename = f"text_{hashlib.md5(text.encode()).hexdigest()[:8]}.png"
            
            return GeneratedImage(
                image_data=image_data,
                config=config,
                prompt=f"Text image: {sub_text}",
                source="generated",
                filename=filename,
                size_kb=len(image_data) // 1024
            )
            
        except Exception as e:
            logger.error(f"æ–‡å­—å›¾ç‰‡ç”Ÿæˆå¤±è´¥: {e}")
            # è¿”å›æœ€ç®€å•çš„å›¾ç‰‡
            try:
                img = Image.new('RGB', (config.width, config.height), (45, 55, 72))
                output = BytesIO()
                img.save(output, format='PNG')
                return GeneratedImage(
                    image_data=output.getvalue(),
                    config=config,
                    prompt="Simple image",
                    source="generated",
                    filename="simple.png",
                    size_kb=len(output.getvalue()) // 1024
                )
            except:
                # æœ€åçš„å…œåº•æ–¹æ¡ˆ
                empty_data = b'\x89PNG\r\n\x1a\n\x00\x00\x00\rIHDR\x00\x00\x01\x00\x00\x00\x01\x00\x08\x02\x00\x00\x00\x90wS\xde\x00\x00\x00\tpHYs\x00\x00\x0b\x13\x00\x00\x0b\x13\x01\x00\x9a\x9c\x18\x00\x00\x00\x17IDAT\x08\x1dc```bPPP\x00\x02\xac\xac\xac\x00\x05\x06\x06\x06\x00\x00\x00\x00\x00\x01?\x1e\x99\x85\x00\x00\x00\x00IEND\xaeB`\x82'
                return GeneratedImage(
                    image_data=empty_data,
                    config=config,
                    prompt="Empty image",
                    source="generated",
                    filename="empty.png",
                    size_kb=1
                )

    async def generate_image_for_news(self, title: str, content: str, platform: str = "wechat") -> GeneratedImage:
        """ä¸ºæ–°é—»ç”Ÿæˆé…å›¾"""
        config = PlatformImageConfig.CONFIGS[platform]
        keywords = self.get_image_keywords(title, content)
        
        logger.info(f"ğŸ¨ ä¸ºæ–°é—»ç”Ÿæˆé…å›¾: {title[:30]}... -> {platform}")
        logger.info(f"   å…³é”®è¯: {keywords}")
        
        # é€‰æ‹©æœ€ä½³æ¨¡æ¿
        if keywords:
            template_key = keywords[0]
            template = self.ai_image_templates.get(template_key, self.ai_image_templates["brain"])
        else:
            template = self.ai_image_templates["brain"]
        
        # æ„å»ºå®Œæ•´æç¤ºè¯
        full_prompt = f"{template['prompt']}, {template['style']}"
        
        # å°è¯•å¤šç§ç”Ÿæˆæ–¹å¼
        image = None
        
        # 1. å°è¯•DALL-Eç”Ÿæˆ
        if not image:
            image = await self.generate_with_dalle(full_prompt, config)
        
        # 2. å°è¯•Unsplashæœç´¢
        if not image:
            search_query = " ".join(keywords) if keywords else "artificial intelligence technology"
            image = await self.search_unsplash(search_query, config)
        
        # 3. ç”Ÿæˆæ–‡å­—å›¾ç‰‡ä½œä¸ºå¤‡ç”¨
        if not image:
            logger.warning("æ‰€æœ‰å›¾ç‰‡ç”Ÿæˆæ–¹å¼å¤±è´¥ï¼Œä½¿ç”¨æ–‡å­—å›¾ç‰‡")
            image = self.generate_text_image(title, config)
        
        logger.info(f"âœ… é…å›¾ç”Ÿæˆå®Œæˆ: {image.source} - {image.size_kb}KB")
        return image

    async def batch_generate_images(self, news_data: List[Dict], platforms: List[str] = None) -> Dict[str, List[GeneratedImage]]:
        """æ‰¹é‡ç”Ÿæˆå›¾ç‰‡"""
        if platforms is None:
            platforms = ["wechat", "xiaohongshu"]
        
        results = {platform: [] for platform in platforms}
        tasks = []
        
        # åˆ›å»ºä»»åŠ¡
        for news in news_data[:10]:  # é™åˆ¶å¤„ç†æ•°é‡
            for platform in platforms:
                task = self.generate_image_for_news(news["title"], news["content"], platform)
                tasks.append((task, news, platform))
        
        logger.info(f"ğŸš€ å¼€å§‹æ‰¹é‡ç”Ÿæˆå›¾ç‰‡: {len(news_data)}æ¡æ–°é—» x {len(platforms)}ä¸ªå¹³å°")
        
        # æ‰§è¡Œä»»åŠ¡
        for task, news, platform in tasks:
            try:
                image = await task
                results[platform].append({
                    "news_title": news["title"],
                    "image": image
                })
            except Exception as e:
                logger.error(f"å›¾ç‰‡ç”Ÿæˆå¤±è´¥: {e}")
        
        logger.info(f"âœ… æ‰¹é‡å›¾ç‰‡ç”Ÿæˆå®Œæˆ!")
        return results

    def save_generated_images(self, results: Dict[str, List[GeneratedImage]], base_dir: str = "generated_images"):
        """ä¿å­˜ç”Ÿæˆçš„å›¾ç‰‡"""
        saved_files = {}
        
        for platform, images in results.items():
            platform_dir = os.path.join(base_dir, platform)
            os.makedirs(platform_dir, exist_ok=True)
            
            saved_files[platform] = []
            
            for item in images:
                if isinstance(item, dict) and "image" in item:
                    image = item["image"]
                    filepath = image.save_to_file(platform_dir)
                    saved_files[platform].append({
                        "news_title": item["news_title"],
                        "filepath": filepath,
                        "filename": image.filename,
                        "source": image.source,
                        "size_kb": image.size_kb
                    })
        
        # ä¿å­˜ç´¢å¼•æ–‡ä»¶
        index_file = os.path.join(base_dir, "image_index.json")
        with open(index_file, 'w', encoding='utf-8') as f:
            json.dump({
                "generated_time": datetime.now().isoformat(),
                "platforms": saved_files
            }, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ“‹ å›¾ç‰‡ç´¢å¼•å·²ä¿å­˜: {index_file}")
        return saved_files

# æµ‹è¯•å‡½æ•°
async def test_image_generator():
    """æµ‹è¯•å›¾ç‰‡ç”Ÿæˆå™¨"""
    generator = AIImageGenerator()
    
    # æµ‹è¯•æ–°é—»æ•°æ®
    test_news = [
        {
            "title": "GPT-5å³å°†å‘å¸ƒï¼OpenAIå†…éƒ¨æ¶ˆæ¯æ›å…‰æ€§èƒ½æå‡300%",
            "content": "æ®å¯é æ¶ˆæ¯æºé€éœ²ï¼ŒOpenAIçš„ä¸‹ä¸€ä»£å¤§è¯­è¨€æ¨¡å‹GPT-5å·²è¿›å…¥æœ€åæµ‹è¯•é˜¶æ®µï¼Œæ€§èƒ½ç›¸æ¯”GPT-4æœ‰æ˜¾è‘—æå‡..."
        },
        {
            "title": "è°·æ­Œå‘å¸ƒæ–°æ¬¾AIæœºå™¨äººï¼Œè‡ªä¸»å­¦ä¹ èƒ½åŠ›éœ‡æ’¼ä¸šç•Œ", 
            "content": "è°·æ­Œæœ€æ–°å‘å¸ƒçš„äººå½¢æœºå™¨äººå…·å¤‡å¼ºå¤§çš„è‡ªä¸»å­¦ä¹ èƒ½åŠ›ï¼Œèƒ½å¤Ÿåœ¨å¤æ‚ç¯å¢ƒä¸­æ‰§è¡Œå„ç§ä»»åŠ¡..."
        },
        {
            "title": "å­—èŠ‚è·³åŠ¨AIèŠ¯ç‰‡é¡¹ç›®è·50äº¿èèµ„ï¼Œä¼°å€¼è¾¾åƒäº¿",
            "content": "å­—èŠ‚è·³åŠ¨æ——ä¸‹AIèŠ¯ç‰‡é¡¹ç›®è·å¾—æ–°ä¸€è½®èèµ„ï¼ŒæŠ•èµ„æ–¹åŒ…æ‹¬å¤šå®¶çŸ¥åæŠ•èµ„æœºæ„..."
        }
    ]
    
    # ç”Ÿæˆå›¾ç‰‡
    results = await generator.batch_generate_images(test_news)
    
    # ä¿å­˜å›¾ç‰‡
    saved_files = generator.save_generated_images(results)
    
    # å±•ç¤ºç»“æœ
    print("\nğŸ¨ å›¾ç‰‡ç”Ÿæˆç»“æœ:")
    print("=" * 80)
    
    for platform, images in saved_files.items():
        print(f"\nğŸ“± {platform.upper()} å¹³å°å›¾ç‰‡:")
        print("-" * 60)
        
        for item in images:
            print(f"æ–°é—»: {item['news_title'][:50]}...")
            print(f"æ–‡ä»¶: {item['filename']} ({item['size_kb']}KB)")
            print(f"æ¥æº: {item['source']}")
            print(f"è·¯å¾„: {item['filepath']}")
            print()

if __name__ == "__main__":
    asyncio.run(test_image_generator())