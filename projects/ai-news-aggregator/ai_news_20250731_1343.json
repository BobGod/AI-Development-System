{
  "collected_time": "2025-07-31T13:43:03.058912",
  "total_count": 47,
  "news_items": [
    {
      "title": "GPT-5泄露！首次统一GPT和o系列，实测demo抢先曝光，下周发布？",
      "content": "可能免费开放",
      "url": "https://www.qbitai.com/2025/07/315960.html",
      "source": "量子位",
      "published_time": "2025-07-31 04:54:48",
      "author": "明敏",
      "tags": [],
      "heat_score": 100,
      "content_type": "article",
      "language": "zh",
      "summary": ""
    },
    {
      "title": "凌晨，Qwen又更新了，3090就能跑，3B激活媲美GPT-4o",
      "content": "",
      "url": "https://www.jiqizhixin.com/articles/2025-07-30-2",
      "source": "机器之心",
      "published_time": "2025-07-30 02:20:20",
      "author": "机器之心",
      "tags": [],
      "heat_score": 50.0,
      "content_type": "article",
      "language": "zh",
      "summary": ""
    },
    {
      "title": "刚刚，OpenAI推出学习模式，AI教师真来了，系统提示词已泄露",
      "content": "",
      "url": "https://www.jiqizhixin.com/articles/2025-07-30-3",
      "source": "机器之心",
      "published_time": "2025-07-30 02:28:36",
      "author": "机器之心",
      "tags": [],
      "heat_score": 45.0,
      "content_type": "article",
      "language": "zh",
      "summary": ""
    },
    {
      "title": "OpenAI launches Study Mode in ChatGPT",
      "content": "OpenAI's Study Mode aims to help students develop their own critical thinking skills, rather than just giving answers.",
      "url": "https://techcrunch.com/2025/07/29/openai-launches-study-mode-in-chatgpt/",
      "source": "TechCrunch AI",
      "published_time": "2025-07-29 17:00:00",
      "author": "Maxwell Zeff",
      "tags": [],
      "heat_score": 45.0,
      "content_type": "article",
      "language": "en",
      "summary": ""
    },
    {
      "title": "1.5B刷新数学代码SOTA！快手&清华精细化Token管理，LLM推理能力飙升",
      "content": "“怎么学”可能比“学了多少”更重要",
      "url": "https://www.qbitai.com/2025/07/315941.html",
      "source": "量子位",
      "published_time": "2025-07-31 04:13:29",
      "author": "不圆",
      "tags": [],
      "heat_score": 40.0,
      "content_type": "article",
      "language": "zh",
      "summary": ""
    },
    {
      "title": "15.8万全尺寸人形抱回家！逐际动力让具身机器人也有经济适用款：31自由度，二开友好度拉满",
      "content": "看国产人形机器人“大展鸿图”",
      "url": "https://www.qbitai.com/2025/07/315891.html",
      "source": "量子位",
      "published_time": "2025-07-31 02:53:36",
      "author": "衡宇",
      "tags": [],
      "heat_score": 40.0,
      "content_type": "article",
      "language": "zh",
      "summary": ""
    },
    {
      "title": "全国首个“AI+玩具”产业基地！由商汤科技与汕头市澄海区共建",
      "content": "签署战略合作协议",
      "url": "https://www.qbitai.com/2025/07/315809.html",
      "source": "量子位",
      "published_time": "2025-07-30 13:56:10",
      "author": "十三",
      "tags": [],
      "heat_score": 40.0,
      "content_type": "article",
      "language": "zh",
      "summary": ""
    },
    {
      "title": "WAIC UP! 之夜：一场关于AI与人类未来的星空思辨",
      "content": "",
      "url": "https://www.jiqizhixin.com/articles/2025-07-31-4",
      "source": "机器之心",
      "published_time": "2025-07-31 04:05:09",
      "author": "新闻助手",
      "tags": [],
      "heat_score": 40.0,
      "content_type": "article",
      "language": "zh",
      "summary": ""
    },
    {
      "title": "把指纹焊死在频率上：抗微调神经网络指纹的硬核方案来了",
      "content": "",
      "url": "https://www.jiqizhixin.com/articles/2025-07-31-2",
      "source": "机器之心",
      "published_time": "2025-07-31 02:24:20",
      "author": "机器之心",
      "tags": [],
      "heat_score": 40.0,
      "content_type": "article",
      "language": "zh",
      "summary": ""
    },
    {
      "title": "When Truthful Representations Flip Under Deceptive Instructions?",
      "content": "arXiv:2507.22149v1 Announce Type: new \nAbstract: Large language models (LLMs) tend to follow maliciously crafted instructions to generate deceptive responses, posing safety challenges. How deceptive instructions alter the internal representations of LLM compared to truthful ones remains poorly understood beyond output analysis. To bridge this gap, we investigate when and how these representations ``flip'', such as from truthful to deceptive, under deceptive versus truthful/neutral instructions. Analyzing the internal representations of Llama-3.1-8B-Instruct and Gemma-2-9B-Instruct on a factual verification task, we find the model's instructed True/False output is predictable via linear probes across all conditions based on the internal representation. Further, we use Sparse Autoencoders (SAEs) to show that the Deceptive instructions induce significant representational shifts compared to Truthful/Neutral representations (which are similar), concentrated in early-to-mid layers and detectable even on complex datasets. We also identify specific SAE features highly sensitive to deceptive instruction and use targeted visualizations to confirm distinct truthful/deceptive representational subspaces. % Our analysis pinpoints layer-wise and feature-level correlates of instructed dishonesty, offering insights for LLM detection and control. Our findings expose feature- and layer-level signatures of deception, offering new insights for detecting and mitigating instructed dishonesty in LLMs.",
      "url": "https://arxiv.org/abs/2507.22149",
      "source": "arXiv AI",
      "published_time": "2025-07-31 04:00:00",
      "author": "Xianxuan Long, Yao Fu, Runchao Li, Mu Sheng, Haotian Yu, Xiaotian Han, Pan Li",
      "tags": [],
      "heat_score": 35.0,
      "content_type": "paper",
      "language": "en",
      "summary": ""
    },
    {
      "title": "Explainability Through Systematicity: The Hard Systematicity Challenge for Artificial Intelligence",
      "content": "arXiv:2507.22197v1 Announce Type: new \nAbstract: This paper argues that explainability is only one facet of a broader ideal that shapes our expectations towards artificial intelligence (AI). Fundamentally, the issue is to what extent AI exhibits systematicity--not merely in being sensitive to how thoughts are composed of recombinable constituents, but in striving towards an integrated body of thought that is consistent, coherent, comprehensive, and parsimoniously principled. This richer conception of systematicity has been obscured by the long shadow of the \"systematicity challenge\" to connectionism, according to which network architectures are fundamentally at odds with what Fodor and colleagues termed \"the systematicity of thought.\" I offer a conceptual framework for thinking about \"the systematicity of thought\" that distinguishes four senses of the phrase. I use these distinctions to defuse the perceived tension between systematicity and connectionism and show that the conception of systematicity that historically shaped our sense of what makes thought rational, authoritative, and scientific is more demanding than the Fodorian notion. To determine whether we have reason to hold AI models to this ideal of systematicity, I then argue, we must look to the rationales for systematization and explore to what extent they transfer to AI models. I identify five such rationales and apply them to AI. This brings into view the \"hard systematicity challenge.\" However, the demand for systematization itself needs to be regulated by the rationales for systematization. This yields a dynamic understanding of the need to systematize thought, which tells us how systematic we need AI models to be and when.",
      "url": "https://arxiv.org/abs/2507.22197",
      "source": "arXiv AI",
      "published_time": "2025-07-31 04:00:00",
      "author": "Matthieu Queloz",
      "tags": [],
      "heat_score": 35.0,
      "content_type": "paper",
      "language": "en",
      "summary": ""
    },
    {
      "title": "CoEx -- Co-evolving World-model and Exploration",
      "content": "arXiv:2507.22281v1 Announce Type: new \nAbstract: Planning in modern LLM agents relies on the utilization of LLM as an internal world model, acquired during pretraining. However, existing agent designs fail to effectively assimilate new observations into dynamic updates of the world model. This reliance on the LLM's static internal world model is progressively prone to misalignment with the underlying true state of the world, leading to the generation of divergent and erroneous plans. We introduce a hierarchical agent architecture, CoEx, in which hierarchical state abstraction allows LLM planning to co-evolve with a dynamically updated model of the world. CoEx plans and interacts with the world by using LLM reasoning to orchestrate dynamic plans consisting of subgoals, and its learning mechanism continuously incorporates these subgoal experiences into a persistent world model in the form of a neurosymbolic belief state, comprising textual inferences and code-based symbolic memory. We evaluate our agent across a diverse set of agent scenarios involving rich environments and complex tasks including ALFWorld, PDDL, and Jericho. Our experiments show that CoEx outperforms existing agent paradigms in planning and exploration.",
      "url": "https://arxiv.org/abs/2507.22281",
      "source": "arXiv AI",
      "published_time": "2025-07-31 04:00:00",
      "author": "Minsoo Kim, Seung-won Hwang",
      "tags": [],
      "heat_score": 35.0,
      "content_type": "paper",
      "language": "en",
      "summary": ""
    },
    {
      "title": "An Explainable Emotion Alignment Framework for LLM-Empowered Agent in Metaverse Service Ecosystem",
      "content": "arXiv:2507.22326v1 Announce Type: new \nAbstract: Metaverse service is a product of the convergence between Metaverse and service systems, designed to address service-related challenges concerning digital avatars, digital twins, and digital natives within Metaverse. With the rise of large language models (LLMs), agents now play a pivotal role in Metaverse service ecosystem, serving dual functions: as digital avatars representing users in the virtual realm and as service assistants (or NPCs) providing personalized support. However, during the modeling of Metaverse service ecosystems, existing LLM-based agents face significant challenges in bridging virtual-world services with real-world services, particularly regarding issues such as character data fusion, character knowledge association, and ethical safety concerns. This paper proposes an explainable emotion alignment framework for LLM-based agents in Metaverse Service Ecosystem. It aims to integrate factual factors into the decision-making loop of LLM-based agents, systematically demonstrating how to achieve more relational fact alignment for these agents. Finally, a simulation experiment in the Offline-to-Offline food delivery scenario is conducted to evaluate the effectiveness of this framework, obtaining more realistic social emergence.",
      "url": "https://arxiv.org/abs/2507.22326",
      "source": "arXiv AI",
      "published_time": "2025-07-31 04:00:00",
      "author": "Qun Ma, Xiao Xue, Ming Zhang, Yifan Shen, Zihan Zhao",
      "tags": [],
      "heat_score": 35.0,
      "content_type": "paper",
      "language": "en",
      "summary": ""
    },
    {
      "title": "Magentic-UI: Towards Human-in-the-loop Agentic Systems",
      "content": "arXiv:2507.22358v1 Announce Type: new \nAbstract: AI agents powered by large language models are increasingly capable of autonomously completing complex, multi-step tasks using external tools. Yet, they still fall short of human-level performance in most domains including computer use, software development, and research. Their growing autonomy and ability to interact with the outside world, also introduces safety and security risks including potentially misaligned actions and adversarial manipulation. We argue that human-in-the-loop agentic systems offer a promising path forward, combining human oversight and control with AI efficiency to unlock productivity from imperfect systems. We introduce Magentic-UI, an open-source web interface for developing and studying human-agent interaction. Built on a flexible multi-agent architecture, Magentic-UI supports web browsing, code execution, and file manipulation, and can be extended with diverse tools via Model Context Protocol (MCP). Moreover, Magentic-UI presents six interaction mechanisms for enabling effective, low-cost human involvement: co-planning, co-tasking, multi-tasking, action guards, and long-term memory. We evaluate Magentic-UI across four dimensions: autonomous task completion on agentic benchmarks, simulated user testing of its interaction capabilities, qualitative studies with real users, and targeted safety assessments. Our findings highlight Magentic-UI's potential to advance safe and efficient human-agent collaboration.",
      "url": "https://arxiv.org/abs/2507.22358",
      "source": "arXiv AI",
      "published_time": "2025-07-31 04:00:00",
      "author": "Hussein Mozannar, Gagan Bansal, Cheng Tan, Adam Fourney, Victor Dibia, Jingya Chen, Jack Gerrits, Tyler Payne, Matheus Kunzler Maldaner, Madeleine Grunde-McLaughlin, Eric Zhu, Griffin Bassman, Jacob Alber, Peter Chang, Ricky Loynd, Friederike Niedtner, Ece Kamar, Maya Murad, Rafah Hosn, Saleema Amershi",
      "tags": [],
      "heat_score": 35.0,
      "content_type": "paper",
      "language": "en",
      "summary": ""
    },
    {
      "title": "LLM-Crowdsourced: A Benchmark-Free Paradigm for Mutual Evaluation of Large Language Models",
      "content": "arXiv:2507.22359v1 Announce Type: new \nAbstract: Although large language models (LLMs) demonstrate remarkable capabilities across various tasks, evaluating their capabilities remains a challenging task. Existing evaluation methods suffer from issues such as data contamination, black-box operation, and subjective preference. These issues make it difficult to evaluate the LLMs' true capabilities comprehensively. To tackle these challenges, we propose a novel benchmark-free evaluation paradigm, LLM-Crowdsourced. It utilizes LLMs to generate questions, answer independently, and evaluate mutually. This method integrates four key evaluation criteria: dynamic, transparent, objective, and professional, which existing evaluation methods cannot satisfy simultaneously. Experiments on eight mainstream LLMs across mathematics and programming verify the advantages of our method in distinguishing LLM performance. Furthermore, our study reveals several novel findings that are difficult for traditional methods to detect, including but not limited to: (1) Gemini demonstrates the highest original and professional question-design capabilities among others; (2) Some LLMs exhibit ''memorization-based answering'' by misrecognizing questions as familiar ones with a similar structure; (3) LLM evaluation results demonstrate high consistency (robustness).",
      "url": "https://arxiv.org/abs/2507.22359",
      "source": "arXiv AI",
      "published_time": "2025-07-31 04:00:00",
      "author": "Qianhong Guo, Wei Xie, Xiaofang Cai, Enze Wang, Shuoyoucheng Ma, Kai Chen, Xiaofeng Wang, Baosheng Wang",
      "tags": [],
      "heat_score": 35.0,
      "content_type": "paper",
      "language": "en",
      "summary": ""
    },
    {
      "title": "Beyond Accuracy: How AI Metacognitive Sensitivity improves AI-assisted Decision Making",
      "content": "arXiv:2507.22365v1 Announce Type: new \nAbstract: In settings where human decision-making relies on AI input, both the predictive accuracy of the AI system and the reliability of its confidence estimates influence decision quality. We highlight the role of AI metacognitive sensitivity -- its ability to assign confidence scores that accurately distinguish correct from incorrect predictions -- and introduce a theoretical framework for assessing the joint impact of AI's predictive accuracy and metacognitive sensitivity in hybrid decision-making settings. Our analysis identifies conditions under which an AI with lower predictive accuracy but higher metacognitive sensitivity can enhance the overall accuracy of human decision making. Finally, a behavioral experiment confirms that greater AI metacognitive sensitivity improves human decision performance. Together, these findings underscore the importance of evaluating AI assistance not only by accuracy but also by metacognitive sensitivity, and of optimizing both to achieve superior decision outcomes.",
      "url": "https://arxiv.org/abs/2507.22365",
      "source": "arXiv AI",
      "published_time": "2025-07-31 04:00:00",
      "author": "ZhaoBin Li, Mark Steyvers",
      "tags": [],
      "heat_score": 35.0,
      "content_type": "paper",
      "language": "en",
      "summary": ""
    },
    {
      "title": "Nearest-Better Network for Visualizing and Analyzing Combinatorial Optimization Problems: A Unified Tool",
      "content": "arXiv:2507.22440v1 Announce Type: new \nAbstract: The Nearest-Better Network (NBN) is a powerful method to visualize sampled data for continuous optimization problems while preserving multiple landscape features. However, the calculation of NBN is very time-consuming, and the extension of the method to combinatorial optimization problems is challenging but very important for analyzing the algorithm's behavior. This paper provides a straightforward theoretical derivation showing that the NBN network essentially functions as the maximum probability transition network for algorithms. This paper also presents an efficient NBN computation method with logarithmic linear time complexity to address the time-consuming issue. By applying this efficient NBN algorithm to the OneMax problem and the Traveling Salesman Problem (TSP), we have made several remarkable discoveries for the first time: The fitness landscape of OneMax exhibits neutrality, ruggedness, and modality features. The primary challenges of TSP problems are ruggedness, modality, and deception. Two state-of-the-art TSP algorithms (i.e., EAX and LKH) have limitations when addressing challenges related to modality and deception, respectively. LKH, based on local search operators, fails when there are deceptive solutions near global optima. EAX, which is based on a single population, can efficiently maintain diversity. However, when multiple attraction basins exist, EAX retains individuals within multiple basins simultaneously, reducing inter-basin interaction efficiency and leading to algorithm's stagnation.",
      "url": "https://arxiv.org/abs/2507.22440",
      "source": "arXiv AI",
      "published_time": "2025-07-31 04:00:00",
      "author": "Yiya Diao, Changhe Li, Sanyou Zeng, Xinye Cai, Wenjian Luo, Shengxiang Yang, Carlos A. Coello Coello",
      "tags": [],
      "heat_score": 35.0,
      "content_type": "paper",
      "language": "en",
      "summary": ""
    },
    {
      "title": "Collaborative Medical Triage under Uncertainty: A Multi-Agent Dynamic Matching Approach",
      "content": "arXiv:2507.22504v1 Announce Type: new \nAbstract: The post-pandemic surge in healthcare demand, coupled with critical nursing shortages, has placed unprecedented pressure on emergency department triage systems, necessitating innovative AI-driven solutions. We present a multi-agent interactive intelligent system for medical triage that addresses three fundamental challenges in current AI-based triage systems: insufficient medical specialization leading to hallucination-induced misclassifications, heterogeneous department structures across healthcare institutions, and inefficient detail-oriented questioning that impedes rapid triage decisions. Our system employs three specialized agents - RecipientAgent, InquirerAgent, and DepartmentAgent - that collaborate through structured inquiry mechanisms and department-specific guidance rules to transform unstructured patient symptoms into accurate department recommendations. To ensure robust evaluation, we constructed a comprehensive Chinese medical triage dataset from a medical website, comprising 3,360 real-world cases spanning 9 primary departments and 62 secondary departments. Through systematic data imputation using large language models, we address the prevalent issue of incomplete medical records in real-world data. Experimental results demonstrate that our multi-agent system achieves 89.2% accuracy in primary department classification and 73.9% accuracy in secondary department classification after four rounds of patient interaction. The system's pattern-matching-based guidance mechanisms enable efficient adaptation to diverse hospital configurations while maintaining high triage accuracy. Our work provides a scalable framework for deploying AI-assisted triage systems that can accommodate the organizational heterogeneity of healthcare institutions while ensuring clinically sound decision-making.",
      "url": "https://arxiv.org/abs/2507.22504",
      "source": "arXiv AI",
      "published_time": "2025-07-31 04:00:00",
      "author": "Hongyan Cheng, Chengzhang Yu, Yanshu Shi, Chiyue Wang, Cong Liu, Zhanpeng Jin",
      "tags": [],
      "heat_score": 35.0,
      "content_type": "paper",
      "language": "en",
      "summary": ""
    },
    {
      "title": "MetaAgent: Automatically Constructing Multi-Agent Systems Based on Finite State Machines",
      "content": "arXiv:2507.22606v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have demonstrated the ability to solve a wide range of practical tasks within multi-agent systems. However, existing human-designed multi-agent frameworks are typically limited to a small set of pre-defined scenarios, while current automated design methods suffer from several limitations, such as the lack of tool integration, dependence on external training data, and rigid communication structures. In this paper, we propose MetaAgent, a finite state machine based framework that can automatically generate a multi-agent system. Given a task description, MetaAgent will design a multi-agent system and polish it through an optimization algorithm. When the multi-agent system is deployed, the finite state machine will control the agent's actions and the state transitions. To evaluate our framework, we conduct experiments on both text-based tasks and practical tasks. The results indicate that the generated multi-agent system surpasses other auto-designed methods and can achieve a comparable performance with the human-designed multi-agent system, which is optimized for those specific tasks.",
      "url": "https://arxiv.org/abs/2507.22606",
      "source": "arXiv AI",
      "published_time": "2025-07-31 04:00:00",
      "author": "Yaolun Zhang, Xiaogeng Liu, Chaowei Xiao",
      "tags": [],
      "heat_score": 35.0,
      "content_type": "paper",
      "language": "en",
      "summary": ""
    },
    {
      "title": "Enhancing Manufacturing Knowledge Access with LLMs and Context-aware Prompting",
      "content": "arXiv:2507.22619v1 Announce Type: new \nAbstract: Knowledge graphs (KGs) have transformed data management within the manufacturing industry, offering effective means for integrating disparate data sources through shared and structured conceptual schemas. However, harnessing the power of KGs can be daunting for non-experts, as it often requires formulating complex SPARQL queries to retrieve specific information. With the advent of Large Language Models (LLMs), there is a growing potential to automatically translate natural language queries into the SPARQL format, thus bridging the gap between user-friendly interfaces and the sophisticated architecture of KGs. The challenge remains in adequately informing LLMs about the relevant context and structure of domain-specific KGs, e.g., in manufacturing, to improve the accuracy of generated queries. In this paper, we evaluate multiple strategies that use LLMs as mediators to facilitate information retrieval from KGs. We focus on the manufacturing domain, particularly on the Bosch Line Information System KG and the I40 Core Information Model. In our evaluation, we compare various approaches for feeding relevant context from the KG to the LLM and analyze their proficiency in transforming real-world questions into SPARQL queries. Our findings show that LLMs can significantly improve their performance on generating correct and complete queries when provided only the adequate context of the KG schema. Such context-aware prompting techniques help LLMs to focus on the relevant parts of the ontology and reduce the risk of hallucination. We anticipate that the proposed techniques help LLMs to democratize access to complex data repositories and empower informed decision-making in manufacturing settings.",
      "url": "https://arxiv.org/abs/2507.22619",
      "source": "arXiv AI",
      "published_time": "2025-07-31 04:00:00",
      "author": "Sebastian Monka, Irlan Grangel-Gonz\\'alez, Stefan Schmid, Lavdim Halilaj, Marc Rickart, Oliver Rudolph, Rui Dias",
      "tags": [],
      "heat_score": 35.0,
      "content_type": "paper",
      "language": "en",
      "summary": ""
    },
    {
      "title": "Enhancing Multi-Agent Collaboration with Attention-Based Actor-Critic Policies",
      "content": "arXiv:2507.22782v1 Announce Type: new \nAbstract: This paper introduces Team-Attention-Actor-Critic (TAAC), a reinforcement learning algorithm designed to enhance multi-agent collaboration in cooperative environments. TAAC employs a Centralized Training/Centralized Execution scheme incorporating multi-headed attention mechanisms in both the actor and critic. This design facilitates dynamic, inter-agent communication, allowing agents to explicitly query teammates, thereby efficiently managing the exponential growth of joint-action spaces while ensuring a high degree of collaboration. We further introduce a penalized loss function which promotes diverse yet complementary roles among agents. We evaluate TAAC in a simulated soccer environment against benchmark algorithms representing other multi-agent paradigms, including Proximal Policy Optimization and Multi-Agent Actor-Attention-Critic. We find that TAAC exhibits superior performance and enhanced collaborative behaviors across a variety of metrics (win rates, goal differentials, Elo ratings, inter-agent connectivity, balanced spatial distributions, and frequent tactical interactions such as ball possession swaps).",
      "url": "https://arxiv.org/abs/2507.22782",
      "source": "arXiv AI",
      "published_time": "2025-07-31 04:00:00",
      "author": "Hugo Garrido-Lestache, Jeremy Kedziora",
      "tags": [],
      "heat_score": 35.0,
      "content_type": "paper",
      "language": "en",
      "summary": ""
    },
    {
      "title": "The Incomplete Bridge: How AI Research (Mis)Engages with Psychology",
      "content": "arXiv:2507.22847v1 Announce Type: new \nAbstract: Social sciences have accumulated a rich body of theories and methodologies for investigating the human mind and behaviors, while offering valuable insights into the design and understanding of Artificial Intelligence (AI) systems. Focusing on psychology as a prominent case, this study explores the interdisciplinary synergy between AI and the field by analyzing 1,006 LLM-related papers published in premier AI venues between 2023 and 2025, along with the 2,544 psychology publications they cite. Through our analysis, we identify key patterns of interdisciplinary integration, locate the psychology domains most frequently referenced, and highlight areas that remain underexplored. We further examine how psychology theories/frameworks are operationalized and interpreted, identify common types of misapplication, and offer guidance for more effective incorporation. Our work provides a comprehensive map of interdisciplinary engagement between AI and psychology, thereby facilitating deeper collaboration and advancing AI systems.",
      "url": "https://arxiv.org/abs/2507.22847",
      "source": "arXiv AI",
      "published_time": "2025-07-31 04:00:00",
      "author": "Han Jiang, Pengda Wang, Xiaoyuan Yi, Xing Xie, Ziang Xiao",
      "tags": [],
      "heat_score": 35.0,
      "content_type": "paper",
      "language": "en",
      "summary": ""
    },
    {
      "title": "Automatically discovering heuristics in a complex SAT solver with large language models",
      "content": "arXiv:2507.22876v1 Announce Type: new \nAbstract: Satisfiability problem (SAT) is a cornerstone of computational complexity with broad industrial applications, and it remains challenging to optimize modern SAT solvers in real-world settings due to their intricate architectures. While automatic configuration frameworks have been developed, they rely on manually constrained search spaces and yield limited performance gains. This work introduces a novel paradigm which effectively optimizes complex SAT solvers via Large Language Models (LLMs), and a tool called AutoModSAT is developed. Three fundamental challenges are addressed in order to achieve superior performance: (1) LLM-friendly solver: Systematic guidelines are proposed for developing a modularized solver to meet LLMs' compatibility, emphasizing code simplification, information share and bug reduction; (2) Automatic prompt optimization: An unsupervised automatic prompt optimization method is introduced to advance the diversity of LLMs' output; (3) Efficient search strategy: We design a presearch strategy and an EA evolutionary algorithm for the final efficient and effective discovery of heuristics. Extensive experiments across a wide range of datasets demonstrate that AutoModSAT achieves 50% performance improvement over the baseline solver and achieves 30% superiority against the state-of-the-art (SOTA) solvers. Moreover, AutoModSAT attains a 20% speedup on average compared to parameter-tuned alternatives of the SOTA solvers, showcasing the enhanced capability in handling complex problem instances. This work bridges the gap between AI-driven heuristics discovery and mission-critical system optimization, and provides both methodological advancements and empirically validated results for next-generation complex solver development.",
      "url": "https://arxiv.org/abs/2507.22876",
      "source": "arXiv AI",
      "published_time": "2025-07-31 04:00:00",
      "author": "Yiwen Sun, Furong Ye, Zhihan Chen, Ke Wei, Shaowei Cai",
      "tags": [],
      "heat_score": 35.0,
      "content_type": "paper",
      "language": "en",
      "summary": ""
    },
    {
      "title": "Spatial-Temporal Data Mining for Ocean Science: Data, Methodologies, and Opportunities",
      "content": "arXiv:2307.10803v2 Announce Type: cross \nAbstract: With the rapid amassing of spatial-temporal (ST) ocean data, many spatial-temporal data mining (STDM) studies have been conducted to address various oceanic issues, including climate forecasting and disaster warning. Compared with typical ST data (e.g., traffic data), ST ocean data is more complicated but with unique characteristics, e.g., diverse regionality and high sparsity. These characteristics make it difficult to design and train STDM models on ST ocean data. To the best of our knowledge, a comprehensive survey of existing studies remains missing in the literature, which hinders not only computer scientists from identifying the research issues in ocean data mining but also ocean scientists to apply advanced STDM techniques. In this paper, we provide a comprehensive survey of existing STDM studies for ocean science. Concretely, we first review the widely-used ST ocean datasets and highlight their unique characteristics. Then, typical ST ocean data quality enhancement techniques are explored. Next, we classify existing STDM studies in ocean science into four types of tasks, i.e., prediction, event detection, pattern mining, and anomaly detection, and elaborate on the techniques for these tasks. Finally, promising research opportunities are discussed. This survey can help scientists from both computer science and ocean science better understand the fundamental concepts, key techniques, and open challenges of STDM for ocean science.",
      "url": "https://arxiv.org/abs/2307.10803",
      "source": "arXiv AI",
      "published_time": "2025-07-31 04:00:00",
      "author": "Hanchen Yang, Wengen Li, Shuyu Wang, Hui Li, Jihong Guan, Shuigeng Zhou, Jiannong Cao",
      "tags": [],
      "heat_score": 35.0,
      "content_type": "paper",
      "language": "en",
      "summary": ""
    },
    {
      "title": "RecPS: Privacy Risk Scoring for Recommender Systems",
      "content": "arXiv:2507.18365v2 Announce Type: cross \nAbstract: Recommender systems (RecSys) have become an essential component of many web applications. The core of the system is a recommendation model trained on highly sensitive user-item interaction data. While privacy-enhancing techniques are actively studied in the research community, the real-world model development still depends on minimal privacy protection, e.g., via controlled access. Users of such systems should have the right to choose \\emph{not} to share highly sensitive interactions. However, there is no method allowing the user to know which interactions are more sensitive than others. Thus, quantifying the privacy risk of RecSys training data is a critical step to enabling privacy-aware RecSys model development and deployment. We propose a membership-inference attack (MIA)- based privacy scoring method, RecPS, to measure privacy risks at both the interaction and user levels. The RecPS interaction-level score definition is motivated and derived from differential privacy, which is then extended to the user-level scoring method. A critical component is the interaction-level MIA method RecLiRA, which gives high-quality membership estimation. We have conducted extensive experiments on well-known benchmark datasets and RecSys models to show the unique features and benefits of RecPS scoring in risk assessment and RecSys model unlearning.",
      "url": "https://arxiv.org/abs/2507.18365",
      "source": "arXiv AI",
      "published_time": "2025-07-31 04:00:00",
      "author": "Jiajie He, Yuechun Gu, Keke Chen",
      "tags": [],
      "heat_score": 35.0,
      "content_type": "paper",
      "language": "en",
      "summary": ""
    },
    {
      "title": "GABRIL: Gaze-Based Regularization for Mitigating Causal Confusion in Imitation Learning",
      "content": "arXiv:2507.19647v1 Announce Type: cross \nAbstract: Imitation Learning (IL) is a widely adopted approach which enables agents to learn from human expert demonstrations by framing the task as a supervised learning problem. However, IL often suffers from causal confusion, where agents misinterpret spurious correlations as causal relationships, leading to poor performance in testing environments with distribution shift. To address this issue, we introduce GAze-Based Regularization in Imitation Learning (GABRIL), a novel method that leverages the human gaze data gathered during the data collection phase to guide the representation learning in IL. GABRIL utilizes a regularization loss which encourages the model to focus on causally relevant features identified through expert gaze and consequently mitigates the effects of confounding variables. We validate our approach in Atari environments and the Bench2Drive benchmark in CARLA by collecting human gaze datasets and applying our method in both domains. Experimental results show that the improvement of GABRIL over behavior cloning is around 179% more than the same number for other baselines in the Atari and 76% in the CARLA setup. Finally, we show that our method provides extra explainability when compared to regular IL agents.",
      "url": "https://arxiv.org/abs/2507.19647",
      "source": "arXiv AI",
      "published_time": "2025-07-31 04:00:00",
      "author": "Amin Banayeeanzade, Fatemeh Bahrani, Yutai Zhou, Erdem B{\\i}y{\\i}k",
      "tags": [],
      "heat_score": 35.0,
      "content_type": "paper",
      "language": "en",
      "summary": ""
    },
    {
      "title": "特赞科技x同济设计人工智能实验室，“创意可计算性”产教实践亮相世界人工智能大会",
      "content": "300+ 人线上报名、200 + 人线下参与",
      "url": "https://www.qbitai.com/2025/07/315641.html",
      "source": "量子位",
      "published_time": "2025-07-30 09:22:27",
      "author": "量子位的朋友们",
      "tags": [],
      "heat_score": 30.0,
      "content_type": "article",
      "language": "zh",
      "summary": ""
    },
    {
      "title": "理想的AI司机，开始强化学习了",
      "content": "自动驾驶进入强化学习时间",
      "url": "https://www.qbitai.com/2025/07/315628.html",
      "source": "量子位",
      "published_time": "2025-07-30 09:22:19",
      "author": "一凡",
      "tags": [],
      "heat_score": 30.0,
      "content_type": "article",
      "language": "zh",
      "summary": ""
    },
    {
      "title": "Nature 子刊 | DeepSeek落户超750家医院，清华团队剖析AI医疗监管隐忧",
      "content": "",
      "url": "https://www.jiqizhixin.com/articles/2025-07-30-8",
      "source": "机器之心",
      "published_time": "2025-07-30 10:05:06",
      "author": "ScienceAI",
      "tags": [],
      "heat_score": 30.0,
      "content_type": "article",
      "language": "zh",
      "summary": ""
    },
    {
      "title": "当智能成为主要生产资料，硅基经济学引爆「AI+金融」",
      "content": "",
      "url": "https://www.jiqizhixin.com/articles/2025-07-30-5",
      "source": "机器之心",
      "published_time": "2025-07-30 06:21:48",
      "author": "机器之心",
      "tags": [],
      "heat_score": 30.0,
      "content_type": "article",
      "language": "zh",
      "summary": ""
    },
    {
      "title": "AI安全上，开源仍胜闭源，Meta、UCB防御LLM提示词注入攻击",
      "content": "",
      "url": "https://www.jiqizhixin.com/articles/2025-07-30",
      "source": "机器之心",
      "published_time": "2025-07-30 02:14:35",
      "author": "机器之心",
      "tags": [],
      "heat_score": 30.0,
      "content_type": "article",
      "language": "zh",
      "summary": ""
    },
    {
      "title": "Microsoft in talks to maintain access to OpenAI’s tech beyond AGI milestone",
      "content": "Microsoft is reportedly in advanced talks with OpenAI for a new agreement that would give it ongoing access to the startup’s technology even if OpenAI achieves what it defines as AGI, or advanced general intelligence. If the deal goes through, it would clear a key hurdle in OpenAI’s transition toward becoming a fully commercial enterprise.",
      "url": "https://techcrunch.com/2025/07/29/microsoft-in-talks-to-maintain-access-to-openais-tech-beyond-agi-milestone/",
      "source": "TechCrunch AI",
      "published_time": "2025-07-29 14:44:10",
      "author": "Rebecca Bellan",
      "tags": [],
      "heat_score": 30.0,
      "content_type": "article",
      "language": "en",
      "summary": ""
    },
    {
      "title": "ASP-FZN: A Translation-based Constraint Answer Set Solver",
      "content": "arXiv:2507.22774v1 Announce Type: new \nAbstract: We present the solver asp-fzn for Constraint Answer Set Programming (CASP), which extends ASP with linear constraints. Our approach is based on translating CASP programs into the solver-independent FlatZinc language that supports several Constraint Programming and Integer Programming backend solvers. Our solver supports a rich language of linear constraints, including some common global constraints. As for evaluation, we show that asp-fzn is competitive with state-of-the-art ASP solvers on benchmarks taken from past ASP competitions. Furthermore, we evaluate it on several CASP problems from the literature and compare its performance with clingcon, which is a prominent CASP solver that supports most of the asp-fzn language. The performance of asp-fzn is very promising as it is already competitive on plain ASP and even outperforms clingcon on some CASP benchmarks.",
      "url": "https://arxiv.org/abs/2507.22774",
      "source": "arXiv AI",
      "published_time": "2025-07-31 04:00:00",
      "author": "Thomas Eiter, Tobias Geibinger, Tobias Kaminski, Nysret Musliu, Johannes Oetsch",
      "tags": [],
      "heat_score": 30.0,
      "content_type": "paper",
      "language": "en",
      "summary": ""
    },
    {
      "title": "GitHub Copilot crosses 20 million all-time users",
      "content": "One of the most popular AI coding tools on the market added five million users in the last three months.",
      "url": "https://techcrunch.com/2025/07/30/github-copilot-crosses-20-million-all-time-users/",
      "source": "TechCrunch AI",
      "published_time": "2025-07-31 01:16:55",
      "author": "Maxwell Zeff",
      "tags": [],
      "heat_score": 25.0,
      "content_type": "article",
      "language": "en",
      "summary": ""
    },
    {
      "title": "Zuckerberg says people without AI glasses will be at a disadvantage in the future",
      "content": "Mark Zuckerberg really believes AI glasses will be the ideal way to blend the physical and digital worlds together.",
      "url": "https://techcrunch.com/2025/07/30/zuckerberg-says-people-without-ai-glasses-will-be-at-a-disadvantage-in-the-future/",
      "source": "TechCrunch AI",
      "published_time": "2025-07-30 22:47:30",
      "author": "Sarah Perez",
      "tags": [],
      "heat_score": 25.0,
      "content_type": "article",
      "language": "en",
      "summary": ""
    },
    {
      "title": "Meta to spend up to $72B on AI infrastructure in 2025 as compute arms race escalates",
      "content": "Meta is pouring money into the physical and technical infrastructure needed to scale its AI ambitions. The company said Wednesday in its second-quarter earnings report that it plans to more than double its spend on building AI infrastructure – like data centers and servers. \n\n“We currently expect 2025 capital expenditures, including principal payments on finance leases, to be in the range of $66-72 billion…up approximately $30 billion year-over-year at the midpoint,” Meta said.",
      "url": "https://techcrunch.com/2025/07/30/meta-to-spend-up-to-72b-on-ai-infrastructure-in-2025-as-compute-arms-race-escalates/",
      "source": "TechCrunch AI",
      "published_time": "2025-07-30 21:31:42",
      "author": "Rebecca Bellan",
      "tags": [],
      "heat_score": 25.0,
      "content_type": "article",
      "language": "en",
      "summary": ""
    },
    {
      "title": "Who really benefits from the AI boom?",
      "content": "If you’ve been hearing about Trump’s AI Action Plan and wondering who it actually benefits, you’re not alone. On today’s episode of Equity, Rebecca Bellan caught up with Amba Kak and Dr. Sarah Myers West from the AI Now Institute, a think tank focused on the social implications of AI and the consolidation of power […]",
      "url": "https://techcrunch.com/podcast/who-really-benefits-from-the-ai-boom/",
      "source": "TechCrunch AI",
      "published_time": "2025-07-30 19:49:33",
      "author": "Theresa Loconsolo, Rebecca Bellan",
      "tags": [],
      "heat_score": 25.0,
      "content_type": "article",
      "language": "en",
      "summary": ""
    },
    {
      "title": "Zuckerberg signals Meta won’t open source all of its ‘superintelligence’ AI models",
      "content": "Meta is shifting how it plans to ensure widespread access to superintelligence, a suggestion that the company’s most advanced AI may remain closed so that Meta can stay in the driver’s seat.",
      "url": "https://techcrunch.com/2025/07/30/zuckerberg-says-meta-likely-wont-open-source-all-of-its-superintelligence-ai-models/",
      "source": "TechCrunch AI",
      "published_time": "2025-07-30 17:56:58",
      "author": "Rebecca Bellan",
      "tags": [],
      "heat_score": 25.0,
      "content_type": "article",
      "language": "en",
      "summary": ""
    },
    {
      "title": "PlayerZero raises $15M to prevent AI agents from shipping buggy code",
      "content": "PlayerZero landed angel investors like Databricks' Matei Zaharia, Dropbox's Drew Houston, Figma's  Dylan Field, and Vercel's Guillermo Rauch, its founder says.",
      "url": "https://techcrunch.com/2025/07/30/playerzero-raises-15m-to-prevent-ai-agents-from-shipping-buggy-code/",
      "source": "TechCrunch AI",
      "published_time": "2025-07-30 16:00:00",
      "author": "Julie Bort",
      "tags": [],
      "heat_score": 25.0,
      "content_type": "article",
      "language": "en",
      "summary": ""
    },
    {
      "title": "How 2 UC Berkeley dropouts raised $28M for their AI marketing automation startup",
      "content": "A marketing automation startup called Conversation has a founding story that sounds like it could have been an episode of the HBO show “Silicon Valley.”",
      "url": "https://techcrunch.com/2025/07/30/how-2-uc-berkeley-dropouts-raised-28m-for-their-ai-marketing-automation-startup/",
      "source": "TechCrunch AI",
      "published_time": "2025-07-30 15:00:00",
      "author": "Julie Bort",
      "tags": [],
      "heat_score": 25.0,
      "content_type": "article",
      "language": "en",
      "summary": ""
    },
    {
      "title": "Introducing Stargate Norway",
      "content": "We’re launching Stargate Norway—OpenAI’s first AI data center initiative in Europe under our OpenAI for Countries program. Stargate is OpenAI’s overarching infrastructure platform and is a critical part of our long-term vision to deliver the benefits of AI to everyone.",
      "url": "https://openai.com/index/introducing-stargate-norway",
      "source": "OpenAI Blog",
      "published_time": "2025-07-31 00:00:00",
      "author": "",
      "tags": [],
      "heat_score": 25.0,
      "content_type": "article",
      "language": "en",
      "summary": ""
    },
    {
      "title": "Observe continues to adapt to the changing world of software observability",
      "content": "Observe just raised a $156 million Series C round as the company looks to offer support for Apache Iceberg by the end of the year.",
      "url": "https://techcrunch.com/2025/07/30/observe-continues-to-adapt-to-the-changing-world-of-software-observability/",
      "source": "TechCrunch AI",
      "published_time": "2025-07-30 13:00:00",
      "author": "Rebecca Szkutak",
      "tags": [],
      "heat_score": 15.0,
      "content_type": "article",
      "language": "en",
      "summary": ""
    },
    {
      "title": "Google says it will sign EU’s AI code of practice",
      "content": "By signing the EU’s code of practice, AI companies would agree to follow a slate of guidelines, which include providing updated documentation about their AI tools and services; no training AI on pirated content; and complying with requests from content owners to not use their works in their datasets.",
      "url": "https://techcrunch.com/2025/07/30/google-says-it-will-sign-eus-ai-code-of-practice/",
      "source": "TechCrunch AI",
      "published_time": "2025-07-30 12:57:03",
      "author": "Ram Iyer",
      "tags": [],
      "heat_score": 15.0,
      "content_type": "article",
      "language": "en",
      "summary": ""
    },
    {
      "title": "Nvidia AI chip challenger Groq said to be nearing new fundraising at $6B valuation",
      "content": "AI chip startup Groq is in talks to raise a fresh $600 million at a near $6 billion valuation, sources tell Bloomberg, although the deal isn’t yet final and terms could change.",
      "url": "https://techcrunch.com/2025/07/29/nvidia-ai-chip-challenger-groq-said-to-be-nearing-new-fundraising-at-6b-valuation/",
      "source": "TechCrunch AI",
      "published_time": "2025-07-29 22:02:51",
      "author": "Julie Bort",
      "tags": [],
      "heat_score": 15.0,
      "content_type": "article",
      "language": "en",
      "summary": ""
    },
    {
      "title": "Spotify hints at a more chatty voice AI interface in the future",
      "content": "Spotify says AI will allow for \"much more interactive\" consumer experiences in its app.",
      "url": "https://techcrunch.com/2025/07/29/spotify-hints-at-a-more-chatty-voice-ai-interface-in-the-future/",
      "source": "TechCrunch AI",
      "published_time": "2025-07-29 16:58:53",
      "author": "Sarah Perez",
      "tags": [],
      "heat_score": 15.0,
      "content_type": "article",
      "language": "en",
      "summary": ""
    },
    {
      "title": "Google’s AI Mode gets new ‘Canvas’ feature, real-time help with Search Live, and more",
      "content": "The tech giant is rolling out a new Canvas feature, the ability to get real-time help with Search Live, and the option to search what you see while browsing.",
      "url": "https://techcrunch.com/2025/07/29/googles-ai-mode-gets-new-canvas-feature-real-time-help-with-search-live-and-more/",
      "source": "TechCrunch AI",
      "published_time": "2025-07-29 16:00:00",
      "author": "Aisha Malik",
      "tags": [],
      "heat_score": 15.0,
      "content_type": "article",
      "language": "en",
      "summary": ""
    },
    {
      "title": "Three lessons for creating a sustainable AI advantage",
      "content": "Discover how Intercom built a scalable AI platform with 3 key lessons—from evaluations to architecture—to lead the future of customer support.",
      "url": "https://openai.com/index/intercom",
      "source": "OpenAI Blog",
      "published_time": "2025-07-30 00:00:00",
      "author": "",
      "tags": [],
      "heat_score": 15.0,
      "content_type": "article",
      "language": "en",
      "summary": ""
    }
  ]
}