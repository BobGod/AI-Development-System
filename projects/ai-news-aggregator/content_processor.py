"""
ğŸ§  AIæ™ºèƒ½å†…å®¹å¤„ç†å’Œæ ¼å¼åŒ–å¼•æ“
å°†åŸå§‹æ–°é—»è½¬æ¢ä¸ºé€‚åˆä¸åŒå¹³å°çš„ç²¾ç¾å†…å®¹
"""

import asyncio
import aiohttp
import json
import logging
import re
from datetime import datetime
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass, asdict
import hashlib
from enum import Enum
import os
from news_spider import NewsItem

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class Platform(Enum):
    """å‘å¸ƒå¹³å°æšä¸¾"""
    WECHAT = "wechat"
    XIAOHONGSHU = "xiaohongshu"
    WEIBO = "weibo"

@dataclass
class ProcessedContent:
    """å¤„ç†åçš„å†…å®¹"""
    original_news: NewsItem
    platform: Platform
    optimized_title: str
    formatted_content: str
    tags: List[str]
    hashtags: List[str]
    summary: str
    reading_time: int  # é¢„ä¼°é˜…è¯»æ—¶é—´ï¼ˆç§’ï¼‰
    engagement_score: float  # é¢„ä¼°äº’åŠ¨åº¦
    thumbnail_prompt: str  # é…å›¾æç¤ºè¯
    
    def to_dict(self) -> Dict:
        result = asdict(self)
        result['platform'] = self.platform.value
        result['original_news'] = asdict(self.original_news)
        return result

class AIContentProcessor:
    """AIå†…å®¹å¤„ç†å¼•æ“"""
    
    def __init__(self, deepseek_api_key: str = None):
        self.api_key = deepseek_api_key or os.getenv("DEEPSEEK_API_KEY")
        self.api_base = "https://api.deepseek.com/v1"
        
        # å¹³å°ç‰¹è‰²æ¨¡æ¿
        self.platform_templates = {
            Platform.WECHAT: {
                "title_style": "ä¸“ä¸šã€æƒå¨ã€æ•°æ®é©±åŠ¨",
                "content_style": "æ·±åº¦åˆ†æã€ç»“æ„åŒ–ã€å¼•ç”¨æ¥æº",
                "max_title_length": 64,
                "emojis": ["ğŸ“ˆ", "ğŸš€", "ğŸ’¡", "ğŸ”¥", "âš¡", "ğŸ¯", "ğŸ“Š"],
                "tone": "professional"
            },
            Platform.XIAOHONGSHU: {
                "title_style": "å¹´è½»åŒ–ã€è¯é¢˜æ€§ã€emojiä¸°å¯Œ",
                "content_style": "è½»æ¾æ´»æ³¼ã€äº’åŠ¨æ€§å¼ºã€è§†è§‰åŒ–",
                "max_title_length": 50,
                "emojis": ["âœ¨", "ğŸ¤–", "ğŸ’«", "ğŸ‰", "ğŸ˜", "ğŸ”¥", "ğŸ’", "ğŸŒŸ", "âš¡", "ğŸ¯"],
                "tone": "casual"
            }
        }
        
        # çƒ­è¯åº“
        self.hot_keywords = {
            "æŠ€æœ¯çªç ´": ["çªç ´", "é©å‘½æ€§", "é¢ è¦†", "é¦–æ¬¡", "å†å²æ€§", "é‡Œç¨‹ç¢‘"],
            "äº§å“å‘å¸ƒ": ["å‘å¸ƒ", "æ¨å‡º", "ä¸Šçº¿", "äº®ç›¸", "ç™»åœº", "é¢ä¸–"],  
            "èèµ„æŠ•èµ„": ["èèµ„", "æŠ•èµ„", "ä¼°å€¼", "IPO", "æ”¶è´­", "åˆå¹¶"],
            "è¡Œä¸šåˆ†æ": ["è¶‹åŠ¿", "é¢„æµ‹", "åˆ†æ", "æ´å¯Ÿ", "æŠ¥å‘Š", "ç ”ç©¶"],
            "æŠ€æœ¯å…¬å¸": ["OpenAI", "Google", "ç™¾åº¦", "è…¾è®¯", "é˜¿é‡Œ", "å­—èŠ‚"],
            "AIæ¨¡å‹": ["GPT", "Claude", "Gemini", "æ–‡å¿ƒ", "é€šä¹‰", "æ˜Ÿç«"]
        }

    async def call_deepseek_api(self, messages: List[Dict], model: str = "deepseek-chat") -> str:
        """è°ƒç”¨DeepSeek API"""
        if not self.api_key:
            logger.warning("æœªè®¾ç½®DEEPSEEK_API_KEYï¼Œä½¿ç”¨æ¨¡æ‹Ÿå“åº”")
            return self._mock_ai_response(messages)
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": model,
            "messages": messages,
            "temperature": 0.7,
            "max_tokens": 2000
        }
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f"{self.api_base}/chat/completions",
                    headers=headers,
                    json=payload,
                    timeout=30
                ) as response:
                    if response.status == 200:
                        result = await response.json()
                        return result["choices"][0]["message"]["content"]
                    else:
                        logger.error(f"DeepSeek APIè°ƒç”¨å¤±è´¥: {response.status}")
                        return self._mock_ai_response(messages)
        except Exception as e:
            logger.error(f"DeepSeek APIè°ƒç”¨å¼‚å¸¸: {e}")
            return self._mock_ai_response(messages)

    def _mock_ai_response(self, messages: List[Dict]) -> str:
        """æ¨¡æ‹ŸAIå“åº”ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
        user_message = messages[-1]["content"] if messages else ""
        
        if "æ ‡é¢˜" in user_message:
            return """
1. ğŸš€ GPT-5å³å°†å‘å¸ƒï¼OpenAIå†…éƒ¨æ¶ˆæ¯é¦–æ¬¡æ›å…‰
2. ğŸ”¥ AIå¤§æ¨¡å‹æ–°çªç ´ï¼šæ€§èƒ½æå‡300%éœ‡æ’¼ç™»åœº  
3. âš¡ é‡ç£…ï¼ä¸‹ä¸€ä»£AIåŠ©æ‰‹å°†æ”¹å˜æ‰€æœ‰è¡Œä¸šæ ¼å±€
            """.strip()
        elif "å°çº¢ä¹¦" in user_message:
            return """
ğŸ¤–âœ¨ AIåœˆåˆæœ‰å¤§åŠ¨ä½œå•¦ï¼

ä»Šå¤©åˆ·åˆ°ä¸€ä¸ªè¶…çº§éœ‡æ’¼çš„æ¶ˆæ¯ï¼ŒGPT-5è¦æ¥äº†ï¼ğŸ”¥ğŸ”¥

æ®è¯´æ€§èƒ½æ¯”GPT-4æå‡äº†å¥½å‡ å€ï¼Œç®€ç›´ä¸æ•¢æƒ³è±¡ä»¥åçš„AIä¼šæœ‰å¤šå¼ºå¤§ ğŸ˜±

âœ¨ é‡ç‚¹æ¥äº†ï¼š
â€¢ æ¨ç†èƒ½åŠ›å¤§å¹…æå‡
â€¢ æ”¯æŒæ›´å¤šæ¨¡æ€äº¤äº’  
â€¢ å“åº”é€Ÿåº¦æ›´å¿«
â€¢ åˆ›é€ åŠ›çˆ†è¡¨ ğŸ’«

å§å¦¹ä»¬ï¼Œä½ ä»¬è§‰å¾—AIå‘å±•è¿™ä¹ˆå¿«ï¼Œä¼šä¸ä¼šå¾ˆå¿«å°±èƒ½å¸®æˆ‘ä»¬åšæ‰€æœ‰å·¥ä½œäº†ï¼Ÿ ğŸ˜‚

#AIæ–°é—» #GPT5 #äººå·¥æ™ºèƒ½ #ç§‘æŠ€å‰æ²¿ #æœªæ¥å·²æ¥
            """.strip()
        elif "å…¬ä¼—å·" in user_message:
            return """
# GPT-5å³å°†å‘å¸ƒï¼šAIå‘å±•æ–°é‡Œç¨‹ç¢‘

## ğŸ“Š æ ¸å¿ƒè¦ç‚¹

â€¢ OpenAIå†…éƒ¨æ¶ˆæ¯ç¡®è®¤ï¼ŒGPT-5å¼€å‘è¿›å±•é¡ºåˆ©
â€¢ é¢„è®¡æ€§èƒ½ç›¸æ¯”GPT-4æå‡æ˜¾è‘—ï¼Œå¤šé¡¹æŒ‡æ ‡åˆ›æ–°é«˜
â€¢ å‘å¸ƒæ—¶é—´çª—å£åˆæ­¥ç¡®å®šï¼Œä¸šç•Œé«˜åº¦å…³æ³¨

## ğŸ“° è¯¦ç»†è§£è¯»

æ ¹æ®å¯é æ¶ˆæ¯æºé€éœ²ï¼ŒOpenAIçš„ä¸‹ä¸€ä»£å¤§è¯­è¨€æ¨¡å‹GPT-5å·²è¿›å…¥æœ€åæµ‹è¯•é˜¶æ®µã€‚ç›¸æ¯”äºGPT-4ï¼Œæ–°æ¨¡å‹åœ¨æ¨ç†èƒ½åŠ›ã€åˆ›é€ æ€§è¾“å‡ºå’Œå¤šæ¨¡æ€ç†è§£æ–¹é¢éƒ½æœ‰æ˜¾è‘—æå‡ã€‚

æŠ€æœ¯å±‚é¢çš„çªç ´ä¸»è¦ä½“ç°åœ¨ï¼šæ¨¡å‹å‚æ•°ä¼˜åŒ–ã€è®­ç»ƒæ•°æ®è´¨é‡æå‡ä»¥åŠè®¡ç®—æ•ˆç‡çš„å¤§å¹…æ”¹è¿›ã€‚

## ğŸ”® è¡Œä¸šå½±å“

GPT-5çš„å‘å¸ƒå°†è¿›ä¸€æ­¥æ¨åŠ¨äººå·¥æ™ºèƒ½åœ¨å„è¡Œå„ä¸šçš„åº”ç”¨æ·±åŒ–ï¼Œç‰¹åˆ«æ˜¯åœ¨æ•™è‚²ã€åŒ»ç–—ã€é‡‘èç­‰é¢†åŸŸçš„æ™ºèƒ½åŒ–è½¬å‹ã€‚

## ğŸ’¡ æ€»ç»“

AIæŠ€æœ¯çš„å¿«é€Ÿè¿­ä»£æ­£åœ¨é‡å¡‘æˆ‘ä»¬çš„å·¥ä½œå’Œç”Ÿæ´»æ–¹å¼ï¼Œå€¼å¾—æŒç»­å…³æ³¨å…¶å‘å±•åŠ¨æ€ã€‚

---
*æœ¬æ–‡ç”±AIæ™ºèƒ½æ–°é—»èšåˆå¹³å°è‡ªåŠ¨ç”Ÿæˆ*
            """.strip()
        else:
            return "AIå¤„ç†å®Œæˆï¼Œå·²ç”Ÿæˆä¼˜åŒ–å†…å®¹ã€‚"

    async def optimize_title(self, news: NewsItem, platform: Platform) -> str:
        """ä¼˜åŒ–æ ‡é¢˜"""
        template = self.platform_templates[platform]
        
        prompt = f"""
è¯·åŸºäºä»¥ä¸‹AIæ–°é—»ï¼Œä¸º{platform.value}å¹³å°ç”Ÿæˆä¼˜åŒ–æ ‡é¢˜ï¼š

åŸæ ‡é¢˜ï¼š{news.title}
æ–°é—»å†…å®¹ï¼š{news.content[:300]}
æ–°é—»æ¥æºï¼š{news.source}

å¹³å°è¦æ±‚ï¼š
- é£æ ¼ï¼š{template['title_style']}
- æœ€å¤§é•¿åº¦ï¼š{template['max_title_length']}å­—
- é€‚ç”¨emojiï¼š{', '.join(template['emojis'])}
- è¯­è°ƒï¼š{template['tone']}

è¯·ç”Ÿæˆ3ä¸ªå€™é€‰æ ‡é¢˜ï¼ŒæŒ‰æ¨èåº¦æ’åºï¼Œæ ¼å¼ï¼š
1. [æœ€æ¨èæ ‡é¢˜]
2. [æ¬¡æ¨èæ ‡é¢˜] 
3. [å¤‡é€‰æ ‡é¢˜]

è¦æ±‚æ ‡é¢˜è¦æœ‰å¸å¼•åŠ›ã€å‡†ç¡®æ€§å’Œå¹³å°é€‚åº”æ€§ã€‚
        """
        
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šçš„æ–°åª’ä½“æ ‡é¢˜ä¼˜åŒ–ä¸“å®¶ï¼Œæ“…é•¿ä¸ºä¸åŒå¹³å°åˆ›ä½œå¸å¼•äººçš„æ ‡é¢˜ã€‚"},
            {"role": "user", "content": prompt}
        ]
        
        response = await self.call_deepseek_api(messages)
        
        # æå–ç¬¬ä¸€ä¸ªæ ‡é¢˜
        lines = response.strip().split('\n')
        for line in lines:
            if line.strip().startswith('1.'):
                title = re.sub(r'^1\.?\s*', '', line.strip())
                return title[:template['max_title_length']]
        
        # å¦‚æœæå–å¤±è´¥ï¼Œè¿”å›åŸæ ‡é¢˜çš„ä¼˜åŒ–ç‰ˆæœ¬
        return f"{template['emojis'][0]} {news.title[:template['max_title_length']-3]}"

    async def format_content(self, news: NewsItem, platform: Platform, optimized_title: str) -> str:
        """æ ¼å¼åŒ–å†…å®¹"""
        if platform == Platform.WECHAT:
            return await self._format_wechat_content(news, optimized_title)
        elif platform == Platform.XIAOHONGSHU:
            return await self._format_xiaohongshu_content(news, optimized_title)
        else:
            return news.content

    async def _format_wechat_content(self, news: NewsItem, title: str) -> str:
        """æ ¼å¼åŒ–å¾®ä¿¡å…¬ä¼—å·å†…å®¹"""
        prompt = f"""
è¯·å°†ä»¥ä¸‹AIæ–°é—»é‡å†™ä¸ºä¸“ä¸šçš„å¾®ä¿¡å…¬ä¼—å·æ–‡ç« ï¼š

æ ‡é¢˜ï¼š{title}
åŸå§‹å†…å®¹ï¼š{news.content}
æ¥æºï¼š{news.source}
å‘å¸ƒæ—¶é—´ï¼š{news.published_time.strftime('%Y-%m-%d %H:%M')}

è¦æ±‚ï¼š
1. ç»“æ„æ¸…æ™°ï¼ŒåŒ…å«ï¼šæ ¸å¿ƒè¦ç‚¹ã€è¯¦ç»†è§£è¯»ã€è¡Œä¸šå½±å“ã€æ€»ç»“
2. è¯­è¨€ä¸“ä¸šä½†æ˜“æ‡‚ï¼Œé€‚åˆå•†åŠ¡è¯»è€…
3. é€‚å½“ä½¿ç”¨æ•°æ®å’Œå¼•ç”¨å¢å¼ºå¯ä¿¡åº¦
4. é•¿åº¦æ§åˆ¶åœ¨800-1200å­—
5. ä½¿ç”¨markdownæ ¼å¼ï¼ŒåŒ…å«åˆé€‚çš„æ ‡é¢˜å±‚çº§
6. åœ¨æ–‡æœ«æ³¨æ˜ä¿¡æ¯æ¥æº

è¯·ç¡®ä¿å†…å®¹å‡†ç¡®ã€æœ‰ä»·å€¼ã€æ˜“äºé˜…è¯»ã€‚
        """
        
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šçš„å•†ä¸šåª’ä½“ç¼–è¾‘ï¼Œæ“…é•¿å°†æ–°é—»ä¿¡æ¯æ”¹å†™ä¸ºé«˜è´¨é‡çš„å…¬ä¼—å·æ–‡ç« ã€‚"},
            {"role": "user", "content": prompt}
        ]
        
        return await self.call_deepseek_api(messages)

    async def _format_xiaohongshu_content(self, news: NewsItem, title: str) -> str:
        """æ ¼å¼åŒ–å°çº¢ä¹¦å†…å®¹"""
        prompt = f"""
è¯·å°†ä»¥ä¸‹AIæ–°é—»é‡å†™ä¸ºå°çº¢ä¹¦é£æ ¼çš„å†…å®¹ï¼š

æ ‡é¢˜ï¼š{title}
åŸå§‹å†…å®¹ï¼š{news.content}
æ¥æºï¼š{news.source}

è¦æ±‚ï¼š
1. å¹´è½»åŒ–ã€å£è¯­åŒ–çš„è¡¨è¾¾æ–¹å¼
2. å¤§é‡ä½¿ç”¨emojiï¼Œå¢åŠ è§†è§‰æ•ˆæœ
3. åˆ†æ®µæ¸…æ™°ï¼Œæ¯æ®µä¸è¶…è¿‡2è¡Œ
4. åŒ…å«äº’åŠ¨å…ƒç´ ï¼ˆæé—®ã€å¾æ±‚æ„è§ç­‰ï¼‰
5. é•¿åº¦300-500å­—
6. ç»“å°¾åŒ…å«ç›¸å…³è¯é¢˜æ ‡ç­¾ï¼ˆ#æ ‡ç­¾ï¼‰
7. åˆ¶é€ è¯é¢˜æ€§å’Œè®¨è®ºåº¦

é£æ ¼å‚è€ƒï¼šåƒæœ‹å‹åˆ†äº«æ¶ˆæ¯ä¸€æ ·è‡ªç„¶äº²åˆ‡ã€‚
        """
        
        messages = [
            {"role": "system", "content": "ä½ æ˜¯å¹´è½»çš„å°çº¢ä¹¦åšä¸»ï¼Œæ“…é•¿ç”¨è½»æ¾æ´»æ³¼çš„æ–¹å¼åˆ†äº«ç§‘æŠ€èµ„è®¯ã€‚"},
            {"role": "user", "content": prompt}
        ]
        
        return await self.call_deepseek_api(messages)

    def extract_tags(self, news: NewsItem, content: str) -> List[str]:
        """æå–æ ‡ç­¾"""
        tags = []
        
        # åŸºäºå†…å®¹æå–å…³é”®è¯
        text = (news.title + " " + content).lower()
        
        # æŠ€æœ¯æ ‡ç­¾
        tech_tags = {
            "gpt": "GPT", "claude": "Claude", "chatgpt": "ChatGPT",
            "openai": "OpenAI", "google": "Google", "ç™¾åº¦": "ç™¾åº¦",
            "å¤§æ¨¡å‹": "å¤§æ¨¡å‹", "llm": "LLM", "ai": "äººå·¥æ™ºèƒ½",
            "æœºå™¨å­¦ä¹ ": "æœºå™¨å­¦ä¹ ", "æ·±åº¦å­¦ä¹ ": "æ·±åº¦å­¦ä¹ ",
            "è‡ªç„¶è¯­è¨€": "NLP", "è®¡ç®—æœºè§†è§‰": "è®¡ç®—æœºè§†è§‰",
            "è‡ªåŠ¨é©¾é©¶": "è‡ªåŠ¨é©¾é©¶", "æœºå™¨äºº": "æœºå™¨äºº"
        }
        
        for keyword, tag in tech_tags.items():
            if keyword in text and tag not in tags:
                tags.append(tag)
        
        # äº‹ä»¶ç±»å‹æ ‡ç­¾
        if any(word in text for word in ["å‘å¸ƒ", "æ¨å‡º", "ä¸Šçº¿"]):
            tags.append("äº§å“å‘å¸ƒ")
        if any(word in text for word in ["èèµ„", "æŠ•èµ„", "ä¼°å€¼"]):
            tags.append("èèµ„æŠ•èµ„")
        if any(word in text for word in ["çªç ´", "åˆ›æ–°", "é¦–æ¬¡"]):
            tags.append("æŠ€æœ¯çªç ´")
        
        return tags[:8]  # æœ€å¤š8ä¸ªæ ‡ç­¾

    def generate_hashtags(self, news: NewsItem, platform: Platform) -> List[str]:
        """ç”Ÿæˆè¯é¢˜æ ‡ç­¾"""
        hashtags = []
        
        if platform == Platform.XIAOHONGSHU:
            base_tags = ["AIæ–°é—»", "äººå·¥æ™ºèƒ½", "ç§‘æŠ€å‰æ²¿", "æœªæ¥ç§‘æŠ€"]
            
            # åŸºäºæ ‡é¢˜å†…å®¹æ·»åŠ ç‰¹å®šæ ‡ç­¾
            title_lower = news.title.lower()
            if "gpt" in title_lower:
                hashtags.append("GPT")
            if "openai" in title_lower:
                hashtags.append("OpenAI")
            if any(word in title_lower for word in ["å‘å¸ƒ", "æ¨å‡º"]):
                hashtags.append("æ–°å“å‘å¸ƒ")
            if any(word in title_lower for word in ["çªç ´", "åˆ›æ–°"]):
                hashtags.append("ç§‘æŠ€çªç ´")
                
            hashtags.extend(base_tags)
            
        elif platform == Platform.WECHAT:
            hashtags = ["AIèµ„è®¯", "ç§‘æŠ€åŠ¨æ€", "è¡Œä¸šè§‚å¯Ÿ"]
        
        return list(set(hashtags))[:6]  # å»é‡ï¼Œæœ€å¤š6ä¸ª

    def calculate_engagement_score(self, news: NewsItem, processed_content: str) -> float:
        """è®¡ç®—é¢„ä¼°äº’åŠ¨åº¦"""
        score = 0.0
        
        # åŸºç¡€çƒ­åº¦
        score += news.heat_score * 0.3
        
        # å†…å®¹è´¨é‡å› å­
        if len(processed_content) > 500:
            score += 20
        elif len(processed_content) > 300:
            score += 10
            
        # æ ‡é¢˜å¸å¼•åŠ›
        title_factors = ["å‘å¸ƒ", "çªç ´", "é¦–æ¬¡", "é‡ç£…", "éœ‡æ’¼", "æ›å…‰"]
        for factor in title_factors:
            if factor in news.title:
                score += 8
        
        # æ—¶æ•ˆæ€§
        hours_ago = (datetime.now() - news.published_time).total_seconds() / 3600
        if hours_ago <= 2:
            score += 15
        elif hours_ago <= 6:
            score += 10
        elif hours_ago <= 12:
            score += 5
            
        return min(score, 100)

    def generate_thumbnail_prompt(self, news: NewsItem) -> str:
        """ç”Ÿæˆé…å›¾æç¤ºè¯"""
        # åŸºäºæ ‡é¢˜å’Œå†…å®¹ç”Ÿæˆå›¾ç‰‡æè¿°
        title_lower = news.title.lower()
        
        base_style = "professional, high-tech, modern, clean background"
        
        if any(word in title_lower for word in ["gpt", "chatgpt", "aiåŠ©æ‰‹"]):
            return f"AI chatbot interface, digital brain, neural network, {base_style}"
        elif any(word in title_lower for word in ["æœºå™¨äºº", "robot"]):
            return f"advanced humanoid robot, futuristic design, white background, {base_style}"
        elif any(word in title_lower for word in ["è‡ªåŠ¨é©¾é©¶", "autonomous"]):
            return f"self-driving car with sensors, LiDAR visualization, {base_style}"
        elif any(word in title_lower for word in ["èŠ¯ç‰‡", "chip", "å¤„ç†å™¨"]):
            return f"computer chip, circuit board, microprocessor, {base_style}"
        elif any(word in title_lower for word in ["æ•°æ®", "data", "ç®—æ³•"]):
            return f"data visualization, flowing data streams, algorithms, {base_style}"
        else:
            return f"artificial intelligence concept, digital technology, {base_style}"

    async def process_news(self, news: NewsItem, platform: Platform) -> ProcessedContent:
        """å¤„ç†å•æ¡æ–°é—»"""
        logger.info(f"ğŸ§  å¤„ç†æ–°é—»: {news.title[:50]}... -> {platform.value}")
        
        # ä¼˜åŒ–æ ‡é¢˜
        optimized_title = await self.optimize_title(news, platform)
        
        # æ ¼å¼åŒ–å†…å®¹
        formatted_content = await self.format_content(news, platform, optimized_title)
        
        # æå–æ ‡ç­¾
        tags = self.extract_tags(news, formatted_content)
        
        # ç”Ÿæˆè¯é¢˜æ ‡ç­¾
        hashtags = self.generate_hashtags(news, platform)
        
        # ç”Ÿæˆæ‘˜è¦
        summary = formatted_content[:150] + "..." if len(formatted_content) > 150 else formatted_content
        
        # è®¡ç®—é¢„ä¼°é˜…è¯»æ—¶é—´ï¼ˆæŒ‰æ¯åˆ†é’Ÿ200å­—è®¡ç®—ï¼‰
        reading_time = max(30, len(formatted_content) // 200 * 60)
        
        # è®¡ç®—äº’åŠ¨åº¦
        engagement_score = self.calculate_engagement_score(news, formatted_content)
        
        # ç”Ÿæˆé…å›¾æç¤º
        thumbnail_prompt = self.generate_thumbnail_prompt(news)
        
        processed = ProcessedContent(
            original_news=news,
            platform=platform,
            optimized_title=optimized_title,
            formatted_content=formatted_content,
            tags=tags,
            hashtags=hashtags,
            summary=summary,
            reading_time=reading_time,
            engagement_score=engagement_score,
            thumbnail_prompt=thumbnail_prompt
        )
        
        logger.info(f"âœ… å¤„ç†å®Œæˆ: {optimized_title[:30]}...")
        return processed

    async def batch_process(self, news_list: List[NewsItem], platforms: List[Platform] = None) -> Dict[Platform, List[ProcessedContent]]:
        """æ‰¹é‡å¤„ç†æ–°é—»"""
        if platforms is None:
            platforms = [Platform.WECHAT, Platform.XIAOHONGSHU]
        
        results = {platform: [] for platform in platforms}
        
        # åˆ›å»ºæ‰€æœ‰ä»»åŠ¡
        tasks = []
        for news in news_list[:20]:  # é™åˆ¶å¤„ç†æ•°é‡
            for platform in platforms:
                tasks.append(self.process_news(news, platform))
        
        logger.info(f"ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç†: {len(news_list)}æ¡æ–°é—» x {len(platforms)}ä¸ªå¹³å°")
        
        # å¹¶å‘æ‰§è¡Œ
        processed_results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # æ•´ç†ç»“æœ
        task_index = 0
        for news in news_list[:20]:
            for platform in platforms:
                result = processed_results[task_index]
                if isinstance(result, ProcessedContent):
                    results[platform].append(result)
                else:
                    logger.error(f"å¤„ç†å¤±è´¥: {result}")
                task_index += 1
        
        # æŒ‰äº’åŠ¨åº¦æ’åº
        for platform in platforms:
            results[platform].sort(key=lambda x: x.engagement_score, reverse=True)
        
        logger.info(f"âœ… æ‰¹é‡å¤„ç†å®Œæˆ!")
        return results

    def save_processed_content(self, results: Dict[Platform, List[ProcessedContent]], filename: str = None):
        """ä¿å­˜å¤„ç†ç»“æœ"""
        if filename is None:
            filename = f"processed_content_{datetime.now().strftime('%Y%m%d_%H%M')}.json"
        
        # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–æ ¼å¼
        data = {
            "processed_time": datetime.now().isoformat(),
            "platforms": {}
        }
        
        for platform, content_list in results.items():
            data["platforms"][platform.value] = {
                "count": len(content_list),
                "content": [item.to_dict() for item in content_list]
            }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2, default=str)
        
        logger.info(f"ğŸ“ å¤„ç†ç»“æœå·²ä¿å­˜åˆ°: {filename}")
        return filename

# æµ‹è¯•å‡½æ•°
async def test_content_processor():
    """æµ‹è¯•å†…å®¹å¤„ç†å™¨"""
    from news_spider import collect_realtime_news
    
    # æ”¶é›†æ–°é—»
    news_items = await collect_realtime_news()
    
    # å¤„ç†å†…å®¹
    processor = AIContentProcessor()
    results = await processor.batch_process(news_items[:5])  # æµ‹è¯•å‰5æ¡
    
    # ä¿å­˜ç»“æœ
    processor.save_processed_content(results)
    
    # å±•ç¤ºç»“æœ
    print("\nğŸ¨ å†…å®¹å¤„ç†ç»“æœé¢„è§ˆ:")
    print("=" * 80)
    
    for platform, content_list in results.items():
        print(f"\nğŸ“± {platform.value.upper()} å¹³å°æ ¼å¼:")
        print("-" * 60)
        
        for i, content in enumerate(content_list[:3], 1):
            print(f"{i}. æ ‡é¢˜: {content.optimized_title}")
            print(f"   çƒ­åº¦: {content.engagement_score:.1f}åˆ† | é˜…è¯»: {content.reading_time}ç§’")
            print(f"   æ ‡ç­¾: {', '.join(content.tags)}")
            print(f"   è¯é¢˜: {', '.join(content.hashtags)}")
            print(f"   å†…å®¹: {content.formatted_content[:100]}...")
            print()

if __name__ == "__main__":
    asyncio.run(test_content_processor())