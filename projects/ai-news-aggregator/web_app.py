"""
ğŸŒ AIæ™ºèƒ½æ–°é—»èšåˆå¹³å° - Web APIæœåŠ¡
æä¾›RESTful APIå’ŒWebç•Œé¢
"""

from fastapi import FastAPI, HTTPException, BackgroundTasks, Request
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse, JSONResponse, FileResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Dict, Optional
import asyncio
import json
import os
import logging
from datetime import datetime
import uvicorn

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from news_spider import NewsSpider, collect_realtime_news
from content_processor import AIContentProcessor, Platform
from image_generator import AIImageGenerator
from viral_article_generator import ViralArticleGenerator

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="AIæ™ºèƒ½æ–°é—»èšåˆå¹³å°",
    description="è¶…è¶Šé‡å­ä½ã€æœºå™¨ä¹‹å¿ƒçš„å…¨è‡ªåŠ¨åŒ–AIæ–°é—»æ”¶é›†å’Œå†…å®¹ç”Ÿæˆç³»ç»Ÿ",
    version="1.0.0",
    docs_url="/api/docs",
    redoc_url="/api/redoc"
)

# é…ç½®CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å…¨å±€å˜é‡
cached_news = []
cached_processed_content = {}
last_update_time = None

# åˆå§‹åŒ–æœåŠ¡ç»„ä»¶
content_processor = AIContentProcessor()
image_generator = AIImageGenerator()
viral_generator = ViralArticleGenerator(content_processor)

# è¯·æ±‚æ¨¡å‹
class NewsRequest(BaseModel):
    """æ–°é—»è¯·æ±‚æ¨¡å‹"""
    limit: int = 20
    platform: str = "wechat"
    refresh: bool = False

class ContentRequest(BaseModel):
    """å†…å®¹å¤„ç†è¯·æ±‚æ¨¡å‹"""
    news_ids: List[str]
    platforms: List[str] = ["wechat", "xiaohongshu"]

class ExportRequest(BaseModel):
    """å¯¼å‡ºè¯·æ±‚æ¨¡å‹"""
    content_id: str
    platform: str
    format: str = "markdown"

class ViralArticleRequest(BaseModel):
    """çˆ†æ¬¾æ–‡ç« ç”Ÿæˆè¯·æ±‚æ¨¡å‹"""
    topic: str
    platform: str = "wechat"
    template_type: Optional[str] = None

class BatchViralRequest(BaseModel):
    """æ‰¹é‡çˆ†æ¬¾æ–‡ç« ç”Ÿæˆè¯·æ±‚æ¨¡å‹"""
    topics: List[str]
    count: int = 3
    platforms: List[str] = ["wechat", "xiaohongshu"]

# APIè·¯ç”±
@app.get("/", response_class=HTMLResponse)
async def root():
    """ä¸»é¡µ"""
    try:
        with open("static/index.html", "r", encoding="utf-8") as f:
            return HTMLResponse(f.read())
    except FileNotFoundError:
        return HTMLResponse("""
        <html>
        <head><title>AIæ–°é—»èšåˆå¹³å°</title></head>
        <body>
            <h1>ğŸ¤– AIæ™ºèƒ½æ–°é—»èšåˆå¹³å°</h1>
            <p>ç³»ç»Ÿæ­£åœ¨å¯åŠ¨ä¸­...</p>
            <p>APIæ–‡æ¡£: <a href="/api/docs">/api/docs</a></p>
            <p>ç³»ç»ŸçŠ¶æ€: <a href="/api/health">/api/health</a></p>
            <p>æœ€æ–°æ–°é—»: <a href="/api/news/latest">/api/news/latest</a></p>
        </body>
        </html>
        """)

@app.get("/api/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "ok",
        "timestamp": datetime.now().isoformat(),
        "version": "1.0.0",
        "services": {
            "news_spider": "running",
            "content_processor": "running", 
            "image_generator": "running",
            "viral_generator": "running"
        }
    }

@app.get("/api/news/latest")
async def get_latest_news(limit: int = 20, refresh: bool = False):
    """è·å–æœ€æ–°AIæ–°é—»"""
    global cached_news, last_update_time
    
    try:
        # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ·æ–°
        if refresh or not cached_news or not last_update_time or \
           (datetime.now() - last_update_time).seconds > 1800:  # 30åˆ†é’Ÿæ›´æ–°ä¸€æ¬¡
            
            logger.info("ğŸ”„ åˆ·æ–°æ–°é—»æ•°æ®...")
            cached_news = await collect_realtime_news()
            last_update_time = datetime.now()
        
        # è¿”å›é™åˆ¶æ•°é‡çš„æ–°é—»
        news_data = []
        for news in cached_news[:limit]:
            news_dict = {
                "id": news.id,
                "title": news.title,
                "content": news.content,
                "url": news.url,
                "source": news.source,
                "published_time": news.published_time.isoformat(),
                "author": news.author,
                "tags": news.tags,
                "heat_score": news.heat_score,
                "language": news.language,
                "content_type": news.content_type
            }
            news_data.append(news_dict)
        
        return {
            "success": True,
            "data": news_data,
            "total": len(cached_news),
            "last_update": last_update_time.isoformat() if last_update_time else None,
            "message": f"è·å–åˆ° {len(news_data)} æ¡AIæ–°é—»"
        }
        
    except Exception as e:
        logger.error(f"è·å–æ–°é—»å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–æ–°é—»å¤±è´¥: {str(e)}")

@app.post("/api/content/process")
async def process_content(request: ContentRequest):
    """å¤„ç†æ–°é—»å†…å®¹å¹¶ç”Ÿæˆé…å›¾"""
    global cached_news, cached_processed_content
    
    try:
        # æ ¹æ®IDç­›é€‰æ–°é—»
        selected_news = []
        for news in cached_news:
            if news.id in request.news_ids:
                selected_news.append(news)
        
        if not selected_news:
            raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°æŒ‡å®šçš„æ–°é—»")
        
        # å¤„ç†å†…å®¹
        processor = AIContentProcessor()
        platforms = [Platform(p) for p in request.platforms]
        results = await processor.batch_process(selected_news, platforms)
        
        # ç”Ÿæˆé…å›¾
        generated_images = {}
        for platform_str in request.platforms:
            generated_images[platform_str] = []
            
            # ä¸ºæ¯ä¸ªæ–°é—»ç”Ÿæˆé…å›¾
            for news in selected_news:
                try:
                    image = await image_generator.generate_image_for_news(
                        news.title, 
                        news.content[:200],  # ä½¿ç”¨å‰200å­—ç¬¦
                        platform_str
                    )
                    
                    # ç¡®ä¿ç›®å½•å­˜åœ¨
                    import os
                    os.makedirs(f"static/images/{platform_str}", exist_ok=True)
                    
                    # ä¿å­˜å›¾ç‰‡
                    image_path = image.save_to_file(f"static/images/{platform_str}")
                    
                    generated_images[platform_str].append({
                        "news_id": news.id,
                        "image_path": image_path,
                        "image_url": f"/static/images/{platform_str}/{image.filename}",
                        "image_source": image.source,
                        "size_kb": image.size_kb,
                        "prompt": image.prompt
                    })
                    
                except Exception as e:
                    logger.error(f"ä¸ºæ–°é—» {news.id} ç”Ÿæˆé…å›¾å¤±è´¥: {e}")
                    # æ·»åŠ å ä½ç¬¦
                    generated_images[platform_str].append({
                        "news_id": news.id,
                        "image_path": None,
                        "image_url": None,
                        "image_source": "failed",
                        "size_kb": 0,
                        "error": str(e)
                    })
        
        # ç¼“å­˜ç»“æœ
        for platform, content_list in results.items():
            platform_key = platform.value
            if platform_key not in cached_processed_content:
                cached_processed_content[platform_key] = []
            
            for content in content_list:
                content_dict = content.to_dict()
                content_dict["processed_time"] = datetime.now().isoformat()
                cached_processed_content[platform_key].append(content_dict)
        
        # æ ¼å¼åŒ–è¿”å›æ•°æ®
        response_data = {}
        for platform, content_list in results.items():
            platform_key = platform.value
            response_data[platform_key] = []
            
            for content in content_list:
                # æŸ¥æ‰¾å¯¹åº”çš„é…å›¾
                image_info = None
                for img in generated_images.get(platform_key, []):
                    if img["news_id"] == content.original_news.id:
                        image_info = img
                        break
                
                response_data[platform_key].append({
                    "id": f"{content.original_news.id}_{platform_key}",
                    "original_title": content.original_news.title,
                    "optimized_title": content.optimized_title,
                    "formatted_content": content.formatted_content,
                    "tags": content.tags,
                    "hashtags": content.hashtags,
                    "engagement_score": content.engagement_score,
                    "reading_time": content.reading_time,
                    "thumbnail_prompt": content.thumbnail_prompt,
                    "generated_image": image_info,  # æ–°å¢ï¼šé…å›¾ä¿¡æ¯
                    "processed_time": datetime.now().isoformat()
                })
        
        return {
            "success": True,
            "data": response_data,
            "processed_count": len(selected_news),
            "platforms": request.platforms,
            "images_generated": sum(len(imgs) for imgs in generated_images.values()),
            "message": "å†…å®¹å¤„ç†å’Œé…å›¾ç”Ÿæˆå®Œæˆ"
        }
        
    except Exception as e:
        logger.error(f"å†…å®¹å¤„ç†å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"å†…å®¹å¤„ç†å¤±è´¥: {str(e)}")

@app.post("/api/images/generate")
async def generate_images(background_tasks: BackgroundTasks, news_ids: List[str], platforms: List[str] = ["wechat"]):
    """ç”Ÿæˆé…å›¾"""
    global cached_news
    
    try:
        # ç­›é€‰æ–°é—»
        selected_news = []
        for news in cached_news:
            if news.id in news_ids:
                selected_news.append({
                    "title": news.title,
                    "content": news.content,
                    "id": news.id
                })
        
        if not selected_news:
            raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°æŒ‡å®šçš„æ–°é—»")
        
        # ç”Ÿæˆå›¾ç‰‡
        generator = AIImageGenerator()
        results = await generator.batch_generate_images(selected_news, platforms)
        
        # ä¿å­˜å›¾ç‰‡
        saved_files = generator.save_generated_images(results)
        
        return {
            "success": True,
            "data": saved_files,
            "generated_count": len(selected_news),
            "platforms": platforms,
            "message": "é…å›¾ç”Ÿæˆå®Œæˆ"
        }
        
    except Exception as e:
        logger.error(f"é…å›¾ç”Ÿæˆå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"é…å›¾ç”Ÿæˆå¤±è´¥: {str(e)}")

@app.get("/api/content/export/{content_id}/{platform}")
async def export_content(content_id: str, platform: str, format: str = "markdown"):
    """å¯¼å‡ºå†…å®¹"""
    global cached_processed_content
    
    try:
        if platform not in cached_processed_content:
            raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°æŒ‡å®šå¹³å°çš„å†…å®¹")
        
        # æŸ¥æ‰¾å†…å®¹
        content_item = None
        for item in cached_processed_content[platform]:
            if f"{item['original_news']['id']}_{platform}" == content_id:
                content_item = item
                break
        
        if not content_item:
            raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°æŒ‡å®šå†…å®¹")
        
        # æ ¼å¼åŒ–å¯¼å‡ºå†…å®¹
        if format == "markdown":
            export_content = content_item["formatted_content"]
        elif format == "html":
            # ç®€å•çš„HTMLæ ¼å¼åŒ–
            export_content = f"""
<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>{content_item['optimized_title']}</title>
    <style>
        body {{ font-family: Arial, sans-serif; max-width: 800px; margin: 0 auto; padding: 20px; }}
        h1 {{ color: #333; }}
        .meta {{ color: #666; font-size: 14px; margin-bottom: 20px; }}
        .tags {{ margin-top: 20px; }}
        .tag {{ background: #e3f2fd; padding: 4px 8px; margin: 2px; border-radius: 4px; font-size: 12px; }}
    </style>
</head>
<body>
    <h1>{content_item['optimized_title']}</h1>
    <div class="meta">
        <p>äº’åŠ¨è¯„åˆ†: {content_item['engagement_score']:.1f}åˆ† | é˜…è¯»æ—¶é—´: {content_item['reading_time']}ç§’</p>
        <p>æ ‡ç­¾: {', '.join(content_item['tags'])}</p>
    </div>
    <div class="content">
        {content_item['formatted_content'].replace(chr(10), '<br>')}
    </div>
    <div class="tags">
        è¯é¢˜: {' '.join(['#' + tag for tag in content_item['hashtags']])}
    </div>
</body>
</html>
            """.strip()
        else:
            export_content = content_item["formatted_content"]
        
        return {
            "success": True,
            "data": {
                "content": export_content,
                "title": content_item["optimized_title"],
                "format": format,
                "platform": platform,
                "export_time": datetime.now().isoformat()
            },
            "message": "å†…å®¹å¯¼å‡ºæˆåŠŸ"
        }
        
    except Exception as e:
        logger.error(f"å†…å®¹å¯¼å‡ºå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"å†…å®¹å¯¼å‡ºå¤±è´¥: {str(e)}")

@app.get("/api/images/{platform}/{filename}")
async def get_image(platform: str, filename: str):
    """è·å–ç”Ÿæˆçš„å›¾ç‰‡"""
    image_path = f"generated_images/{platform}/{filename}"
    
    if os.path.exists(image_path):
        return FileResponse(image_path)
    else:
        raise HTTPException(status_code=404, detail="å›¾ç‰‡ä¸å­˜åœ¨")

@app.get("/api/stats")
async def get_stats():
    """è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
    global cached_news, cached_processed_content, last_update_time
    
    try:
        # ç»Ÿè®¡æ•°æ®
        total_news = len(cached_news)
        processed_count = sum(len(items) for items in cached_processed_content.values())
        
        # çƒ­åº¦åˆ†å¸ƒ
        heat_distribution = {"high": 0, "medium": 0, "low": 0}
        for news in cached_news:
            if news.heat_score >= 70:
                heat_distribution["high"] += 1
            elif news.heat_score >= 40:
                heat_distribution["medium"] += 1
            else:
                heat_distribution["low"] += 1
        
        # æ¥æºåˆ†å¸ƒ
        source_distribution = {}
        for news in cached_news:
            source_distribution[news.source] = source_distribution.get(news.source, 0) + 1
        
        return {
            "success": True,
            "data": {
                "total_news": total_news,
                "processed_content": processed_count,
                "last_update": last_update_time.isoformat() if last_update_time else None,
                "heat_distribution": heat_distribution,
                "source_distribution": source_distribution,
                "platforms": list(cached_processed_content.keys()),
                "uptime_hours": 24  # ç®€åŒ–ç»Ÿè®¡
            },
            "message": "ç»Ÿè®¡ä¿¡æ¯è·å–æˆåŠŸ"
        }
        
    except Exception as e:
        logger.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}")

# é™æ€æ–‡ä»¶æœåŠ¡
app.mount("/static", StaticFiles(directory="static"), name="static")

# ğŸ”¥ æ–°å¢ï¼šçˆ†æ¬¾æ–‡ç« ç”ŸæˆAPI
@app.post("/api/viral/generate")
async def generate_viral_article(request: ViralArticleRequest):
    """ç”Ÿæˆå•ç¯‡çˆ†æ¬¾æ–‡ç« """
    try:
        logger.info(f"ğŸ”¥ ç”Ÿæˆçˆ†æ¬¾æ–‡ç« è¯·æ±‚: {request.topic}")
        
        article = await viral_generator.generate_viral_article(
            topic=request.topic,
            platform=request.platform,
            template_type=request.template_type
        )
        
        return {
            "status": "success",
            "data": {
                "title": article.title,
                "content": article.content,
                "platform": article.platform,
                "viral_score": article.viral_score,
                "predicted_views": article.predicted_views,
                "engagement_rate": article.engagement_rate,
                "optimization_tips": article.optimization_tips,
                "risk_factors": article.risk_factors,
                "best_publish_time": article.best_publish_time,
                "target_audience": article.target_audience,
                "trending_keywords": article.trending_keywords,
                "generated_time": datetime.now().isoformat()
            }
        }
        
    except Exception as e:
        logger.error(f"çˆ†æ¬¾æ–‡ç« ç”Ÿæˆå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"ç”Ÿæˆå¤±è´¥: {str(e)}")

@app.post("/api/viral/auto-generate")
async def auto_generate_viral_articles(count: int = 5, platform: str = "wechat"):
    """æ ¹æ®å½“å‰çƒ­é—¨æ–°é—»è‡ªåŠ¨ç”Ÿæˆçˆ†æ¬¾æ–‡ç« """
    global cached_news
    
    try:
        logger.info(f"ğŸš€ è‡ªåŠ¨ç”Ÿæˆçˆ†æ¬¾æ–‡ç« : åŸºäºçƒ­é—¨æ–°é—»ï¼Œæ•°é‡ {count}")
        
        if not cached_news:
            raise HTTPException(status_code=404, detail="æš‚æ— æ–°é—»æ•°æ®ï¼Œè¯·å…ˆåˆ·æ–°æ–°é—»")
        
        # é€‰æ‹©çƒ­åº¦æœ€é«˜çš„æ–°é—»
        hot_news = sorted(cached_news, key=lambda x: x.heat_score, reverse=True)[:count]
        
        generated_articles = []
        
        for news in hot_news:
            try:
                # åŸºäºæ–°é—»æ ‡é¢˜ç”Ÿæˆçˆ†æ¬¾æ–‡ç« 
                article = await viral_generator.generate_viral_article(
                    topic=news.title,
                    platform=platform,
                    template_type=None  # è‡ªåŠ¨é€‰æ‹©æœ€ä½³æ¨¡æ¿
                )
                
                # ä¸ºæ–‡ç« ç”Ÿæˆé…å›¾
                try:
                    image = await image_generator.generate_image_for_news(
                        news.title, 
                        news.content[:200],
                        platform
                    )
                    
                    # ä¿å­˜å›¾ç‰‡
                    os.makedirs(f"static/images/{platform}", exist_ok=True)
                    image_path = image.save_to_file(f"static/images/{platform}")
                    
                    image_info = {
                        "image_url": f"/static/images/{platform}/{image.filename}",
                        "image_source": image.source,
                        "size_kb": image.size_kb,
                        "prompt": image.prompt
                    }
                except Exception as img_e:
                    logger.warning(f"ä¸ºæ–‡ç« ç”Ÿæˆé…å›¾å¤±è´¥: {img_e}")
                    image_info = None
                
                generated_articles.append({
                    "original_news_id": news.id,
                    "original_title": news.title,
                    "original_source": news.source,
                    "original_heat_score": news.heat_score,
                    "viral_title": article.title,
                    "viral_content": article.content,
                    "platform": article.platform,
                    "viral_score": article.viral_score,
                    "predicted_views": article.predicted_views,
                    "engagement_rate": article.engagement_rate,
                    "best_publish_time": article.best_publish_time,
                    "target_audience": article.target_audience,
                    "trending_keywords": article.trending_keywords,
                    "generated_image": image_info,
                    "generated_time": datetime.now().isoformat()
                })
                
            except Exception as e:
                logger.error(f"ä¸ºæ–°é—» {news.title[:30]}... ç”Ÿæˆçˆ†æ¬¾æ–‡ç« å¤±è´¥: {e}")
                continue
        
        # æŒ‰é¢„æµ‹é˜…è¯»é‡æ’åº
        generated_articles.sort(key=lambda x: x["predicted_views"], reverse=True)
        
        return {
            "status": "success",
            "data": {
                "total_generated": len(generated_articles),
                "articles": generated_articles,
                "summary": {
                    "avg_viral_score": sum(a["viral_score"] for a in generated_articles) / len(generated_articles) if generated_articles else 0,
                    "total_predicted_views": sum(a["predicted_views"] for a in generated_articles),
                    "best_article": generated_articles[0] if generated_articles else None,
                    "articles_with_10k_plus": len([a for a in generated_articles if a["predicted_views"] >= 10000])
                },
                "generated_time": datetime.now().isoformat()
            }
        }
        
    except Exception as e:
        logger.error(f"è‡ªåŠ¨ç”Ÿæˆçˆ†æ¬¾æ–‡ç« å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è‡ªåŠ¨ç”Ÿæˆå¤±è´¥: {str(e)}")

@app.post("/api/viral/batch")
async def generate_batch_viral_articles(request: BatchViralRequest):
    """æ‰¹é‡ç”Ÿæˆçˆ†æ¬¾æ–‡ç« """
    try:
        logger.info(f"ğŸš€ æ‰¹é‡ç”Ÿæˆçˆ†æ¬¾æ–‡ç« : {len(request.topics)} ä¸ªè¯é¢˜")
        
        results = []
        
        for topic in request.topics:
            for platform in request.platforms:
                try:
                    article = await viral_generator.generate_viral_article(topic, platform)
                    
                    results.append({
                        "topic": topic,
                        "title": article.title,
                        "content": article.content,
                        "platform": article.platform,
                        "viral_score": article.viral_score,
                        "predicted_views": article.predicted_views,
                        "engagement_rate": article.engagement_rate,
                        "optimization_tips": article.optimization_tips[:3],  # åªè¿”å›å‰3ä¸ªå»ºè®®
                        "risk_factors": article.risk_factors[:2],  # åªè¿”å›å‰2ä¸ªé£é™©
                        "best_publish_time": article.best_publish_time,
                        "target_audience": article.target_audience,
                        "trending_keywords": article.trending_keywords[:5]  # åªè¿”å›å‰5ä¸ªå…³é”®è¯
                    })
                    
                except Exception as e:
                    logger.error(f"è¯é¢˜ {topic} åœ¨ {platform} å¹³å°ç”Ÿæˆå¤±è´¥: {e}")
                    continue
        
        # æŒ‰é¢„æµ‹é˜…è¯»é‡æ’åº
        results.sort(key=lambda x: x["predicted_views"], reverse=True)
        
        return {
            "status": "success",
            "data": {
                "total_generated": len(results),
                "articles": results,
                "summary": {
                    "avg_viral_score": sum(r["viral_score"] for r in results) / len(results) if results else 0,
                    "total_predicted_views": sum(r["predicted_views"] for r in results),
                    "best_article": results[0] if results else None
                },
                "generated_time": datetime.now().isoformat()
            }
        }
        
    except Exception as e:
        logger.error(f"æ‰¹é‡ç”Ÿæˆå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ‰¹é‡ç”Ÿæˆå¤±è´¥: {str(e)}")

@app.get("/api/viral/templates")
async def get_viral_templates():
    """è·å–çˆ†æ¬¾æ–‡ç« æ¨¡æ¿ç±»å‹"""
    return {
        "status": "success",
        "data": {
            "templates": list(viral_generator.viral_templates.keys()),
            "platforms": list(viral_generator.platform_features.keys()),
            "template_details": {
                name: {
                    "viral_potential": info["viral_potential"],
                    "sample_patterns": info["title_patterns"][:2],  # å‰2ä¸ªç¤ºä¾‹
                    "sample_hooks": info["hooks"][:2]  # å‰2ä¸ªé’©å­
                }
                for name, info in viral_generator.viral_templates.items()
            }
        }
    }

@app.post("/api/viral/optimize")
async def optimize_article(title: str, content: str, platform: str = "wechat"):
    """ä¼˜åŒ–æ–‡ç« ä»¥æå‡çˆ†æ¬¾æ½œåŠ›"""
    try:
        # è®¡ç®—å½“å‰çˆ†æ¬¾æŒ‡æ•°
        current_score = viral_generator.calculate_viral_score(title, content, platform)
        
        # ç”Ÿæˆä¼˜åŒ–å»ºè®®
        optimization_tips = viral_generator.generate_optimization_tips(current_score, title, content, platform)
        
        # é¢„æµ‹é˜…è¯»é‡
        predicted_views = viral_generator.predict_views(current_score, platform, len(content))
        
        # é£é™©è¯„ä¼°
        risk_factors = viral_generator._assess_risks(title, content, "æ·±åº¦è§£æ")
        
        return {
            "status": "success",
            "data": {
                "current_viral_score": current_score,
                "predicted_views": predicted_views,
                "optimization_tips": optimization_tips,
                "risk_factors": risk_factors,
                "trending_keywords": viral_generator._extract_trending_keywords(title, content),
                "best_publish_time": viral_generator._get_best_publish_time(platform),
                "platform_features": viral_generator.platform_features[platform],
                "analysis_time": datetime.now().isoformat()
            }
        }
        
    except Exception as e:
        logger.error(f"æ–‡ç« ä¼˜åŒ–åˆ†æå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"åˆ†æå¤±è´¥: {str(e)}")

# åå°ä»»åŠ¡ï¼šå®šæœŸæ›´æ–°æ–°é—»
async def periodic_news_update():
    """å®šæœŸæ›´æ–°æ–°é—»"""
    global cached_news, last_update_time
    
    while True:
        try:
            await asyncio.sleep(1800)  # 30åˆ†é’Ÿæ›´æ–°ä¸€æ¬¡
            logger.info("ğŸ”„ å®šæœŸæ›´æ–°æ–°é—»...")
            cached_news = await collect_realtime_news()
            last_update_time = datetime.now()
            logger.info(f"âœ… æ–°é—»æ›´æ–°å®Œæˆï¼Œå…± {len(cached_news)} æ¡")
        except Exception as e:
            logger.error(f"å®šæœŸæ›´æ–°å¤±è´¥: {e}")

# å¯åŠ¨æ—¶åˆå§‹åŒ–
@app.on_event("startup")
async def startup_event():
    """å¯åŠ¨äº‹ä»¶"""
    global cached_news, last_update_time
    
    logger.info("ğŸš€ AIæ™ºèƒ½æ–°é—»èšåˆå¹³å°å¯åŠ¨ä¸­...")
    
    # åˆ›å»ºå¿…è¦çš„ç›®å½•
    os.makedirs("generated_images", exist_ok=True)
    os.makedirs("static", exist_ok=True)
    
    # åˆå§‹åŒ–æ–°é—»æ•°æ®
    try:
        cached_news = await collect_realtime_news()
        last_update_time = datetime.now()
        logger.info(f"âœ… åˆå§‹åŒ–å®Œæˆï¼Œè·å–åˆ° {len(cached_news)} æ¡æ–°é—»")
    except Exception as e:
        logger.error(f"åˆå§‹åŒ–å¤±è´¥: {e}")
        cached_news = []
    
    # å¯åŠ¨å®šæœŸæ›´æ–°ä»»åŠ¡
    asyncio.create_task(periodic_news_update())
    
    logger.info("ğŸ‰ ç³»ç»Ÿå¯åŠ¨å®Œæˆï¼è®¿é—® http://localhost:8000")

if __name__ == "__main__":
    uvicorn.run(
        "web_app:app",
        host="127.0.0.1",
        port=8000,
        reload=True,
        log_level="info"
    )