"""
ğŸŒ AIæ™ºèƒ½æ–°é—»èšåˆå¹³å° - Web APIæœåŠ¡
æä¾›RESTful APIå’ŒWebç•Œé¢
"""

from fastapi import FastAPI, HTTPException, BackgroundTasks, Request
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse, JSONResponse, FileResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Dict, Optional
import asyncio
import json
import os
import logging
from datetime import datetime
import uvicorn

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from news_spider import NewsSpider, collect_realtime_news
from content_processor import AIContentProcessor, Platform
from image_generator import AIImageGenerator

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="AIæ™ºèƒ½æ–°é—»èšåˆå¹³å°",
    description="è¶…è¶Šé‡å­ä½ã€æœºå™¨ä¹‹å¿ƒçš„å…¨è‡ªåŠ¨åŒ–AIæ–°é—»æ”¶é›†å’Œå†…å®¹ç”Ÿæˆç³»ç»Ÿ",
    version="1.0.0",
    docs_url="/api/docs",
    redoc_url="/api/redoc"
)

# é…ç½®CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å…¨å±€å˜é‡
cached_news = []
cached_processed_content = {}
last_update_time = None

# è¯·æ±‚æ¨¡å‹
class NewsRequest(BaseModel):
    """æ–°é—»è¯·æ±‚æ¨¡å‹"""
    limit: int = 20
    platform: str = "wechat"
    refresh: bool = False

class ContentRequest(BaseModel):
    """å†…å®¹å¤„ç†è¯·æ±‚æ¨¡å‹"""
    news_ids: List[str]
    platforms: List[str] = ["wechat", "xiaohongshu"]

class ExportRequest(BaseModel):
    """å¯¼å‡ºè¯·æ±‚æ¨¡å‹"""
    content_id: str
    platform: str
    format: str = "markdown"

# APIè·¯ç”±
@app.get("/", response_class=HTMLResponse)
async def root():
    """ä¸»é¡µ"""
    return HTMLResponse(open("static/index.html", encoding="utf-8").read())

@app.get("/api/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "ok",
        "timestamp": datetime.now().isoformat(),
        "version": "1.0.0",
        "services": {
            "news_spider": "running",
            "content_processor": "running", 
            "image_generator": "running"
        }
    }

@app.get("/api/news/latest")
async def get_latest_news(limit: int = 20, refresh: bool = False):
    """è·å–æœ€æ–°AIæ–°é—»"""
    global cached_news, last_update_time
    
    try:
        # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ·æ–°
        if refresh or not cached_news or not last_update_time or \
           (datetime.now() - last_update_time).seconds > 1800:  # 30åˆ†é’Ÿæ›´æ–°ä¸€æ¬¡
            
            logger.info("ğŸ”„ åˆ·æ–°æ–°é—»æ•°æ®...")
            cached_news = await collect_realtime_news()
            last_update_time = datetime.now()
        
        # è¿”å›é™åˆ¶æ•°é‡çš„æ–°é—»
        news_data = []
        for news in cached_news[:limit]:
            news_dict = {
                "id": news.id,
                "title": news.title,
                "content": news.content,
                "url": news.url,
                "source": news.source,
                "published_time": news.published_time.isoformat(),
                "author": news.author,
                "tags": news.tags,
                "heat_score": news.heat_score,
                "language": news.language,
                "content_type": news.content_type
            }
            news_data.append(news_dict)
        
        return {
            "success": True,
            "data": news_data,
            "total": len(cached_news),
            "last_update": last_update_time.isoformat() if last_update_time else None,
            "message": f"è·å–åˆ° {len(news_data)} æ¡AIæ–°é—»"
        }
        
    except Exception as e:
        logger.error(f"è·å–æ–°é—»å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–æ–°é—»å¤±è´¥: {str(e)}")

@app.post("/api/content/process")
async def process_content(request: ContentRequest):
    """å¤„ç†æ–°é—»å†…å®¹"""
    global cached_news, cached_processed_content
    
    try:
        # æ ¹æ®IDç­›é€‰æ–°é—»
        selected_news = []
        for news in cached_news:
            if news.id in request.news_ids:
                selected_news.append(news)
        
        if not selected_news:
            raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°æŒ‡å®šçš„æ–°é—»")
        
        # å¤„ç†å†…å®¹
        processor = AIContentProcessor()
        platforms = [Platform(p) for p in request.platforms]
        results = await processor.batch_process(selected_news, platforms)
        
        # ç¼“å­˜ç»“æœ
        for platform, content_list in results.items():
            platform_key = platform.value
            if platform_key not in cached_processed_content:
                cached_processed_content[platform_key] = []
            
            for content in content_list:
                content_dict = content.to_dict()
                content_dict["processed_time"] = datetime.now().isoformat()
                cached_processed_content[platform_key].append(content_dict)
        
        # æ ¼å¼åŒ–è¿”å›æ•°æ®
        response_data = {}
        for platform, content_list in results.items():
            response_data[platform.value] = []
            for content in content_list:
                response_data[platform.value].append({
                    "id": f"{content.original_news.id}_{platform.value}",
                    "original_title": content.original_news.title,
                    "optimized_title": content.optimized_title,
                    "formatted_content": content.formatted_content,
                    "tags": content.tags,
                    "hashtags": content.hashtags,
                    "engagement_score": content.engagement_score,
                    "reading_time": content.reading_time,
                    "thumbnail_prompt": content.thumbnail_prompt
                })
        
        return {
            "success": True,
            "data": response_data,
            "processed_count": len(selected_news),
            "platforms": request.platforms,
            "message": "å†…å®¹å¤„ç†å®Œæˆ"
        }
        
    except Exception as e:
        logger.error(f"å†…å®¹å¤„ç†å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"å†…å®¹å¤„ç†å¤±è´¥: {str(e)}")

@app.post("/api/images/generate")
async def generate_images(background_tasks: BackgroundTasks, news_ids: List[str], platforms: List[str] = ["wechat"]):
    """ç”Ÿæˆé…å›¾"""
    global cached_news
    
    try:
        # ç­›é€‰æ–°é—»
        selected_news = []
        for news in cached_news:
            if news.id in news_ids:
                selected_news.append({
                    "title": news.title,
                    "content": news.content,
                    "id": news.id
                })
        
        if not selected_news:
            raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°æŒ‡å®šçš„æ–°é—»")
        
        # ç”Ÿæˆå›¾ç‰‡
        generator = AIImageGenerator()
        results = await generator.batch_generate_images(selected_news, platforms)
        
        # ä¿å­˜å›¾ç‰‡
        saved_files = generator.save_generated_images(results)
        
        return {
            "success": True,
            "data": saved_files,
            "generated_count": len(selected_news),
            "platforms": platforms,
            "message": "é…å›¾ç”Ÿæˆå®Œæˆ"
        }
        
    except Exception as e:
        logger.error(f"é…å›¾ç”Ÿæˆå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"é…å›¾ç”Ÿæˆå¤±è´¥: {str(e)}")

@app.get("/api/content/export/{content_id}/{platform}")
async def export_content(content_id: str, platform: str, format: str = "markdown"):
    """å¯¼å‡ºå†…å®¹"""
    global cached_processed_content
    
    try:
        if platform not in cached_processed_content:
            raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°æŒ‡å®šå¹³å°çš„å†…å®¹")
        
        # æŸ¥æ‰¾å†…å®¹
        content_item = None
        for item in cached_processed_content[platform]:
            if f"{item['original_news']['id']}_{platform}" == content_id:
                content_item = item
                break
        
        if not content_item:
            raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°æŒ‡å®šå†…å®¹")
        
        # æ ¼å¼åŒ–å¯¼å‡ºå†…å®¹
        if format == "markdown":
            export_content = content_item["formatted_content"]
        elif format == "html":
            # ç®€å•çš„HTMLæ ¼å¼åŒ–
            export_content = f"""
<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>{content_item['optimized_title']}</title>
    <style>
        body {{ font-family: Arial, sans-serif; max-width: 800px; margin: 0 auto; padding: 20px; }}
        h1 {{ color: #333; }}
        .meta {{ color: #666; font-size: 14px; margin-bottom: 20px; }}
        .tags {{ margin-top: 20px; }}
        .tag {{ background: #e3f2fd; padding: 4px 8px; margin: 2px; border-radius: 4px; font-size: 12px; }}
    </style>
</head>
<body>
    <h1>{content_item['optimized_title']}</h1>
    <div class="meta">
        <p>äº’åŠ¨è¯„åˆ†: {content_item['engagement_score']:.1f}åˆ† | é˜…è¯»æ—¶é—´: {content_item['reading_time']}ç§’</p>
        <p>æ ‡ç­¾: {', '.join(content_item['tags'])}</p>
    </div>
    <div class="content">
        {content_item['formatted_content'].replace(chr(10), '<br>')}
    </div>
    <div class="tags">
        è¯é¢˜: {' '.join(['#' + tag for tag in content_item['hashtags']])}
    </div>
</body>
</html>
            """.strip()
        else:
            export_content = content_item["formatted_content"]
        
        return {
            "success": True,
            "data": {
                "content": export_content,
                "title": content_item["optimized_title"],
                "format": format,
                "platform": platform,
                "export_time": datetime.now().isoformat()
            },
            "message": "å†…å®¹å¯¼å‡ºæˆåŠŸ"
        }
        
    except Exception as e:
        logger.error(f"å†…å®¹å¯¼å‡ºå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"å†…å®¹å¯¼å‡ºå¤±è´¥: {str(e)}")

@app.get("/api/images/{platform}/{filename}")
async def get_image(platform: str, filename: str):
    """è·å–ç”Ÿæˆçš„å›¾ç‰‡"""
    image_path = f"generated_images/{platform}/{filename}"
    
    if os.path.exists(image_path):
        return FileResponse(image_path)
    else:
        raise HTTPException(status_code=404, detail="å›¾ç‰‡ä¸å­˜åœ¨")

@app.get("/api/stats")
async def get_stats():
    """è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
    global cached_news, cached_processed_content, last_update_time
    
    try:
        # ç»Ÿè®¡æ•°æ®
        total_news = len(cached_news)
        processed_count = sum(len(items) for items in cached_processed_content.values())
        
        # çƒ­åº¦åˆ†å¸ƒ
        heat_distribution = {"high": 0, "medium": 0, "low": 0}
        for news in cached_news:
            if news.heat_score >= 70:
                heat_distribution["high"] += 1
            elif news.heat_score >= 40:
                heat_distribution["medium"] += 1
            else:
                heat_distribution["low"] += 1
        
        # æ¥æºåˆ†å¸ƒ
        source_distribution = {}
        for news in cached_news:
            source_distribution[news.source] = source_distribution.get(news.source, 0) + 1
        
        return {
            "success": True,
            "data": {
                "total_news": total_news,
                "processed_content": processed_count,
                "last_update": last_update_time.isoformat() if last_update_time else None,
                "heat_distribution": heat_distribution,
                "source_distribution": source_distribution,
                "platforms": list(cached_processed_content.keys()),
                "uptime_hours": 24  # ç®€åŒ–ç»Ÿè®¡
            },
            "message": "ç»Ÿè®¡ä¿¡æ¯è·å–æˆåŠŸ"
        }
        
    except Exception as e:
        logger.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}")

# é™æ€æ–‡ä»¶æœåŠ¡
app.mount("/static", StaticFiles(directory="static"), name="static")

# åå°ä»»åŠ¡ï¼šå®šæœŸæ›´æ–°æ–°é—»
async def periodic_news_update():
    """å®šæœŸæ›´æ–°æ–°é—»"""
    global cached_news, last_update_time
    
    while True:
        try:
            await asyncio.sleep(1800)  # 30åˆ†é’Ÿæ›´æ–°ä¸€æ¬¡
            logger.info("ğŸ”„ å®šæœŸæ›´æ–°æ–°é—»...")
            cached_news = await collect_realtime_news()
            last_update_time = datetime.now()
            logger.info(f"âœ… æ–°é—»æ›´æ–°å®Œæˆï¼Œå…± {len(cached_news)} æ¡")
        except Exception as e:
            logger.error(f"å®šæœŸæ›´æ–°å¤±è´¥: {e}")

# å¯åŠ¨æ—¶åˆå§‹åŒ–
@app.on_event("startup")
async def startup_event():
    """å¯åŠ¨äº‹ä»¶"""
    global cached_news, last_update_time
    
    logger.info("ğŸš€ AIæ™ºèƒ½æ–°é—»èšåˆå¹³å°å¯åŠ¨ä¸­...")
    
    # åˆ›å»ºå¿…è¦çš„ç›®å½•
    os.makedirs("generated_images", exist_ok=True)
    os.makedirs("static", exist_ok=True)
    
    # åˆå§‹åŒ–æ–°é—»æ•°æ®
    try:
        cached_news = await collect_realtime_news()
        last_update_time = datetime.now()
        logger.info(f"âœ… åˆå§‹åŒ–å®Œæˆï¼Œè·å–åˆ° {len(cached_news)} æ¡æ–°é—»")
    except Exception as e:
        logger.error(f"åˆå§‹åŒ–å¤±è´¥: {e}")
        cached_news = []
    
    # å¯åŠ¨å®šæœŸæ›´æ–°ä»»åŠ¡
    asyncio.create_task(periodic_news_update())
    
    logger.info("ğŸ‰ ç³»ç»Ÿå¯åŠ¨å®Œæˆï¼è®¿é—® http://localhost:8000")

if __name__ == "__main__":
    uvicorn.run(
        "web_app:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )