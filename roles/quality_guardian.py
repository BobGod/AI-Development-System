#!/usr/bin/env python3
"""
AIè‡ªä¸»å¼€å‘ç³»ç»Ÿ - è´¨é‡å®ˆæŠ¤è€…
è´Ÿè´£ä»£ç è´¨é‡æ§åˆ¶ã€é™æ€åˆ†æã€ä»£ç è§„èŒƒæ£€æŸ¥ã€æŠ€æœ¯å€ºåŠ¡ç®¡ç†
"""

import asyncio
import logging
import json
import hashlib
import re
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
from enum import Enum
from dataclasses import dataclass, asdict
import uuid

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from roles.base_role import BaseRole, Task, TaskStatus, RoleState

class QualityLevel(Enum):
    """è´¨é‡ç­‰çº§æšä¸¾"""
    EXCELLENT = "excellent"      # ä¼˜ç§€ (90-100åˆ†)
    GOOD = "good"               # è‰¯å¥½ (80-89åˆ†)  
    ACCEPTABLE = "acceptable"    # å¯æ¥å— (70-79åˆ†)
    POOR = "poor"               # è¾ƒå·® (60-69åˆ†)
    CRITICAL = "critical"       # ä¸¥é‡ (0-59åˆ†)

class IssueType(Enum):
    """é—®é¢˜ç±»å‹æšä¸¾"""
    SECURITY = "security"           # å®‰å…¨é—®é¢˜
    BUG = "bug"                    # åŠŸèƒ½ç¼ºé™·
    CODE_SMELL = "code_smell"      # ä»£ç å¼‚å‘³
    DUPLICATION = "duplication"    # ä»£ç é‡å¤
    COMPLEXITY = "complexity"      # å¤æ‚åº¦é—®é¢˜
    STYLE = "style"               # é£æ ¼é—®é¢˜
    PERFORMANCE = "performance"    # æ€§èƒ½é—®é¢˜
    MAINTAINABILITY = "maintainability"  # å¯ç»´æŠ¤æ€§

class IssueSeverity(Enum):
    """é—®é¢˜ä¸¥é‡ç¨‹åº¦æšä¸¾"""
    BLOCKER = "blocker"      # é˜»æ–­
    CRITICAL = "critical"    # ä¸¥é‡
    MAJOR = "major"         # é‡å¤§
    MINOR = "minor"         # è½»å¾®
    INFO = "info"           # ä¿¡æ¯

class TechDebtType(Enum):
    """æŠ€æœ¯å€ºåŠ¡ç±»å‹æšä¸¾"""
    DESIGN_DEBT = "design_debt"     # è®¾è®¡å€ºåŠ¡
    CODE_DEBT = "code_debt"         # ä»£ç å€ºåŠ¡
    TEST_DEBT = "test_debt"         # æµ‹è¯•å€ºåŠ¡  
    DOC_DEBT = "doc_debt"           # æ–‡æ¡£å€ºåŠ¡
    BUILD_DEBT = "build_debt"       # æ„å»ºå€ºåŠ¡

@dataclass
class QualityIssue:
    """è´¨é‡é—®é¢˜æ•°æ®ç±»"""
    issue_id: str
    issue_type: IssueType
    severity: IssueSeverity
    file_path: str
    line_number: int
    message: str
    rule_id: str
    suggestion: str = ""
    created_at: str = ""
    
    def __post_init__(self):
        if not self.created_at:
            self.created_at = datetime.now().isoformat()

@dataclass
class QualityMetrics:
    """è´¨é‡æŒ‡æ ‡æ•°æ®ç±»"""
    overall_score: float
    maintainability_index: float
    complexity_score: float
    duplication_ratio: float
    test_coverage: float
    security_issues: int
    code_smells: int
    bugs: int
    tech_debt_ratio: float
    lines_of_code: int
    analyzed_at: str = ""
    
    def __post_init__(self):
        if not self.analyzed_at:
            self.analyzed_at = datetime.now().isoformat()

@dataclass  
class TechDebt:
    """æŠ€æœ¯å€ºåŠ¡æ•°æ®ç±»"""
    debt_id: str
    debt_type: TechDebtType
    description: str
    file_path: str
    estimated_hours: float
    priority: str
    status: str = "open"
    assigned_to: str = ""
    created_at: str = ""
    
    def __post_init__(self):
        if not self.created_at:
            self.created_at = datetime.now().isoformat()

class QualityGuardian(BaseRole):
    """è´¨é‡å®ˆæŠ¤è€… - è´Ÿè´£ä»£ç è´¨é‡æ§åˆ¶å’ŒæŠ€æœ¯å€ºåŠ¡ç®¡ç†"""
    
    def __init__(self, config: Optional[Dict] = None):
        super().__init__(
            role_id="quality_guardian",
            role_name="è´¨é‡å®ˆæŠ¤è€…", 
            config=config
        )
        
        # è´¨é‡è§„åˆ™é…ç½®
        self.quality_rules = self._init_quality_rules()
        
        # è´¨é‡æŒ‡æ ‡å­˜å‚¨
        self.quality_metrics: Dict[str, QualityMetrics] = {}
        self.quality_issues: Dict[str, List[QualityIssue]] = {}
        self.tech_debts: Dict[str, TechDebt] = {}
        
        # è´¨é‡é—¨ç¦é…ç½®
        self.quality_gates = self._init_quality_gates()
        
        # åˆ†æå·¥å…·é…ç½®
        self.analysis_tools = self._init_analysis_tools()
        
        # è´¨é‡å†å²è®°å½•
        self.quality_history: List[Dict] = []
        
        # æ¶ˆæ¯å¤„ç†å™¨æ˜ å°„
        self.message_handlers.update({
            'analyze_code': self._handle_analyze_code,
            'check_quality_gates': self._handle_check_quality_gates,  
            'scan_security': self._handle_scan_security,
            'detect_duplicates': self._handle_detect_duplicates,
            'analyze_complexity': self._handle_analyze_complexity,
            'manage_tech_debt': self._handle_manage_tech_debt,
            'generate_quality_report': self._handle_generate_quality_report,
            'update_quality_rules': self._handle_update_quality_rules
        })
        
        self.logger.info(f"{self.role_name} åˆå§‹åŒ–å®Œæˆ")
        
    def _init_quality_rules(self) -> Dict[str, Any]:
        """åˆå§‹åŒ–è´¨é‡è§„åˆ™"""
        return {
            'complexity': {
                'max_cyclomatic_complexity': 10,
                'max_cognitive_complexity': 15,
                'max_function_length': 50,
                'max_class_length': 500
            },
            'duplication': {
                'max_duplication_ratio': 0.05,  # 5%
                'min_duplicate_lines': 6
            },
            'coverage': {
                'min_line_coverage': 0.80,  # 80%
                'min_branch_coverage': 0.75  # 75%
            },
            'maintainability': {
                'min_maintainability_index': 80
            },
            'security': {
                'block_critical_vulnerabilities': True,
                'block_high_vulnerabilities': True,
                'allow_medium_vulnerabilities': 5,
                'allow_low_vulnerabilities': 20
            },
            'style': {
                'enforce_naming_conventions': True,
                'enforce_formatting': True,
                'max_line_length': 120
            }
        }
        
    def _init_quality_gates(self) -> Dict[str, Any]:
        """åˆå§‹åŒ–è´¨é‡é—¨ç¦"""
        return {
            'blocking_conditions': [
                {'type': 'security', 'severity': 'critical', 'threshold': 0},
                {'type': 'security', 'severity': 'high', 'threshold': 0},
                {'type': 'bug', 'severity': 'critical', 'threshold': 0},
                {'type': 'complexity', 'max_increase': 0.1},  # å¤æ‚åº¦å¢é•¿ä¸è¶…è¿‡10%
                {'type': 'coverage', 'min_decrease': 0.05}   # è¦†ç›–ç‡ä¸‹é™ä¸è¶…è¿‡5%
            ],
            'warning_conditions': [
                {'type': 'code_smell', 'severity': 'major', 'threshold': 5},
                {'type': 'duplication', 'max_ratio': 0.03},
                {'type': 'maintainability', 'min_score': 75}
            ]
        }
        
    def _init_analysis_tools(self) -> Dict[str, Any]:
        """åˆå§‹åŒ–åˆ†æå·¥å…·é…ç½®"""
        return {
            'python': {
                'linters': ['pylint', 'flake8', 'bandit', 'mypy'],
                'complexity': ['radon', 'mccabe'],
                'security': ['bandit', 'safety'],
                'style': ['black', 'isort', 'autopep8']
            },
            'javascript': {
                'linters': ['eslint', 'jshint'],
                'complexity': ['complexity-report'],
                'security': ['npm-audit', 'snyk'],
                'style': ['prettier']
            },
            'typescript': {
                'linters': ['tslint', 'eslint'],
                'complexity': ['ts-complexity'],
                'security': ['tslint-config-security'],
                'style': ['prettier']
            },
            'java': {
                'linters': ['spotbugs', 'pmd', 'checkstyle'],
                'complexity': ['pmd'],
                'security': ['spotbugs-security'],
                'style': ['checkstyle']
            }
        }
        
    async def _handle_analyze_code(self, message):
        """å¤„ç†ä»£ç åˆ†æè¯·æ±‚"""
        try:
            data = message.body.data
            file_path = data.get('file_path')
            code_content = data.get('code_content', '')
            language = data.get('language', 'unknown')
            
            self.logger.info(f"å¼€å§‹åˆ†æä»£ç : {file_path}")
            
            # æ‰§è¡Œå¤šç»´åº¦ä»£ç åˆ†æ
            analysis_results = await self._perform_code_analysis(
                file_path, code_content, language
            )
            
            # ç”Ÿæˆè´¨é‡æŒ‡æ ‡
            metrics = await self._calculate_quality_metrics(analysis_results)
            
            # å­˜å‚¨ç»“æœ
            self.quality_metrics[file_path] = metrics
            self.quality_issues[file_path] = analysis_results.get('issues', [])
            
            # è®°å½•å†å²
            self.quality_history.append({
                'file_path': file_path,
                'timestamp': datetime.now().isoformat(),
                'metrics': asdict(metrics),
                'issues_count': len(analysis_results.get('issues', []))
            })
            
            response_data = {
                'file_path': file_path,
                'quality_level': self._determine_quality_level(metrics.overall_score),
                'metrics': asdict(metrics),
                'issues': [asdict(issue) for issue in analysis_results.get('issues', [])],
                'recommendations': analysis_results.get('recommendations', [])
            }
            
            await self._send_response(message, 'quality_analysis_result', response_data)
            self.logger.info(f"ä»£ç åˆ†æå®Œæˆ: {file_path}, è´¨é‡åˆ†æ•°: {metrics.overall_score:.1f}")
            
        except Exception as e:
            self.logger.error(f"ä»£ç åˆ†æå¤±è´¥: {e}")
            await self._send_error_response(message, str(e))
            
    async def _perform_code_analysis(self, file_path: str, code_content: str, language: str) -> Dict[str, Any]:
        """æ‰§è¡Œä»£ç åˆ†æ"""
        issues = []
        recommendations = []
        
        # 1. å¤æ‚åº¦åˆ†æ
        complexity_issues = await self._analyze_complexity(code_content, language)
        issues.extend(complexity_issues)
        
        # 2. é‡å¤ä»£ç æ£€æµ‹
        duplication_issues = await self._detect_duplicates(code_content, file_path)
        issues.extend(duplication_issues)
        
        # 3. å®‰å…¨æ‰«æ
        security_issues = await self._scan_security(code_content, language)
        issues.extend(security_issues)
        
        # 4. ä»£ç é£æ ¼æ£€æŸ¥
        style_issues = await self._check_code_style(code_content, language)
        issues.extend(style_issues)
        
        # 5. ç”Ÿæˆå»ºè®®
        recommendations = await self._generate_recommendations(issues, code_content)
        
        return {
            'issues': issues,
            'recommendations': recommendations,
            'analysis_timestamp': datetime.now().isoformat()
        }
        
    async def _analyze_complexity(self, code_content: str, language: str) -> List[QualityIssue]:
        """åˆ†æä»£ç å¤æ‚åº¦"""
        issues = []
        
        if language == 'python':
            # ç®€åŒ–çš„Pythonå¤æ‚åº¦åˆ†æ
            lines = code_content.split('\n')
            
            for i, line in enumerate(lines, 1):
                line = line.strip()
                
                # æ£€æŸ¥å‡½æ•°é•¿åº¦
                if line.startswith('def '):
                    func_lines = self._count_function_lines(lines, i-1)
                    if func_lines > self.quality_rules['complexity']['max_function_length']:
                        issues.append(QualityIssue(
                            issue_id=str(uuid.uuid4()),
                            issue_type=IssueType.COMPLEXITY,
                            severity=IssueSeverity.MAJOR,
                            file_path="",
                            line_number=i,
                            message=f"å‡½æ•°è¿‡é•¿: {func_lines} è¡Œ (æœ€å¤§ {self.quality_rules['complexity']['max_function_length']} è¡Œ)",
                            rule_id="max_function_length",
                            suggestion="è€ƒè™‘å°†å‡½æ•°æ‹†åˆ†ä¸ºæ›´å°çš„å‡½æ•°"
                        ))
                
                # æ£€æŸ¥åµŒå¥—æ·±åº¦
                indent_level = (len(line) - len(line.lstrip())) // 4
                if indent_level > 4:
                    issues.append(QualityIssue(
                        issue_id=str(uuid.uuid4()),
                        issue_type=IssueType.COMPLEXITY,
                        severity=IssueSeverity.MINOR,
                        file_path="",
                        line_number=i,
                        message=f"åµŒå¥—å±‚æ¬¡è¿‡æ·±: {indent_level} å±‚",
                        rule_id="max_nesting_depth",
                        suggestion="è€ƒè™‘ä½¿ç”¨æ—©æœŸè¿”å›æˆ–æå–å‡½æ•°æ¥å‡å°‘åµŒå¥—"
                    ))
        
        return issues
        
    def _count_function_lines(self, lines: List[str], start_index: int) -> int:
        """è®¡ç®—å‡½æ•°è¡Œæ•°"""
        count = 1
        base_indent = len(lines[start_index]) - len(lines[start_index].lstrip())
        
        for i in range(start_index + 1, len(lines)):
            line = lines[i].strip()
            if not line:  # ç©ºè¡Œ
                continue
                
            current_indent = len(lines[i]) - len(lines[i].lstrip())
            if current_indent <= base_indent and line:
                break
                
            count += 1
            
        return count
        
    async def _detect_duplicates(self, code_content: str, file_path: str) -> List[QualityIssue]:
        """æ£€æµ‹é‡å¤ä»£ç """
        issues = []
        lines = code_content.split('\n')
        
        # ç®€åŒ–çš„é‡å¤æ£€æµ‹ï¼šæŸ¥æ‰¾ç›¸åŒçš„ä»£ç å—
        seen_blocks = {}
        block_size = 6  # æœ€å°é‡å¤å—å¤§å°
        
        for i in range(len(lines) - block_size + 1):
            block = '\n'.join(lines[i:i+block_size])
            block_hash = hashlib.md5(block.encode()).hexdigest()
            
            if block_hash in seen_blocks:
                issues.append(QualityIssue(
                    issue_id=str(uuid.uuid4()),
                    issue_type=IssueType.DUPLICATION,
                    severity=IssueSeverity.MAJOR,
                    file_path=file_path,
                    line_number=i+1,
                    message=f"å‘ç°é‡å¤ä»£ç å— ({block_size} è¡Œ)",
                    rule_id="duplicate_code_block",
                    suggestion="è€ƒè™‘æå–å…¬å…±å‡½æ•°æˆ–ä½¿ç”¨è®¾è®¡æ¨¡å¼æ¶ˆé™¤é‡å¤"
                ))
            else:
                seen_blocks[block_hash] = i+1
                
        return issues
        
    async def _scan_security(self, code_content: str, language: str) -> List[QualityIssue]:
        """æ‰«æå®‰å…¨é—®é¢˜"""
        issues = []
        
        # ç®€åŒ–çš„å®‰å…¨æ‰«æè§„åˆ™
        security_patterns = {
            'hardcoded_password': {
                'pattern': r'password\s*=\s*["\'][^"\']*["\']',
                'message': 'å‘ç°ç¡¬ç¼–ç å¯†ç ',
                'severity': IssueSeverity.CRITICAL
            },
            'sql_injection': {
                'pattern': r'execute\s*\(\s*["\'].*%.*["\']',
                'message': 'å¯èƒ½å­˜åœ¨SQLæ³¨å…¥é£é™©',
                'severity': IssueSeverity.CRITICAL
            },
            'xss_vulnerability': {
                'pattern': r'innerHTML\s*=.*\+',
                'message': 'å¯èƒ½å­˜åœ¨XSSæ¼æ´',
                'severity': IssueSeverity.MAJOR
            }
        }
        
        lines = code_content.split('\n')
        for i, line in enumerate(lines, 1):
            for rule_id, rule in security_patterns.items():
                if re.search(rule['pattern'], line, re.IGNORECASE):
                    issues.append(QualityIssue(
                        issue_id=str(uuid.uuid4()),
                        issue_type=IssueType.SECURITY,
                        severity=rule['severity'],
                        file_path="",
                        line_number=i,
                        message=rule['message'],
                        rule_id=rule_id,
                        suggestion="è¯·ä½¿ç”¨å®‰å…¨çš„ç¼–ç¨‹å®è·µ"
                    ))
                    
        return issues
        
    async def _check_code_style(self, code_content: str, language: str) -> List[QualityIssue]:
        """æ£€æŸ¥ä»£ç é£æ ¼"""
        issues = []
        lines = code_content.split('\n')
        
        for i, line in enumerate(lines, 1):
            # æ£€æŸ¥è¡Œé•¿åº¦
            if len(line) > self.quality_rules['style']['max_line_length']:
                issues.append(QualityIssue(
                    issue_id=str(uuid.uuid4()),
                    issue_type=IssueType.STYLE,
                    severity=IssueSeverity.MINOR,
                    file_path="",
                    line_number=i,
                    message=f"è¡Œé•¿åº¦è¶…é™: {len(line)} å­—ç¬¦ (æœ€å¤§ {self.quality_rules['style']['max_line_length']} å­—ç¬¦)",
                    rule_id="max_line_length",
                    suggestion="è€ƒè™‘æ‹†åˆ†é•¿è¡Œæˆ–ä½¿ç”¨æ›´çŸ­çš„å˜é‡å"
                ))
            
            # æ£€æŸ¥å‘½åè§„èŒƒï¼ˆPythonç¤ºä¾‹ï¼‰
            if language == 'python':
                # æ£€æŸ¥ç±»åï¼ˆåº”è¯¥æ˜¯PascalCaseï¼‰
                if re.match(r'^\s*class\s+([a-z])', line):
                    issues.append(QualityIssue(
                        issue_id=str(uuid.uuid4()),
                        issue_type=IssueType.STYLE,
                        severity=IssueSeverity.MINOR,
                        file_path="",
                        line_number=i,
                        message="ç±»ååº”ä½¿ç”¨PascalCaseå‘½åè§„èŒƒ",
                        rule_id="class_naming_convention",
                        suggestion="å°†ç±»åé¦–å­—æ¯å¤§å†™"
                    ))
                    
        return issues
        
    async def _generate_recommendations(self, issues: List[QualityIssue], code_content: str) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []
        
        # æŒ‰é—®é¢˜ç±»å‹ç»Ÿè®¡
        issue_counts = {}
        for issue in issues:
            issue_type = issue.issue_type.value
            issue_counts[issue_type] = issue_counts.get(issue_type, 0) + 1
            
        # ç”Ÿæˆé’ˆå¯¹æ€§å»ºè®®
        if issue_counts.get('complexity', 0) > 0:
            recommendations.append("å»ºè®®ä½¿ç”¨è®¾è®¡æ¨¡å¼å’Œé‡æ„æŠ€æœ¯é™ä½ä»£ç å¤æ‚åº¦")
            
        if issue_counts.get('duplication', 0) > 0:
            recommendations.append("å»ºè®®æå–å…¬å…±æ–¹æ³•æˆ–ä½¿ç”¨ç»§æ‰¿æ¥æ¶ˆé™¤ä»£ç é‡å¤")
            
        if issue_counts.get('security', 0) > 0:
            recommendations.append("å»ºè®®ä½¿ç”¨å®‰å…¨ç¼–ç¨‹æœ€ä½³å®è·µï¼Œé¿å…å®‰å…¨æ¼æ´")
            
        if issue_counts.get('style', 0) > 0:
            recommendations.append("å»ºè®®ä½¿ç”¨ä»£ç æ ¼å¼åŒ–å·¥å…·ç»Ÿä¸€ä»£ç é£æ ¼")
            
        return recommendations
        
    async def _calculate_quality_metrics(self, analysis_results: Dict[str, Any]) -> QualityMetrics:
        """è®¡ç®—è´¨é‡æŒ‡æ ‡"""
        issues = analysis_results.get('issues', [])
        
        # æŒ‰ä¸¥é‡ç¨‹åº¦ç»Ÿè®¡é—®é¢˜
        critical_issues = len([i for i in issues if i.severity == IssueSeverity.CRITICAL])
        major_issues = len([i for i in issues if i.severity == IssueSeverity.MAJOR])
        minor_issues = len([i for i in issues if i.severity == IssueSeverity.MINOR])
        
        # æŒ‰ç±»å‹ç»Ÿè®¡é—®é¢˜
        security_issues = len([i for i in issues if i.issue_type == IssueType.SECURITY])
        bugs = len([i for i in issues if i.issue_type == IssueType.BUG])
        code_smells = len([i for i in issues if i.issue_type == IssueType.CODE_SMELL])
        
        # è®¡ç®—ç»¼åˆè´¨é‡åˆ†æ•° (0-100)
        overall_score = 100.0
        overall_score -= critical_issues * 20  # ä¸¥é‡é—®é¢˜æ‰£20åˆ†
        overall_score -= major_issues * 5      # é‡å¤§é—®é¢˜æ‰£5åˆ†
        overall_score -= minor_issues * 1      # è½»å¾®é—®é¢˜æ‰£1åˆ†
        overall_score = max(0, overall_score)  # æœ€ä½0åˆ†
        
        # ç®€åŒ–çš„æŒ‡æ ‡è®¡ç®—
        maintainability_index = max(0, 100 - major_issues * 5 - minor_issues * 2)
        complexity_score = max(0, 100 - len([i for i in issues if i.issue_type == IssueType.COMPLEXITY]) * 10)
        duplication_ratio = len([i for i in issues if i.issue_type == IssueType.DUPLICATION]) * 0.01
        tech_debt_ratio = (critical_issues * 0.1 + major_issues * 0.05 + minor_issues * 0.01)
        
        return QualityMetrics(
            overall_score=overall_score,
            maintainability_index=maintainability_index,
            complexity_score=complexity_score,
            duplication_ratio=duplication_ratio,
            test_coverage=85.0,  # æ¨¡æ‹Ÿå€¼
            security_issues=security_issues,
            code_smells=code_smells,
            bugs=bugs,
            tech_debt_ratio=tech_debt_ratio,
            lines_of_code=len(analysis_results.get('code_content', '').split('\n'))
        )
        
    def _determine_quality_level(self, score: float) -> QualityLevel:
        """ç¡®å®šè´¨é‡ç­‰çº§"""
        if score >= 90:
            return QualityLevel.EXCELLENT
        elif score >= 80:
            return QualityLevel.GOOD
        elif score >= 70:
            return QualityLevel.ACCEPTABLE
        elif score >= 60:
            return QualityLevel.POOR
        else:
            return QualityLevel.CRITICAL
            
    async def _handle_check_quality_gates(self, message):
        """å¤„ç†è´¨é‡é—¨ç¦æ£€æŸ¥"""
        try:
            data = message.body.data
            file_path = data.get('file_path')
            change_type = data.get('change_type', 'modification')
            
            self.logger.info(f"æ£€æŸ¥è´¨é‡é—¨ç¦: {file_path}")
            
            # è·å–å½“å‰è´¨é‡æŒ‡æ ‡
            current_metrics = self.quality_metrics.get(file_path)
            current_issues = self.quality_issues.get(file_path, [])
            
            if not current_metrics:
                await self._send_error_response(message, "æœªæ‰¾åˆ°è´¨é‡æŒ‡æ ‡ï¼Œè¯·å…ˆæ‰§è¡Œä»£ç åˆ†æ")
                return
                
            # æ£€æŸ¥é˜»æ–­æ¡ä»¶
            blocking_violations = []
            warning_violations = []
            
            for condition in self.quality_gates['blocking_conditions']:
                violation = await self._check_gate_condition(condition, current_metrics, current_issues)
                if violation:
                    blocking_violations.append(violation)
                    
            for condition in self.quality_gates['warning_conditions']:
                violation = await self._check_gate_condition(condition, current_metrics, current_issues)
                if violation:
                    warning_violations.append(violation)
                    
            # ç¡®å®šé—¨ç¦çŠ¶æ€
            gate_status = "PASSED"
            if blocking_violations:
                gate_status = "BLOCKED"
            elif warning_violations:
                gate_status = "WARNING"
                
            response_data = {
                'file_path': file_path,
                'gate_status': gate_status,
                'blocking_violations': blocking_violations,
                'warning_violations': warning_violations,
                'quality_score': current_metrics.overall_score,
                'recommendations': self._generate_gate_recommendations(blocking_violations, warning_violations)
            }
            
            await self._send_response(message, 'quality_gate_status', response_data)
            self.logger.info(f"è´¨é‡é—¨ç¦æ£€æŸ¥å®Œæˆ: {file_path}, çŠ¶æ€: {gate_status}")
            
        except Exception as e:
            self.logger.error(f"è´¨é‡é—¨ç¦æ£€æŸ¥å¤±è´¥: {e}")
            await self._send_error_response(message, str(e))
            
    async def _check_gate_condition(self, condition: Dict, metrics: QualityMetrics, issues: List[QualityIssue]) -> Optional[str]:
        """æ£€æŸ¥é—¨ç¦æ¡ä»¶"""
        condition_type = condition.get('type')
        threshold = condition.get('threshold', 0)
        
        if condition_type == 'security':
            severity = condition.get('severity')
            count = len([i for i in issues if i.issue_type == IssueType.SECURITY and i.severity.value == severity])
            if count > threshold:
                return f"å®‰å…¨é—®é¢˜è¶…æ ‡: {count} ä¸ª {severity} çº§åˆ«é—®é¢˜ (é˜ˆå€¼: {threshold})"
                
        elif condition_type == 'bug':
            severity = condition.get('severity')
            count = len([i for i in issues if i.issue_type == IssueType.BUG and i.severity.value == severity])
            if count > threshold:
                return f"åŠŸèƒ½ç¼ºé™·è¶…æ ‡: {count} ä¸ª {severity} çº§åˆ«ç¼ºé™· (é˜ˆå€¼: {threshold})"
                
        elif condition_type == 'coverage':
            min_decrease = condition.get('min_decrease', 0.05)
            # è¿™é‡Œåº”è¯¥ä¸å†å²è¦†ç›–ç‡æ¯”è¾ƒï¼Œç®€åŒ–å¤„ç†
            if metrics.test_coverage < 0.75:  # å‡è®¾ä¹‹å‰è¦†ç›–ç‡æ˜¯80%
                return f"æµ‹è¯•è¦†ç›–ç‡ä¸‹é™è¿‡å¤š: å½“å‰ {metrics.test_coverage:.1%} (æœ€å°å…è®¸ä¸‹é™: {min_decrease:.1%})"
                
        elif condition_type == 'complexity':
            max_increase = condition.get('max_increase', 0.1)
            # ç®€åŒ–å¤„ç†ï¼šå¦‚æœå¤æ‚åº¦å¾—åˆ†ä½äº70ï¼Œè®¤ä¸ºå¢é•¿è¿‡å¤š
            if metrics.complexity_score < 70:
                return f"ä»£ç å¤æ‚åº¦å¢é•¿è¿‡å¤š: å½“å‰å¾—åˆ† {metrics.complexity_score:.1f} (æœ€å¤§å…è®¸å¢é•¿: {max_increase:.1%})"
                
        return None
        
    def _generate_gate_recommendations(self, blocking_violations: List[str], warning_violations: List[str]) -> List[str]:
        """ç”Ÿæˆé—¨ç¦å»ºè®®"""
        recommendations = []
        
        if blocking_violations:
            recommendations.append("ğŸš« å‘ç°é˜»æ–­é—®é¢˜ï¼Œå¿…é¡»ä¿®å¤åæ‰èƒ½åˆå¹¶ä»£ç ")
            for violation in blocking_violations:
                recommendations.append(f"  - {violation}")
                
        if warning_violations:
            recommendations.append("âš ï¸ å‘ç°è­¦å‘Šé—®é¢˜ï¼Œå»ºè®®ä¿®å¤ä»¥æé«˜ä»£ç è´¨é‡")
            for violation in warning_violations:
                recommendations.append(f"  - {violation}")
                
        if not blocking_violations and not warning_violations:
            recommendations.append("âœ… ä»£ç è´¨é‡è‰¯å¥½ï¼Œç¬¦åˆæ‰€æœ‰è´¨é‡é—¨ç¦è¦æ±‚")
            
        return recommendations
        
    async def _handle_manage_tech_debt(self, message):
        """å¤„ç†æŠ€æœ¯å€ºåŠ¡ç®¡ç†"""
        try:
            data = message.body.data
            action = data.get('action')  # create, update, list, prioritize
            
            if action == 'create':
                debt = await self._create_tech_debt(data)
                response_data = {'action': 'created', 'debt': asdict(debt)}
            elif action == 'update':
                debt = await self._update_tech_debt(data)
                response_data = {'action': 'updated', 'debt': asdict(debt)}
            elif action == 'list':
                debts = await self._list_tech_debts(data)
                response_data = {'action': 'listed', 'debts': [asdict(d) for d in debts]}
            elif action == 'prioritize':
                prioritized_debts = await self._prioritize_tech_debts()
                response_data = {'action': 'prioritized', 'debts': [asdict(d) for d in prioritized_debts]}
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ“ä½œ: {action}")
                
            await self._send_response(message, 'tech_debt_update', response_data)
            self.logger.info(f"æŠ€æœ¯å€ºåŠ¡ç®¡ç†å®Œæˆ: {action}")
            
        except Exception as e:
            self.logger.error(f"æŠ€æœ¯å€ºåŠ¡ç®¡ç†å¤±è´¥: {e}")
            await self._send_error_response(message, str(e))
            
    async def _create_tech_debt(self, data: Dict) -> TechDebt:
        """åˆ›å»ºæŠ€æœ¯å€ºåŠ¡è®°å½•"""
        debt = TechDebt(
            debt_id=str(uuid.uuid4()),
            debt_type=TechDebtType(data.get('debt_type', 'code_debt')),
            description=data.get('description', ''),
            file_path=data.get('file_path', ''),
            estimated_hours=data.get('estimated_hours', 0.0),
            priority=data.get('priority', 'medium'),
            assigned_to=data.get('assigned_to', '')
        )
        
        self.tech_debts[debt.debt_id] = debt
        return debt
        
    async def _handle_generate_quality_report(self, message):
        """å¤„ç†è´¨é‡æŠ¥å‘Šç”Ÿæˆ"""
        try:
            data = message.body.data
            report_type = data.get('report_type', 'summary')  # summary, detailed, trend
            time_range = data.get('time_range', '7d')  # 7d, 30d, 90d
            
            self.logger.info(f"ç”Ÿæˆè´¨é‡æŠ¥å‘Š: {report_type}")
            
            if report_type == 'summary':
                report = await self._generate_summary_report()
            elif report_type == 'detailed':
                report = await self._generate_detailed_report()
            elif report_type == 'trend':
                report = await self._generate_trend_report(time_range)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æŠ¥å‘Šç±»å‹: {report_type}")
                
            response_data = {
                'report_type': report_type,
                'generated_at': datetime.now().isoformat(),
                'report': report
            }
            
            await self._send_response(message, 'quality_report', response_data)
            self.logger.info(f"è´¨é‡æŠ¥å‘Šç”Ÿæˆå®Œæˆ: {report_type}")
            
        except Exception as e:
            self.logger.error(f"è´¨é‡æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
            await self._send_error_response(message, str(e))
            
    async def _generate_summary_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š"""
        total_files = len(self.quality_metrics)
        if total_files == 0:
            return {'message': 'æš‚æ— è´¨é‡æ•°æ®'}
            
        # è®¡ç®—å¹³å‡æŒ‡æ ‡
        total_score = sum(m.overall_score for m in self.quality_metrics.values())
        avg_score = total_score / total_files
        
        total_issues = sum(len(issues) for issues in self.quality_issues.values())
        
        # ç»Ÿè®¡é—®é¢˜åˆ†å¸ƒ
        issue_distribution = {}
        for issues in self.quality_issues.values():
            for issue in issues:
                issue_type = issue.issue_type.value
                issue_distribution[issue_type] = issue_distribution.get(issue_type, 0) + 1
                
        # è´¨é‡ç­‰çº§åˆ†å¸ƒ
        quality_distribution = {}
        for metrics in self.quality_metrics.values():
            level = self._determine_quality_level(metrics.overall_score).value
            quality_distribution[level] = quality_distribution.get(level, 0) + 1
            
        return {
            'summary': {
                'total_files_analyzed': total_files,
                'average_quality_score': round(avg_score, 1),
                'total_issues': total_issues,
                'total_tech_debts': len(self.tech_debts)
            },
            'quality_distribution': quality_distribution,
            'issue_distribution': issue_distribution,
            'top_issues': self._get_top_issues(5),
            'recommendations': self._get_summary_recommendations()
        }
    
    def _get_top_issues(self, limit: int) -> List[Dict]:
        """è·å–æœ€ä¸¥é‡çš„é—®é¢˜"""
        all_issues = []
        for file_path, issues in self.quality_issues.items():
            for issue in issues:
                all_issues.append({
                    'file_path': file_path,
                    'issue': asdict(issue)
                })
                
        # æŒ‰ä¸¥é‡ç¨‹åº¦æ’åº
        severity_order = {
            IssueSeverity.BLOCKER: 0,
            IssueSeverity.CRITICAL: 1,
            IssueSeverity.MAJOR: 2,
            IssueSeverity.MINOR: 3,
            IssueSeverity.INFO: 4
        }
        
        all_issues.sort(key=lambda x: severity_order.get(
            IssueSeverity(x['issue']['severity']), 5
        ))
        
        return all_issues[:limit]
        
    def _get_summary_recommendations(self) -> List[str]:
        """è·å–æ€»ä½“å»ºè®®"""
        recommendations = []
        
        if len(self.quality_metrics) == 0:
            return ["å»ºè®®å¼€å§‹å¯¹ä»£ç è¿›è¡Œè´¨é‡åˆ†æ"]
            
        avg_score = sum(m.overall_score for m in self.quality_metrics.values()) / len(self.quality_metrics)
        
        if avg_score < 60:
            recommendations.append("ğŸš¨ æ•´ä½“ä»£ç è´¨é‡è¾ƒå·®ï¼Œå»ºè®®ç«‹å³å¼€å§‹é‡æ„å·¥ä½œ")
        elif avg_score < 80:
            recommendations.append("âš ï¸ ä»£ç è´¨é‡éœ€è¦æ”¹è¿›ï¼Œå»ºè®®åˆ¶å®šè´¨é‡æå‡è®¡åˆ’")
        else:
            recommendations.append("âœ… ä»£ç è´¨é‡è‰¯å¥½ï¼Œå»ºè®®ä¿æŒç°æœ‰æ ‡å‡†")
            
        # åŸºäºæŠ€æœ¯å€ºåŠ¡æä¾›å»ºè®®
        if len(self.tech_debts) > 10:
            recommendations.append("ğŸ“‹ æŠ€æœ¯å€ºåŠ¡è¾ƒå¤šï¼Œå»ºè®®ä¼˜å…ˆå¤„ç†é«˜ä¼˜å…ˆçº§å€ºåŠ¡")
            
        return recommendations
        
    async def _initialize_role(self):
        """åˆå§‹åŒ–è§’è‰²ç‰¹å®šèµ„æº"""
        self.logger.info(f"{self.role_name} è§’è‰²åˆå§‹åŒ–å®Œæˆ")
        
    async def _cleanup_role(self):
        """æ¸…ç†è§’è‰²ç‰¹å®šèµ„æº"""
        self.logger.info(f"{self.role_name} è§’è‰²æ¸…ç†å®Œæˆ")
        
    async def _process_task(self, task: Task):
        """å¤„ç†ä»»åŠ¡"""
        self.logger.info(f"å¤„ç†ä»»åŠ¡: {task.task_id}")
        # ç®€åŒ–å¤„ç†
        task.status = TaskStatus.COMPLETED
        
    async def _handle_custom_message(self, message):
        """å¤„ç†è‡ªå®šä¹‰æ¶ˆæ¯"""
        self.logger.info(f"æ”¶åˆ°è‡ªå®šä¹‰æ¶ˆæ¯: {message}")
        return "å¤„ç†å®Œæˆ"
        
    async def _handle_scan_security(self, message):
        """å¤„ç†å®‰å…¨æ‰«æè¯·æ±‚"""
        try:
            data = message.body.data
            code_content = data.get('code_content', '')
            language = data.get('language', 'unknown')
            
            self.logger.info("å¼€å§‹å®‰å…¨æ‰«æ")
            
            # æ‰§è¡Œå®‰å…¨æ‰«æ
            security_issues = await self._scan_security(code_content, language)
            
            response_data = {
                'scan_completed': True,
                'issues_found': len(security_issues),
                'security_issues': [asdict(issue) for issue in security_issues]
            }
            
            await self._send_response(message, 'security_scan_result', response_data)
            self.logger.info(f"å®‰å…¨æ‰«æå®Œæˆï¼Œå‘ç° {len(security_issues)} ä¸ªé—®é¢˜")
            
        except Exception as e:
            self.logger.error(f"å®‰å…¨æ‰«æå¤±è´¥: {e}")
            await self._send_error_response(message, str(e))
            
    async def _handle_detect_duplicates(self, message):
        """å¤„ç†é‡å¤ä»£ç æ£€æµ‹è¯·æ±‚"""
        try:
            data = message.body.data
            code_content = data.get('code_content', '')
            file_path = data.get('file_path', '')
            
            self.logger.info("å¼€å§‹é‡å¤ä»£ç æ£€æµ‹")
            
            # æ‰§è¡Œé‡å¤ä»£ç æ£€æµ‹
            duplicate_issues = await self._detect_duplicates(code_content, file_path)
            
            response_data = {
                'detection_completed': True,
                'duplicates_found': len(duplicate_issues),
                'duplicate_issues': [asdict(issue) for issue in duplicate_issues]
            }
            
            await self._send_response(message, 'duplication_report', response_data)
            self.logger.info(f"é‡å¤ä»£ç æ£€æµ‹å®Œæˆï¼Œå‘ç° {len(duplicate_issues)} ä¸ªé—®é¢˜")
            
        except Exception as e:
            self.logger.error(f"é‡å¤ä»£ç æ£€æµ‹å¤±è´¥: {e}")
            await self._send_error_response(message, str(e))
            
    async def _handle_analyze_complexity(self, message):
        """å¤„ç†å¤æ‚åº¦åˆ†æè¯·æ±‚"""
        try:
            data = message.body.data
            code_content = data.get('code_content', '')
            language = data.get('language', 'unknown')
            
            self.logger.info("å¼€å§‹å¤æ‚åº¦åˆ†æ")
            
            # æ‰§è¡Œå¤æ‚åº¦åˆ†æ
            complexity_issues = await self._analyze_complexity(code_content, language)
            
            response_data = {
                'analysis_completed': True,
                'complexity_issues_found': len(complexity_issues),
                'complexity_issues': [asdict(issue) for issue in complexity_issues]
            }
            
            await self._send_response(message, 'complexity_analysis', response_data)
            self.logger.info(f"å¤æ‚åº¦åˆ†æå®Œæˆï¼Œå‘ç° {len(complexity_issues)} ä¸ªé—®é¢˜")
            
        except Exception as e:
            self.logger.error(f"å¤æ‚åº¦åˆ†æå¤±è´¥: {e}")
            await self._send_error_response(message, str(e))
            
    async def _handle_update_quality_rules(self, message):
        """å¤„ç†è´¨é‡è§„åˆ™æ›´æ–°è¯·æ±‚"""
        try:
            data = message.body.data
            rule_updates = data.get('rule_updates', {})
            
            self.logger.info("å¼€å§‹æ›´æ–°è´¨é‡è§„åˆ™")
            
            # æ›´æ–°è´¨é‡è§„åˆ™
            for rule_category, rule_values in rule_updates.items():
                if rule_category in self.quality_rules:
                    self.quality_rules[rule_category].update(rule_values)
                    
            response_data = {
                'update_completed': True,
                'updated_rules': list(rule_updates.keys()),
                'current_rules': self.quality_rules
            }
            
            await self._send_response(message, 'quality_rules_updated', response_data)
            self.logger.info(f"è´¨é‡è§„åˆ™æ›´æ–°å®Œæˆï¼Œæ›´æ–°äº† {len(rule_updates)} ä¸ªè§„åˆ™ç±»åˆ«")
            
        except Exception as e:
            self.logger.error(f"è´¨é‡è§„åˆ™æ›´æ–°å¤±è´¥: {e}")
            await self._send_error_response(message, str(e))